{"version":2,"generated":"2025-12-08T12:38:06.937Z","totalDocs":158,"docs":[{"id":0,"title":"BlackBox Flight Recorder","description":"Event recording and crash analysis for post-mortem debugging and incident investigation","slug":"/advanced/blackbox","content":"BlackBox Flight Recorder The BlackBox flight recorder provides continuous event logging in a circular buffer for post-mortem analysis. Like an aircraft flight recorder, it captures all significant events leading up to failures for debugging and incident investigation. Overview The BlackBox system: - Records all significant scheduler and node events - Uses a circular buffer to limit memory usage - Supports write-ahead logging (WAL) for crash recovery - Generates detailed crash reports - Enables filtering by event type or time range Enabling BlackBox Event Types The BlackBox records 12 event types covering all critical system operations: Description Scheduler initialization with config SchedulerStop New node registered NodeTick Node execution failed DeadlineMiss Node exceeded WCET budget CircuitBreakerChange Profiling learning phase finished JITCompilation Emergency stop triggered Custom Recording Events Querying Events Get All Events Get Recent Events Filter by Event Type Get Anomalies Get all error-related events (errors, deadline misses, WCET violations, emergency stops): Persistence Write-Ahead Logging (WAL) The WAL file ensures events are persisted immediately for crash recovery: Save and Load Crash Reports Generate a comprehensive crash report for incident analysis: Sample output: Thread-Safe Usage For multi-threaded applications, use the shared blackbox wrapper: Integration with Scheduler The scheduler automatically integrates with BlackBox: Configuration Default 0 (disabled) 5000/MB Immediate Best Practices 1. Enable in Production 2. Regular Saves 3. Size Appropriately - Development: 1-5 MB - Production: 10-50 MB - Long-running systems: 50-100 MB 4. Monitor Anomalies See Also - Safety Monitor - Real-time safety monitoring - Circuit Breaker - Fault tolerance patterns - Checkpoint System - State persistence - Troubleshooting - Common issues and solutions","headings":"BlackBox Flight Recorder Overview Enabling BlackBox Event Types Recording Events Querying Events Get All Events Get Recent Events Filter by Event Type Get Anomalies Persistence Write-Ahead Logging (WAL) Save and Load Crash Reports Thread-Safe Usage Integration with Scheduler Configuration Best Practices 1. Enable in Production 2. Regular Saves 3. Size Appropriately 4. Monitor Anomalies See Also","category":"advanced"},{"id":1,"title":"Checkpoint System","description":"Periodic state snapshots for crash recovery and rollback","slug":"/advanced/checkpoint","content":"Checkpoint System The Checkpoint System provides periodic state snapshots that can be used to recover from crashes or rollback to known-good states. This is essential for long-running robotics applications that need fault tolerance. Overview The checkpoint system provides: - Periodic snapshots: Automatic state persistence at intervals - Crash recovery: Restore from last checkpoint after failure - Rollback: Return to previous known-good states - Retention policy: Automatic cleanup of old checkpoints Basic Usage Creating a Checkpoint Manager Checking When to Checkpoint Creating Checkpoints Checkpoint Structure Loading Checkpoints Load Latest Load Specific Checkpoint List Available Checkpoints Custom Node State Nodes can save custom state in checkpoints: Automatic Cleanup Old checkpoints are automatically removed: Integration with Scheduler Recovery Flow Best Practices 1. Choose Appropriate Intervals 2. Checkpoint Before Risky Operations 3. Validate Checkpoints 4. Log Checkpoint Events File Format Checkpoints are stored as bincode-serialized files: File naming ensures chronological ordering and easy identification. See Also - BlackBox Flight Recorder - Event logging - Safety Monitor - Real-time safety - Circuit Breaker - Fault tolerance","headings":"Checkpoint System Overview Basic Usage Creating a Checkpoint Manager Checking When to Checkpoint Creating Checkpoints Checkpoint Structure Loading Checkpoints Load Latest Load Specific Checkpoint List Available Checkpoints Custom Node State Automatic Cleanup Integration with Scheduler Recovery Flow Best Practices 1. Choose Appropriate Intervals 2. Checkpoint Before Risky Operations 3. Validate Checkpoints 4. Log Checkpoint Events File Format See Also","category":"advanced"},{"id":2,"title":"Circuit Breaker","description":"Fault tolerance pattern for preventing cascading failures in node execution","slug":"/advanced/circuit-breaker","content":"Circuit Breaker The circuit breaker pattern prevents cascading failures by temporarily disabling failing nodes. When a node fails repeatedly, the circuit \"opens\" to stop calling it, giving it time to recover. Overview Circuit breakers protect against: - Cascading failures from one failing node - Resource exhaustion from repeated retry attempts - System-wide slowdowns from blocked calls States Description Normal operation Too many failures Testing recovery Basic Usage Configuration State Transitions Closed → Open When failures reach the threshold: Open → Half-Open After timeout elapses: Half-Open → Closed After success threshold: Half-Open → Open On any failure: Monitoring Get Statistics State Checking Integration with Scheduler The scheduler automatically manages circuit breakers for each node: Per-Node Configuration Configure circuit breakers per node for different reliability requirements: Thread Safety The circuit breaker uses lock-free atomics for thread-safe operation: Best Practices 1. Tune Thresholds Per Node Type 2. Monitor Circuit State 3. Handle Open Circuit Gracefully 4. Log State Changes Common Configurations Failure Threshold Timeout 2-3 10-30s Control loop 3 10 2-3s Logging 1 5 10s | See Also - BlackBox Flight Recorder - Event logging - Safety Monitor - Real-time safety - Checkpoint System - State recovery","headings":"Circuit Breaker Overview States Basic Usage Configuration State Transitions Closed → Open Open → Half-Open Half-Open → Closed Half-Open → Open Monitoring Get Statistics State Checking Integration with Scheduler Per-Node Configuration Thread Safety Best Practices 1. Tune Thresholds Per Node Type 2. Monitor Circuit State 3. Handle Open Circuit Gracefully 4. Log State Changes Common Configurations See Also","category":"advanced"},{"id":3,"title":"Deterministic Execution","description":"Achieving bit-for-bit reproducible execution in HORUS for testing, debugging, and safety certification","slug":"/advanced/deterministic-execution","content":"Deterministic Execution HORUS supports fully deterministic execution where the same inputs produce identical outputs every run. This is essential for safety-critical systems, debugging, and formal verification. Key Takeaways After reading this guide, you will understand: - Why determinism matters for robotics - How to enable deterministic mode in HORUS - The trade-offs between determinism and performance - Best practices for reproducible robot behavior Why Determinism Matters Safety Certification Safety standards (ISO 26262, IEC 62443) often require: - Predictable execution timing - Reproducible behavior under test - Formal verification of control loops Debugging Non-deterministic bugs are hard to reproduce: - \"It worked yesterday but fails today\" - Race conditions that appear randomly - Timing-dependent failures Testing Deterministic execution enables: - Repeatable unit tests - Regression testing - Simulation validation Determinism Levels HORUS offers different levels of deterministic guarantees. Choose based on your requirements: Config Use Case Scheduler::new() Most applications + Performance Basic + explicit JIT/optimization tiers SchedulerConfig::safetycritical() Medical, industrial + Topology Basic + connection validation, locked graph Level 1: Basic Determinism (Default) Scheduler::new() is deterministic out of the box: Guarantees: - Sequential execution (same order every tick) - No learning phase (no 100-tick profiling) - Reproducible runs with same inputs Does NOT include: Performance optimization, safety monitoring, topology validation. Level 2: Determinism + Performance Use addwithtier() to get deterministic execution with explicit performance tiers: Adds: Explicit performance tiers without runtime profiling (deterministic optimization). Level 3: Determinism + Safety Use SchedulerConfig::safetycritical() for safety-critical systems: Adds: - Watchdog timers (100ms timeout) - WCET enforcement - Deadline monitoring (panic on miss) - Memory locking (mlockall)","headings":"Deterministic Execution Key Takeaways Why Determinism Matters Safety Certification Debugging Testing Determinism Levels Level 1: Basic Determinism (Default) Level 2: Determinism + Performance Level 3: Determinism + Safety Level 4: Determinism + Topology Validation Topology Validation DeterministicConfig Options Presets Topology Methods What Topology Validation Checks Auto-Collection from Nodes What Makes Execution Deterministic? Learning Phase (Opt-In Only) Sequential Execution Fixed Timing Deterministic vs Non-Deterministic Execution Comparison Performance Trade-off Best Practices Use Deterministic Seeds Avoid System Time Control External Inputs Example: Deterministic Robot Controller Verification Comparing Runs Run 1 Run 2 Compare (should be identical in deterministic mode) No output = identical runs Automated Testing When to Enable Learning Summary Next Steps","category":"advanced"},{"id":4,"title":"Execution Modes","description":"Understanding HORUS scheduler execution modes: JIT, Parallel, Sequential, AsyncIO, and AutoAdaptive","slug":"/advanced/execution-modes","content":"Execution Modes HORUS supports multiple execution modes to optimize for different robotics scenarios. This guide explains each mode, when to use it, and the trade-offs involved. Overview Sequential Mode The deterministic choice for safety-critical systems. How It Works - Nodes execute one-by-one in priority order - Same execution order every tick - No learning phase, no adaptation - Bit-for-bit reproducible runs Characteristics Value 100-500ns per node Deterministic No (single thread) Best For When to Use - Medical/surgical robots requiring certification - Systems needing reproducible behavior - Debugging complex timing issues - Formal verification scenarios JITOptimized Mode Maximum performance through Just-In-Time compilation. How It Works - Uses Cranelift JIT compiler - Compiles hot paths to native machine code - Optimizes simple arithmetic and control flow - Learning phase identifies candidates for JIT Characteristics Value &lt;50ns for JIT-compiled nodes Deterministic 100 ticks Best For JIT-Compatible Operations The JIT compiler optimizes: - Arithmetic operations (+, -, , /) - Simple control flow - Data transformations - Filter calculations When to Use - Racing/competition robots - High-frequency control loops (&gt;1kHz) - Performance-critical applications - When determinism is not required Parallel Mode Multi-core execution with dependency resolution. How It Works - Analyzes node dependencies - Builds execution DAG (Directed Acyclic Graph) - Schedules independent nodes on different cores - Respects data dependencies Characteristics Value Variable (depends on DAG) Deterministic Yes Best For Dependency Analysis When to Use - Multi-sensor robots - Compute-heavy pipelines - Systems with many independent nodes - When you have multiple CPU cores available AsyncIO Mode Optimized for I/O-bound operations. How It Works - Uses async/await for I/O operations - Non-blocking network and file access - Event-driven execution - Optimal for waiting on external resources Charac","headings":"Execution Modes Overview Sequential Mode How It Works Characteristics When to Use JITOptimized Mode How It Works Characteristics JIT-Compatible Operations When to Use Parallel Mode How It Works Characteristics Dependency Analysis When to Use AsyncIO Mode How It Works Characteristics When to Use AutoAdaptive Mode (Opt-In) How It Works Node Classification Tiers Characteristics Deterministic Alternative When to Use Mode Comparison Choosing the Right Mode Examples Safety-Critical System Racing Robot Multi-Sensor Robot Cloud-Connected Robot Next Steps","category":"advanced"},{"id":5,"title":"GPU Tensor Sharing","description":"Zero-copy GPU memory sharing across processes using CUDA IPC for high-performance AI/ML robotics","slug":"/advanced/gpu-tensor-sharing","content":"GPU Tensor Sharing HORUS provides native CUDA IPC (Inter-Process Communication) support for sharing GPU tensors between processes with zero-copy semantics. This enables high-performance AI/ML robotics pipelines where perception, planning, and control can share GPU data without expensive CPU roundtrips. Key Takeaways After reading this guide, you will understand: - How CUDA IPC enables zero-copy GPU memory sharing - When to use GPU tensor sharing vs CPU tensors - How to implement cross-process GPU pipelines - Performance characteristics and limitations Why GPU Tensor Sharing? The Problem Traditional robotics frameworks copy data through CPU memory: This adds 4ms+ latency per frame for a 1080p image. The Solution HORUS uses CUDA IPC to share GPU memory directly: Only a 64-byte handle is transferred. Both processes access the same physical GPU memory. Enabling CUDA Support Build Configuration Enable the cuda feature in your Cargo.toml: Runtime Requirements - NVIDIA GPU with compute capability 3.0+ - CUDA 11.0+ runtime installed - Linux (CUDA IPC not supported on Windows/macOS) Check availability at runtime: Basic Usage Rust API Python API Architecture CudaTensorPool The CudaTensorPool manages GPU memory with IPC support: Memory Layout Each tensor slot stores: - 64-byte CUDA IPC handle - Shape, dtype, size metadata - Atomic reference count - Generation counter (ABA prevention) Integration with Hub/Link Sending GPU Tensors GPU tensors integrate with HORUS Hub and Link communication: Receiving GPU Tensors Performance Characteristics Latency Comparison Latency 1μs 10μs 0 2ms 2ms Best Use Cases Good for: - Multi-process ML inference pipelines - Camera → Detection → Planning chains - GPU-accelerated sensor fusion - Real-time neural network inference Not ideal for: - Single-process applications (use TensorHandle directly) - Small tensors (&lt;1KB) - IPC overhead dominates - Non-Linux platforms Limitations Platform Support Support Full support Windows Not supported (no CUDA) |","headings":"GPU Tensor Sharing Key Takeaways Why GPU Tensor Sharing? The Problem The Solution Enabling CUDA Support Build Configuration Runtime Requirements Basic Usage Rust API Python API Check CUDA availability Create tensor pool Allocate CPU tensor and transfer to GPU Get IPC handle for sharing Zero-copy PyTorch integration Architecture CudaTensorPool Memory Layout Integration with Hub/Link Sending GPU Tensors Receiving GPU Tensors Performance Characteristics Latency Comparison Best Use Cases Limitations Platform Support CUDA IPC Constraints Troubleshooting \"CUDA not available\" Check NVIDIA driver Check CUDA toolkit Ensure libcudart is installed \"Failed to open IPC handle\" Memory Leaks Example: ML Inference Pipeline See Also","category":"advanced"},{"id":6,"title":"JIT Compilation","description":"Just-in-time compilation for ultra-fast node execution using Cranelift","slug":"/advanced/jit-compilation","content":"JIT Compilation HORUS includes a JIT (Just-In-Time) compiler that compiles deterministic dataflow nodes to native machine code for ultra-fast execution (20-50ns latency). This is ideal for simple arithmetic operations that run millions of times. Overview The JIT compiler: - Compiles deterministic nodes to native x86-64/ARM64 code - Achieves 20-50ns execution latency (vs 1µs for interpreted) - Uses Cranelift as the backend compiler - Automatically selected for nodes classified as \"UltraFast\" tier When to Use JIT JIT compilation is beneficial for: - Simple arithmetic/math operations - Dataflow transformations (scale, offset, combine) - High-frequency sensor processing - Nodes with &lt;5µs execution time and low variance JIT is not suitable for: - Nodes with I/O operations - Nodes that allocate memory - Nodes with complex control flow - Nodes that call external libraries Enabling JIT Enable the JIT feature in Cargo.toml: Basic Usage Creating the JIT Compiler Compiling Arithmetic Nodes Compile a simple output = input factor + offset operation: Compiling Dataflow Combiners Compile multi-input dataflow: output = (a + b) (c - d): Integration with Scheduler The scheduler automatically identifies and JIT-compiles suitable nodes: Execution Tiers The scheduler classifies nodes into execution tiers based on profiling: Latency 20-50ns 50-100ns 10-100µs 1-10ms 1-100ms Tier Classification Criteria Performance Comparison Latency 20-50ns 50-100ns 100-500ns 1-10ms Example: Sensor Pipeline Compiled Dataflow The JIT compiler supports compiled dataflow graphs: Limitations Supported Operations - Integer arithmetic (add, sub, mul, div) - Bitwise operations (and, or, xor, shift) - Comparisons - Constants Not Supported - Floating point (use scaled integers) - Memory allocation - System calls - Complex control flow - External function calls Workarounds Safety JIT-compiled functions require unsafe to execute: Debugging Check Compilation Verify Results Requirements - Feature flag: jit - Depend","headings":"JIT Compilation Overview When to Use JIT Enabling JIT Basic Usage Creating the JIT Compiler Compiling Arithmetic Nodes Compiling Dataflow Combiners Integration with Scheduler Execution Tiers Tier Classification Criteria Performance Comparison Example: Sensor Pipeline Compiled Dataflow Limitations Supported Operations Not Supported Workarounds Safety Debugging Check Compilation Verify Results Requirements See Also","category":"advanced"},{"id":7,"title":"Model Registry","description":"ML model versioning, metadata management, and deployment configuration","slug":"/advanced/model-registry","content":"Model Registry The Model Registry provides centralized management for machine learning models used in HORUS applications. It handles versioning, metadata, and deployment configuration for models in various formats. Overview The registry provides: - Version management: Track multiple versions of each model - Metadata storage: Metrics, training info, format details - Status tracking: latest, stable, deprecated - YAML persistence: Human-readable configuration Registry Configuration Models are configured in /.horus/models.yaml: Basic Usage Creating a Registry Getting Models Listing Models Model Entry Each model version has comprehensive metadata: Registering Models Add New Version Update Status Model Formats The registry supports various model formats: Extension .onnx .tflite .pt, .pth .engine .xml, .bin Metrics Tracking Track model performance metrics: Integration with Nodes Use the registry in inference nodes: Validation Validate model integrity: Model Selection Select models based on requirements: Best Practices 1. Use Semantic Versioning 2. Include Hashes for Production 3. Track Training Metadata 4. Deprecate Gracefully File Structure Recommended project structure: See Also - GPU Tensor Sharing - GPU memory for inference - Built-in Nodes - Using models in nodes","headings":"Model Registry Overview Registry Configuration Basic Usage Creating a Registry Getting Models Listing Models Model Entry Registering Models Add New Version Update Status Model Formats Metrics Tracking Integration with Nodes Validation Model Selection Best Practices 1. Use Semantic Versioning Good Bad 2. Include Hashes for Production 3. Track Training Metadata 4. Deprecate Gracefully File Structure See Also","category":"advanced"},{"id":8,"title":"Network Backends","description":"High-performance network transports: QUIC, io_uring, compression, and batching","slug":"/advanced/network-backends","content":"Network Backends HORUS provides advanced network backends for high-performance distributed communication. These backends offer significant improvements over basic UDP/TCP for robotics applications. Available Backends Latency Use Case 10µs Local network iouring High 1ms WAN, reliable SmartTransport Auto QUIC Transport QUIC provides reliable, encrypted transport with superior performance over TCP: Features - 0-RTT connection resumption: No handshake latency for repeat connections - No head-of-line blocking: Independent streams - Built-in TLS 1.3: Encrypted by default - Connection migration: Handles IP changes - Better congestion control: Modern algorithms Enabling QUIC Configuration Configuration Options Default High Throughput 30s 120s keepaliveinterval 2s 100 1000 enable0rtt true 10ms 20ms maxudppayloadsize 1472 Client Usage Server Usage Statistics iouring Backend True zero-copy networking using Linux iouring for ultra-low latency: Features - 3-5µs latency: Matches Zenoh-pico performance - Zero-copy: Registered buffers avoid copies - SQPOLL mode: Kernel-side polling without syscalls - Single core 100Gb: Can saturate high-speed NICs Requirements - Linux 5.6+ (5.19+ for SQPOLL without root) - io-uring-net feature - Root or CAPSYSNICE for SQPOLL Enabling iouring Configuration Configuration Options Default Low Latency 256 128 sqpoll true 2000 0 numbuffers 256 65536 8192 cooptaskrun true true true Algorithm Ratio LZ4 Moderate Slower Large payloads Auto Varies Configuration Usage Network Packets Smart Transport Auto-selects the best transport based on conditions: Message Batching Batch multiple messages for efficiency: Congestion Control Adaptive congestion control for network stability: Best Practices 1. Choose the Right Backend 2. Enable Compression for Large Data 3. Batch Small Messages See Also - Network Communication - Basic networking - Shared Memory - Local communication - GPU Tensor Sharing - GPU memory transfer","headings":"Network Backends Available Backends QUIC Transport Features Enabling QUIC Configuration Configuration Options Client Usage Server Usage Statistics iouring Backend Features Requirements Enabling iouring Configuration Configuration Options Basic Usage Async Operations SQPOLL Mode Compression Algorithms Configuration Usage Network Packets Smart Transport Message Batching Congestion Control Best Practices 1. Choose the Right Backend 2. Enable Compression for Large Data 3. Batch Small Messages See Also","category":"advanced"},{"id":9,"title":"Safety Monitor","description":"Real-time safety monitoring with watchdogs, WCET enforcement, and emergency stop","slug":"/advanced/safety-monitor","content":"Safety Monitor The Safety Monitor provides real-time safety monitoring for safety-critical robotics applications. It enforces timing constraints, monitors node health, and triggers emergency stops when safety violations occur. Overview The Safety Monitor includes: - Watchdogs: Monitor node liveness - WCET Enforcement: Worst-Case Execution Time budgets - Deadline Tracking: Count and handle deadline misses - Emergency Stop: Immediate system halt on critical failures - Safety States: Normal, Degraded, Safe Mode, Emergency Stop Safety States Description All systems operating correctly Non-critical failures detected Significant issues detected Critical failure Basic Usage Creating a Safety Monitor Watchdogs Watchdogs monitor node liveness by requiring periodic \"feeding\": Feeding Watchdogs Checking Watchdogs Watchdog Configuration WCET Enforcement Worst-Case Execution Time (WCET) budgets ensure nodes complete within time limits: Setting Budgets Checking Execution Time WCET Violation Details Deadline Monitoring Track deadline misses across the system: Emergency Stop Trigger immediate system halt: Automatic Triggers Emergency stop is automatically triggered by: - Critical node watchdog expiration - Critical node WCET violation - Critical node deadline miss - Exceeding maxdeadlinemisses threshold Safety States Management Entering Degraded Mode Entering Safe Mode Statistics Get comprehensive safety statistics: Integration with Scheduler The scheduler integrates with the safety monitor: Complete Example Best Practices 1. Set Conservative Budgets Initially 2. Use Appropriate Watchdog Timeouts 3. Layer Safety Checks 4. Log Safety Events 5. Test Emergency Stop See Also - BlackBox Flight Recorder - Event logging - Circuit Breaker - Fault tolerance - Checkpoint System - State recovery","headings":"Safety Monitor Overview Safety States Basic Usage Creating a Safety Monitor Watchdogs Feeding Watchdogs Checking Watchdogs Watchdog Configuration WCET Enforcement Setting Budgets Checking Execution Time WCET Violation Details Deadline Monitoring Emergency Stop Automatic Triggers Safety States Management Entering Degraded Mode Entering Safe Mode Statistics Integration with Scheduler Complete Example Best Practices 1. Set Conservative Budgets Initially 2. Use Appropriate Watchdog Timeouts 3. Layer Safety Checks 4. Log Safety Events 5. Test Emergency Stop See Also","category":"advanced"},{"id":10,"title":"Scheduler Configuration","description":"Advanced scheduler configuration for real-time, safety-critical, and high-performance robotics","slug":"/advanced/scheduler-configuration","content":"Scheduler Configuration HORUS provides a comprehensive SchedulerConfig system that allows you to tune the scheduler for different robotics scenarios - from rapid prototyping to safety-critical medical devices. Key Takeaways After reading this guide, you will understand: - How to configure the scheduler for different execution modes (Sequential, Parallel, JIT, Adaptive) - When to use deterministic vs adaptive scheduling - How to apply robot presets for common scenarios - Advanced timing, fault tolerance, and real-time configuration options SchedulerConfig Overview The SchedulerConfig struct provides complete control over scheduler behavior. Note that Scheduler::new() is deterministic by default - configuration is only needed for advanced customization. Configuration Sections Execution Mode Controls how nodes are executed each tick: Latency Best For &lt;50ns tick Racing, competition Parallel No Variable Network-heavy apps Sequential Yes Variable General robotics Setting Standard High-Performance Execution AutoAdaptive JITOptimized No No Opt-in Tick Rate 60 Hz 10 kHz - 10μs 5μs Deadline Miss Warn Skip No Yes Yes Watchdog No No No Yes Yes SCHEDFIFO No Yes Yes Yes With profile | Next Steps - Learn about Execution Modes in detail - Understand Deterministic Execution for reproducible runs","headings":"Scheduler Configuration Key Takeaways SchedulerConfig Overview Configuration Sections Execution Mode Timing Configuration Fault Tolerance Configuration Real-Time Configuration Resource Configuration Built-in Presets Default (No Config Needed) Standard (With Config) Safety-Critical High-Performance Hard Real-Time Space Robotics Swarm Robotics Custom Configuration Configuration Comparison Next Steps","category":"advanced"},{"id":11,"title":"Scheduling Intelligence","description":"Runtime profiling, automatic tier classification, and dependency analysis for optimal node execution","slug":"/advanced/scheduling-intelligence","content":"Scheduling Intelligence HORUS includes an intelligent scheduling system that automatically profiles node execution characteristics and optimizes scheduling decisions. The system learns node behavior during a learning phase and classifies nodes into execution tiers for optimal performance. Overview The scheduling intelligence system includes: - RuntimeProfiler: Collects execution statistics using Welford's algorithm - TierClassifier: Assigns nodes to execution tiers based on characteristics - DependencyGraph: Analyzes pub/sub relationships for parallel execution - OfflineProfiler: Pre-computed execution profiles for deterministic systems Runtime Profiler The RuntimeProfiler collects real-time statistics about node execution: Creating a Profiler Recording Execution Times Recording Failures Checking Learning Progress Node Statistics The profiler tracks comprehensive statistics for each node: Classification Criteria Criteria Coefficient of variation < 10% I/O Heavy Average 100µs AND CV < 20% High Failure Rate Tier Classifier The TierClassifier assigns nodes to execution tiers based on profiler data: Execution Tiers Criteria Execution Method &lt;5µs, deterministic JIT compiled Fast 50-100ns I/O heavy Async executor Isolated 1-10ms Everything else Thread pool | Classification Priority Tier Statistics Dependency Graph The DependencyGraph analyzes pub/sub relationships to identify parallel execution opportunities: Topological Levels Nodes at the same level can execute in parallel: Parallel Groups Find nodes that can execute truly in parallel (no path between them): Graph Statistics Profiler Summary Generate a summary report: Integration with Scheduler The scheduler integrates all intelligence components: Forcing Classifications For testing or known node characteristics: Best Practices 1. Appropriate Learning Phase 2. Monitor Tier Changes 3. Validate Dependency Graph See Also - JIT Compilation - Ultra-fast execution - Execution Modes - Execution strategies - Scheduler Config","headings":"Scheduling Intelligence Overview Runtime Profiler Creating a Profiler Recording Execution Times Recording Failures Checking Learning Progress Node Statistics Classification Criteria Tier Classifier Execution Tiers Classification Priority Tier Statistics Dependency Graph Topological Levels Parallel Groups Graph Statistics Profiler Summary Integration with Scheduler Forcing Classifications Best Practices 1. Appropriate Learning Phase 2. Monitor Tier Changes 3. Validate Dependency Graph See Also","category":"advanced"},{"id":12,"title":"Advanced Examples","description":"Complex patterns, state machines, multi-process systems, and Python integration","slug":"/advanced-examples","content":"Advanced Examples Advanced HORUS patterns for complex robotics systems. These examples demonstrate state machines, priority-based safety systems, multi-process architectures, and cross-language communication. Prerequisites: Complete Basic Examples first. 1. State Machine Node Implement complex behavior using state machines - ideal for autonomous robots with multiple operating modes. File: statemachine.rs Run it: Key Concepts: - Enum for states: Idle, Moving, ObstacleDetected, Rotating, Escaped - Match expression handles state transitions - Each state defines behavior and next state - Log state transitions for debugging 2. Priority-Based Safety System Use node priorities to ensure safety-critical tasks always run first - essential for production robotics. File: safetysystem.rs Run it: Key Concepts: - Priority 0 (Critical): Emergency stop - runs first, always - Priority 1 (High): Motor control - runs after safety checks - Priority 4 (Background): Logging - runs last, non-critical - Lower number = higher priority - Safety systems should always check estop before acting 3. Python Multi-Process System Build a complete sensor monitoring system with Python nodes running as independent processes. Project Structure Sensor Node nodes/sensor.py: Controller Node nodes/controller.py: Logger Node nodes/logger.py: Run All Nodes Concurrently Output: Key Features: - Independent Processes: Each node runs in its own process - Shared Memory IPC: Nodes communicate via HORUS topics (/dev/shm/horus/) - Color-Coded Output: Each node has a unique color - Graceful Shutdown: Ctrl+C stops all processes cleanly - Zero Configuration: No launch files needed 4. Rust + Python Cross-Language System Mix Rust and Python nodes in the same application. Rust Sensor Node nodes/rustsensor.rs: Python Controller Node nodes/pycontroller.py: Rust Actuator Node nodes/rustactuator.rs: Run Mixed System HORUS automatically detects file types and compiles/runs appropriately! Key Concepts: - Rust nodes: High perform","headings":"Advanced Examples 1. State Machine Node 2. Priority-Based Safety System 3. Python Multi-Process System Project Structure Sensor Node Controller Node Logger Node Run All Nodes Concurrently Make scripts executable Run all nodes as separate processes 4. Rust + Python Cross-Language System Rust Sensor Node Python Controller Node Rust Actuator Node Run Mixed System 5. Advanced Python Features Create nodes with different rates Run all nodes When to Use Multi-Process vs Single-Process Multi-Process (Concurrent Execution) Single-Process Performance Notes Multi-Process IPC Performance Single-Process Performance Testing Multi-Node Systems Next Steps","category":"general"},{"id":13,"title":"Architecture Overview","description":"Complete technical architecture of the HORUS framework","slug":"/concepts/architecture","content":"Architecture Overview HORUS is a modern robotics framework built on Rust, shared memory IPC, and deterministic scheduling. This document provides a comprehensive overview of the system architecture, core components, and how they work together. System Architecture Core Components 1. horus (Unified Crate) The main entry point for all HORUS applications. Provides a unified API that abstracts the complexity of the framework. Key Exports: - Node trait: Base interface for all robotics nodes - Hub<T: Type-safe pub/sub communication - Scheduler: Priority-based node orchestration - prelude::: Unified imports for all essential types Usage: Location: /horus/ 2. horuscore (Framework Engine) The heart of the HORUS framework. Implements all core functionality including communication, scheduling, and memory management. Modules: communication/ - hub.rs: Generic Hub<Timplementation with backend abstraction - horusbackend.rs: Shared memory IPC with serde serialization (248ns-437ns) - message.rs: Message trait and safety primitives scheduling/ - scheduler.rs: Priority-based deterministic scheduler - node.rs: Node trait, NodeInfo, lifecycle management - Priority ordering: Lower number = higher priority (0 = highest) core/ - logbuffer.rs: SharedLogBuffer - ring buffer for cross-process logging - 5000 entries × 512B - Lock-free writes with atomic counters - Stored in platform-specific path (Linux: /dev/shm/, macOS: /tmp/, Windows: %TEMP%) - registry.rs: Node registry for monitoring and discovery memory/ - shm.rs: Cross-platform shared memory abstraction - platform.rs: Platform-specific path detection (Linux, macOS, Windows) - alignment.rs: Safe cross-process memory alignment Other: - params.rs: Global parameter storage - error.rs: Comprehensive error types - backend.rs: Backend trait for pluggable communication Performance: - CmdVel (16B): 437ns (Hub) / 248ns (Link) - IMU (304B): 940ns (Hub) - Odometry (736B): 1.1μs (Hub) - LaserScan (1.5KB): 2.2μs (Hub) - PointCloud (120KB): 360μs (Hub)","headings":"Architecture Overview System Architecture Core Components 1. horus (Unified Crate) 2. horuscore (Framework Engine) communication/ scheduling/ core/ memory/ Other: 3. horusmacros (Code Generation) node! - Zero-Boilerplate Node Definition 4. horusmanager (CLI & Package Management) Project Management Package Management Authentication Monitoring (via monitor) Alternative: CLI monitoring (if available) 5. horuslibrary (Standard Library) 6. Multi-Language Bindings horuspy (Python Support) Communication Architecture Shared Memory IPC Communication System Scheduling Architecture Priority-Based Execution Tick Rate Limitation Logging System SharedLogBuffer Architecture Package Management Registry Architecture 1. Authenticate Opens browser  GitHub OAuth  Stores token 2. Create package 3. Develop 4. Publish Uploads to registry with Git metadata 5. Install (on another machine) Downloads, caches, builds Monitoring & Monitor Real-Time System Monitoring Memory Safety Guarantees Rust Advantages Build System & Workspace Cargo Workspace Structure Development (fast compile) Release (optimized) Rust Project Compilation Data Flow Example Complete Message Flow When to Use Each Component Performance Characteristics Latency vs Message Size Comparison to traditional frameworks Next Steps","category":"concepts"},{"id":14,"title":"Communication Configuration","description":"Managing endpoints with configuration files","slug":"/concepts/communication-configuration","content":"Communication Configuration Managing endpoints through configuration files makes your code environment-agnostic and easier to deploy across development, staging, and production environments. Why Use Configuration Files? Without configuration (hardcoded): With configuration (environment-agnostic): Configuration File Formats HORUS supports both TOML and YAML formats: TOML Format horus.toml: YAML Format horus.yaml: Configuration Search Path HORUS searches for configuration files in this order: 1. ./horus.toml or ./horus.yaml (current directory) 2. /.horus/config.toml or /.horus/config.yaml (user home) 3. /etc/horus/config.toml or /etc/horus/config.yaml (system-wide) Priority: Files earlier in the search path override later ones. Loading from Configuration Hub from Config Link from Config Environment-Specific Configurations Development Environment horusdev.toml: Production Environment horusprod.toml: Switching Environments Method 1: Symlink Method 2: Environment Variable Complete Example Configuration File horus.toml: Application Code Advanced Configuration Per-Environment Overrides horus.toml (base config): horuslocal.toml (local override): Robot-Specific Configs robot1config.toml: robot2config.toml: Multi-Environment Testing horustest.toml: Configuration Management Best Practices 1. Version Control 2. Environment Templates horus.template.toml: 3. Deployment Scripts deploy.sh: 4. Configuration Validation Configuration for Different Scenarios Scenario 1: Development (Local Only) horusdev.toml: Scenario 2: Lab Testing (Local Network) horuslab.toml: Scenario 3: Field Deployment (Production) horusfield.toml: Scenario 4: Multi-Robot Fleet horusfleet.toml: Troubleshooting Config File Not Found Error: Failed to load configuration: file not found Solution: Hub/Link Not Found in Config Error: Hub 'telemetry' not found in configuration Solution: Invalid Endpoint Syntax Error: Invalid endpoint: telemetry@invalid:port Solution: Summary Benefits of Configuration Files: - Environmen","headings":"Communication Configuration Why Use Configuration Files? Configuration File Formats TOML Format YAML Format Configuration Search Path Loading from Configuration Hub from Config Link from Config Environment-Specific Configurations Development Environment Local shared memory for development Production Environment Network endpoints for production Switching Environments Development Production Development Production Complete Example Configuration File ======= ROBOT CONFIGURATION ======= Network telemetry to ground station Network camera to processing server Local motor control (critical path - must be local!) Local IMU (critical path) Network fleet coordination Application Code Advanced Configuration Per-Environment Overrides Robot-Specific Configs Deploy robot 1 Deploy robot 2 Multi-Environment Testing Simulate network delays locally for testing Run with test config Configuration Management Best Practices 1. Version Control Track all config files .gitignore sensitive production configs 2. Environment Templates Template configuration - copy and customize Setup new deployment Edit horus.toml with actual IPs 3. Deployment Scripts Deploy robot configuration Copy environment-specific config Deploy and run Deploy to staging Deploy to production 4. Configuration Validation Configuration for Different Scenarios Scenario 1: Development (Local Only) Scenario 2: Lab Testing (Local Network) Scenario 3: Field Deployment (Production) Scenario 4: Multi-Robot Fleet Central router for fleet coordination Local control for each robot Troubleshooting Config File Not Found Check current directory Check user config Check system config Create config Hub/Link Not Found in Config Verify hub name matches config Check TOML syntax Invalid Endpoint Syntax Correct endpoint formats Summary Next Steps","category":"concepts"},{"id":15,"title":"Communication Patterns Overview","description":"Understanding Hub vs Link communication patterns in HORUS","slug":"/concepts/communication-overview","content":"Communication Patterns Overview HORUS provides two fundamental communication patterns for different use cases. Understanding when to use each pattern is key to building efficient robotics systems. Two Core Patterns Hub: Many-to-Many Pub/Sub (MPMC) Pattern: Multiple publishers → Multiple subscribers Use Case: Broadcasting, flexible topologies, logging Semantics: Buffered queue, all messages delivered Link: Point-to-Point (SPSC) Pattern: One producer → One consumer Use Case: Control loops, critical paths, 1P1C pipelines Semantics: Single-slot, latest value only Decision Matrix Use Hub (MPMC) Multiple subscribers All messages buffered 481ns &lt;50µs Broadcasting, monitoring Dynamic, flexible Every message matters Key Differences 1. Message Semantics Hub (Buffering): - Messages are queued - All messages are delivered to all subscribers - If buffer fills, oldest messages dropped - Perfect for: Logging, event streams, commands Link (Latest Value): - Single slot, always overwrites - Consumer gets latest value only - Older unread values are lost - Perfect for: Sensor readings, state updates, control signals 2. Performance Hub: - 481ns latency (local shared memory) - &lt;50µs latency (network) - Slightly slower due to MPMC coordination Link: - 248ns latency (local shared memory) - 5-15µs latency (network) - Faster due to SPSC optimization (no contention) 3. Topology Flexibility Hub: Link: When to Use Hub Broadcasting to multiple nodes Logging and monitoring Event-driven systems Flexible topologies - Number of subscribers unknown at compile time - Nodes can join/leave during runtime - Pub/sub pattern from ROS/MQTT/DDS When to Use Link Control loops (high-frequency, latency-critical) Point-to-point pipelines Latest-value semantics Deterministic real-time systems - Fixed topology known at compile time - Predictable latency critical - Hard real-time requirements Hybrid Patterns You can combine both patterns in the same system: Design principle: Use Link for the critical path, Hu","headings":"Communication Patterns Overview Two Core Patterns Hub: Many-to-Many Pub/Sub (MPMC) Link: Point-to-Point (SPSC) Decision Matrix Key Differences 1. Message Semantics 2. Performance 3. Topology Flexibility When to Use Hub When to Use Link Hybrid Patterns Common Patterns 1. Sensor Fusion 2. Command Distribution 3. Pipeline Processing Transport Independence Summary Next Steps","category":"concepts"},{"id":16,"title":"Communication Transport Overview","description":"Local vs Network transport mechanisms in HORUS","slug":"/concepts/communication-transport","content":"Communication Transport Overview HORUS supports two transport mechanisms: local shared memory and network communication. Both Hub and Link work transparently with either transport. Transport vs Pattern Important distinction: - Pattern (Hub vs Link): How nodes communicate (MPMC vs SPSC) - Transport (Local vs Network): Where nodes communicate (same machine vs distributed) You can use any pattern with any transport: Local Transport Hub::new(\"topic\") Link::producer(\"topic\") Two Transport Mechanisms Local: Shared Memory What: Linux shared memory (/dev/shm) for same-machine IPC When: All nodes running on the same computer Latency: Ultra-fast (248ns Link, 481ns Hub) How it works: - Memory region in RAM accessible by all processes - Zero-copy (no serialization) - Lock-free atomic operations - Cache-aligned for performance Network: TCP/UDP What: Network sockets for multi-machine communication When: Nodes distributed across multiple computers Latency: Very fast (5-15µs Link, &lt;50µs Hub) How it works: - TCP (Link): Reliable, ordered, connection-oriented - UDP (Hub): Connectionless, efficient for pub/sub - Binary serialization (bincode) - Async I/O for low latency Performance Comparison Latency Link (SPSC) Use Case 248ns Same machine, ultra-low latency Network &lt;50µs 20-60x Acceptable for distributed systems Aspect Network Max Nodes Limited by network topology Max Throughput 100MB/sec (1Gbps LAN) Latency Variance 1-10ms jitter (WiFi) Reliability 99.9%+ (LAN), lower on WiFi | When to Use Local Transport Single-machine systems Development and testing Ultra-low latency requirements High-bandwidth data Local Transport Benefits - Fastest possible: 248ns-481ns latency - Zero-copy: No serialization overhead - Deterministic: Predictable, no network jitter - Simple: No network configuration - Reliable: No packet loss or connection issues Local Transport Limitations - Same machine only: All nodes must run on same computer - Limited by RAM: Shared memory uses system RAM - No fault iso","headings":"Communication Transport Overview Transport vs Pattern Two Transport Mechanisms Local: Shared Memory Network: TCP/UDP Performance Comparison Latency Throughput Scalability When to Use Local Transport Local Transport Benefits Local Transport Limitations When to Use Network Transport Network Transport Benefits Network Transport Limitations Hybrid Deployments Example: Drone with Ground Station Automatic Transport Selection Performance Guidelines Message Size Considerations Frequency Guidelines Reliability Considerations Local Shared Memory Network Reliability Best Practices Configuration Management horus.toml Summary Local Shared Memory Network Next Steps","category":"concepts"},{"id":17,"title":"Core Concepts - Hub","description":"Understanding HORUS pub/sub communication system","slug":"/concepts/core-concepts-hub","content":"Hub and Pub/Sub Key Takeaways After reading this guide, you will understand: - How Hub provides zero-copy, lock-free pub/sub communication with sub-microsecond latency (248ns-437ns) - The send() and recv() methods for publishing and subscribing to typed topics - Communication patterns (one-to-one, one-to-many, many-to-one, many-to-many) for different architectures - How shared memory in /dev/shm enables processes to communicate without serialization - When to use Hub for real-time, single-machine communication vs network-based messaging The Hub is HORUS's ultra-low latency publish-subscribe (pub/sub) communication system. It enables nodes to exchange messages through shared memory IPC with 248ns-437ns latency (Link/Hub). What is a Hub? A Hub<Tis a typed communication channel that connects publishers and subscribers through shared memory. Multiple nodes can publish to the same topic, and multiple nodes can subscribe to the same topic. Key Features Zero-Copy Communication: Messages are written directly to shared memory without serialization Lock-Free Operations: Atomic operations for thread-safe communication without locks Type Safety: Compile-time guarantees for message types Cache-Aligned: Optimized memory layout prevents false sharing Sub-Microsecond Latency: 248ns (Link) / 437ns (Hub) for small messages (16B) Linear Scaling: Latency scales linearly with message size Basic Usage Creating a Hub The generic type T must implement: - Clone: For copying data - Debug: For logging - Send: For thread safety Publishing Messages Subscribing to Messages Transport Options Hub supports both local and network transports transparently: Local Shared Memory (Default) Performance: 481ns latency Use case: All nodes on same machine Pros: Ultra-fast, deterministic, zero-copy Network Communication Performance: &lt;50µs latency Use case: Nodes distributed across multiple machines Pros: Multi-machine, fault isolation, scalable Important: The Hub pattern (MPMC pub/sub) works identically wi","headings":"Hub and Pub/Sub Key Takeaways What is a Hub? Key Features Basic Usage Creating a Hub Publishing Messages Subscribing to Messages Transport Options Local Shared Memory (Default) Network Communication Hub Architecture Memory Layout Shared Memory Topic Send and Receive The send() Method The recv() Method Connection States Checking Connection State State Transitions Performance Metrics Accessing Metrics Communication Patterns One-to-One One-to-Many (Broadcast) Many-to-One (Aggregation) Many-to-Many Topic Naming Use Dots, Not Slashes Best Practices Reserved Topic Names Error Handling Send Errors Receive Errors Type Constraints Valid Message Types Invalid Message Types Advanced Usage Conditional Publishing Message Buffering Rate Limiting Message Filtering Shared Memory Details Location View HORUS shared memory segments Size Limitations Cleaning Up Remove all HORUS shared memory Performance Characteristics Latency by Message Size Throughput Performance Benchmarks Best Practices Use Appropriate Types Minimize Cloning Check recv() Every Tick Handle Send Failures Next Steps","category":"concepts"},{"id":18,"title":"Core Concepts - Link","description":"Understanding HORUS ultra-low latency point-to-point communication","slug":"/concepts/core-concepts-link","content":"Link and Point-to-Point Communication Link is HORUS's ultra-low latency Single Producer Single Consumer (SPSC) communication system. It enables two nodes to exchange messages through shared memory with 248ns round-trip latency - 1.94x faster than Hub. What is a Link? A Link<Tis a typed point-to-point channel that connects exactly one producer to exactly one consumer through lock-free shared memory. Link is optimized for the tightest control loops where every nanosecond counts. Key Features Ultra-Low Latency: 248ns round-trip (vs 481ns for Hub) - the fastest IPC primitive in HORUS Lock-Free SPSC: Single Producer Single Consumer queue with no locks or atomic contention Zero-Copy: Messages written directly to shared memory without serialization Cache-Optimized: False sharing eliminated through careful memory alignment Type Safety: Compile-time type checking for message types Predictable Performance: No head-of-line blocking, no subscriber variability Basic Usage Creating a Link Links have explicit roles - you create either a producer or consumer: Sending Messages Receiving Messages Transport Options Link supports both local and network transports transparently: Local Shared Memory (Default) Performance: 248ns latency Use case: All nodes on same machine Pros: Ultra-fast, deterministic, zero-copy Network Communication Performance: 5-15µs latency (3-10x faster than Hub network!) Use case: Nodes distributed across multiple machines Pros: Multi-machine, fault isolation, still very fast Important: The Link pattern (SPSC point-to-point) works identically with both transports - only the endpoint syntax changes! See Communication Transport for detailed comparison and Network Communication for multi-machine setup. Link vs Hub Link (SPSC) 248ns 1 producer 1 consumer Control loops, critical paths Lower (no coordination) 1.94x faster When to Use Link Control loops running at &gt;100Hz where latency matters Point-to-point communication with fixed topology Critical paths in your data","headings":"Link and Point-to-Point Communication What is a Link? Key Features Basic Usage Creating a Link Sending Messages Receiving Messages Transport Options Local Shared Memory (Default) Network Communication Link vs Hub When to Use Link When to Use Hub How Link Works Internally Memory Layout Single-Slot Design Why Single-Slot is Fast Performance Characteristics Latency by Message Size Throughput Common Patterns 1. Control Loop Pipeline 2. Sensor Data Flow 3. Metrics and Monitoring Error Handling Send Always Succeeds No Messages Available Debugging Tips Check Metrics Enable Logging Common Issues Comparison with Other IPC Best Practices Example: Drone Flight Controller Summary","category":"concepts"},{"id":19,"title":"Core Concepts - Nodes","description":"Understanding HORUS nodes and their lifecycle","slug":"/concepts/core-concepts-nodes","content":"Nodes and Lifecycle Key Takeaways After reading this guide, you will understand: - How nodes are self-contained units of computation that run in the scheduler - The Node trait's lifecycle methods (init, tick, shutdown) and when each is called - How NodeInfo provides logging, metrics, and timing context to your nodes - When to use different priority levels (0 for safety-critical, 100 for background logging) - Communication patterns (publisher, subscriber, pipeline, aggregator) for building node graphs Nodes are the fundamental building blocks of HORUS applications. Every component in your robotics system is a node - sensors, actuators, controllers, filters, and more. What is a Node? A node is a self-contained unit of computation that runs in the HORUS scheduler. Nodes communicate with each other through the Hub pub/sub system using shared memory IPC. Key Characteristics Lifecycle Management: Nodes have explicit initialization, execution, and shutdown phases Priority-Based Execution: Nodes run in priority order every tick cycle Zero Boilerplate: The node! macro generates all necessary boilerplate code Type-Safe Communication: Compile-time guarantees for message passing Memory Safety: Written in Rust with zero unsafe code in user-facing APIs The Node Trait Every HORUS node implements the Node trait: Required Methods name(): Returns a static string identifying the node tick(): Main execution loop called repeatedly by the scheduler Optional Methods init(): Called once during node startup (default: no-op) shutdown(): Called once during graceful shutdown (default: no-op) getpublishers(): Returns list of published topics (default: empty) getsubscribers(): Returns list of subscribed topics (default: empty) Node Lifecycle Nodes transition through well-defined states during their lifetime: Lifecycle States Uninitialized: Node created but not added to scheduler Initializing: Running init() method Running: Executing tick() in main loop Paused: Temporarily suspended (future featu","headings":"Nodes and Lifecycle Key Takeaways What is a Node? Key Characteristics The Node Trait Required Methods Optional Methods Node Lifecycle Lifecycle States State Transitions Lifecycle Example NodeInfo Context Structure Logging Methods Pub/Sub Logging (Automatic) Performance Metrics Timing Methods Node Priority Priority Levels Priority Usage Priority Guidelines Creating Nodes Manual Implementation Using the node! Macro Node Communication Patterns Publisher Pattern Subscriber Pattern Pipeline Pattern Aggregator Pattern Best Practices Keep tick() Fast What to Include in init() What to Include in shutdown() Complete Custom Node Example When init() and shutdown() Are NOT Optional Use Result Types Check ctx Before Logging Avoid State in Static Variables Error Handling Initialization Errors Runtime Errors Shutdown Errors Advanced Topics Conditional Execution State Machines Multi-Topic Synchronization Graceful Shutdown & Motor Safety Signal Handling Why shutdown() Matters for Motors Built-in Node Shutdown Behavior Sensor and Bus Nodes Implementing shutdown() in Custom Nodes Testing Shutdown Behavior Start your application In another terminal, send SIGINT Or simply press Ctrl+C in the application terminal Best Practices for Shutdown Next Steps","category":"concepts"},{"id":20,"title":"Core Concepts - Scheduler","description":"Understanding HORUS priority-based scheduler and execution orchestration","slug":"/concepts/core-concepts-scheduler","content":"Scheduler Key Takeaways After reading this guide, you will understand: - How the Scheduler orchestrates node execution through init(), tick(), and shutdown() phases - Why priority-based execution ensures safety-critical nodes run first every tick cycle - The default 60 FPS tick rate and how nodes execute in sorted priority order - Graceful shutdown via Ctrl+C signal handling without losing data - When to use different priority levels (0=Critical for emergency stops, 100=Background for logging) The Scheduler is the execution orchestrator in HORUS. It manages the node lifecycle, coordinates priority-based execution, and handles graceful shutdown. What is the Scheduler? The Scheduler is responsible for: Node Registration: Adding nodes to the scheduler Lifecycle Management: Calling init(), tick(), and shutdown() at the right times Priority-Based Execution: Running nodes in priority order every tick Signal Handling: Graceful shutdown on Ctrl+C Performance Monitoring: Tracking execution metrics for all nodes Error Recovery: Handling node errors without crashing the system Basic Usage Creating a Scheduler Adding Nodes Running the Scheduler Scheduler Architecture Internal Structure nodes: Vector of registered nodes with their contexts running: Atomic flag for graceful shutdown tickratefps: Target execution rate (default: 60 FPS) Execution Flow Tick Rate Limitation Important: HORUS currently has a hardcoded 60 FPS tick rate (16ms per tick cycle). What this means: - The tickratefps field is set to 60 and cannot be changed in the current version - Each complete tick cycle (all nodes execute once) takes approximately 16ms - Maximum achievable frequency: 60 Hz - This is enforced by a sleep at the end of each tick cycle Implications for your nodes: Workaround for higher frequencies: Run nodes in separate processes with their own schedulers. Each process can independently achieve 60 Hz. Future: Configurable per-node tick rates and removal of the global 60 FPS limit are planned for","headings":"Scheduler Key Takeaways What is the Scheduler? Basic Usage Creating a Scheduler Adding Nodes Running the Scheduler Scheduler Architecture Internal Structure Execution Flow Tick Rate Limitation Process 1: High-frequency sensor (60 Hz max) Process 2: Normal controller (60 Hz max) Both run at 60 Hz independently Priority-Based Execution Priority Levels Execution Order Why Priority Matters Priority Best Practices Lifecycle Management Initialization Phase Main Execution Loop Shutdown Phase Tick Rate Control Default Tick Rate Tick Rate Considerations Running Modes Continuous Mode (run) Node-Specific Execution Signal Handling Ctrl+C Handling Graceful Shutdown Error Handling Initialization Errors Runtime Errors Shutdown Errors Performance Monitoring Accessing Node Metrics Built-in Logging Advanced Usage Dynamic Node Registration Conditional Execution Multi-Scheduler Systems Best Practices Initialize Heavy Resources in init() Keep tick() Fast Use Appropriate Priorities Handle Errors Gracefully Monitor Performance Common Patterns Layered Architecture Feedback Loops Pipeline Processing Troubleshooting Scheduler Not Stopping Nodes Not Running Slow Execution Next Steps","category":"concepts"},{"id":21,"title":"Core Concepts - Shared Memory","description":"Understanding HORUS shared memory IPC architecture","slug":"/concepts/core-concepts-shared-memory","content":"Shared Memory IPC HORUS achieves 248ns-2.8µs latency through a zero-copy shared memory IPC architecture. This page explains how HORUS uses platform-specific shared memory for ultra-low latency inter-process communication. Cross-Platform Support: Shared Memory Path /dev/shm/horus/ /tmp/horus/ %TEMP%\\horus\\ What is Shared Memory IPC? Shared memory is a region of RAM that multiple processes can access simultaneously. Unlike network-based communication (TCP/UDP) or message queues, shared memory: Eliminates serialization: No conversion to/from bytes Eliminates copying: Data written once, read directly Enables zero-copy semantics: Loan pattern for minimal allocations Provides deterministic latency: No network stack overhead Scales linearly: Latency proportional to message size Architecture Overview Storage Location HORUS stores shared memory segments in platform-specific directories using a flat namespace (like ROS): Linux: macOS: Windows: All processes on the same machine share the same topic namespace. This is simple and familiar to ROS developers. Why platform-specific paths? RAM-backed: Stored in RAM (or tmpfs on macOS), not disk Fast access: Direct memory operations Kernel-managed: Operating system handles memory mapping Cross-platform: Auto-detected at compile time Simple cleanup: Use horus clean --shm or delete the directory Flat Namespace Design (ROS-like) HORUS uses a flat topic namespace like ROS. All processes on the same machine share the same topics: Result: Both processes automatically communicate. No configuration needed! Why Flat Namespace? Description No session IDs to configure ROS familiarity ls /dev/shm/horus/topics/ shows all topics Multi-process by default Topic Isolation (When Needed) If you need topic isolation between projects, use topic prefixes (like ROS namespaces): This creates separate topics: - /dev/shm/horus/topics/horusrobotarmcmdvel - /dev/shm/horus/topics/horusmobilerobotcmdvel File Naming Convention Shared memory topics follow this nami","headings":"Shared Memory IPC What is Shared Memory IPC? Architecture Overview Storage Location Flat Namespace Design (ROS-like) Terminal 1: Robot controller Terminal 2: GUI monitor (same topic!) Why Flat Namespace? Topic Isolation (When Needed) File Naming Convention ShmRegion: Memory-Mapped Files What is ShmRegion? Structure Creating a Region Opening Existing Region Ownership ShmTopic: Lock-Free Ring Buffer (Internal) Zero-Copy Loan Pattern (Internal) Lock-Free Operations (Internal) Multi-Consumer Architecture How Multiple Subscribers Work Buffer Fill Management Safety Features Comprehensive Bounds Checking Capacity Limits Type Safety Performance Optimizations Cache-Line Alignment Atomic Operations Zero-Copy Semantics Hub Integration Managing Shared Memory Viewing Active Topics Linux macOS Example output: -rw-r--r-- 1 user user 4.0K Oct 5 12:34 horuscmdvel -rw-r--r-- 1 user user 8.0K Oct 5 12:34 horuslaserscan Checking Available Space Linux macOS (check temp space) Example output (Linux): Filesystem      Size  Used Avail Use% Mounted on tmpfs           7.8G  128M  7.7G   2% /dev/shm Manual Cleanup Using HORUS CLI (recommended) Or manually remove the directory Monitoring Memory Usage Watch memory usage in real-time Show per-topic sizes Platform Considerations Linux Check current size Increase to 4GB (requires sudo) Make permanent (add to /etc/fstab): tmpfs /dev/shm tmpfs defaults,size=4G 0 0 macOS Check shared memory Check available space Windows Check shared memory View temp directory location Inside WSL, HORUS uses Linux's /dev/shm/ Best Practices Understanding Capacity vs Memory Size High-Level API: Message Capacity Low-Level API: Direct Memory Size Calculating Memory Requirements From Messages to Bytes From MB to Message Capacity Memory Size Examples System Limits Choosing Memory Configuration By Message Count (Recommended) By Memory Budget Rule of Thumb Calculations Choose Appropriate Capacity Monitor Buffer Utilization Handle Buffer Full Errors Clean Up Regularly Troubleshooting \"No space left on device\" Check usage Clean up (HORUS auto-cleans sessions, but manual cleanup helps if full) Or increase size Check usage Clean up Clean up \"Permission denied\" Check permissions (Linux) Check permissions (macOS) Fix permissions (if needed) Stale Shared Memory Using HORUS CLI Or manually: Linux macOS Windows \"Element size mismatch\" Multi-Process Communication Automatic Topic Sharing Running Multi-Process Applications Terminal 1 - Backend Terminal 2 - GUI (same topic names = automatic communication) Topic Isolation (When Needed) Real-World Example: Snake Game Terminal 1 - Backend Terminal 2 - GUI (same topics = automatic communication) Next Steps","category":"concepts"},{"id":22,"title":"Core Concepts","description":"Understanding HORUS architecture and IPC backends","slug":"/concepts/core","content":"Core Concepts HORUS provides multiple IPC backends, each optimized for different use cases. All backends share a common API, allowing backends to be changed without modifying application code. Architecture Overview Communication System Hub (Topic-Based Pub/Sub) Production-Grade Message Passing - Latency: 248ns-437ns (Link/Hub) for production messages - Use case: All robotics applications - control, sensing, perception - Message Types: CmdVel (500ns Hub / 248ns Link), IMU (940ns Hub), LaserScan (2.2µs Hub), Odometry (1.1µs Hub) Production Performance Real Message Latencies (with serde serialization): Size Link Latency 16 B 248 ns 304 B 400 ns 1.5 KB 900 ns 736 B 600 ns 120 KB 120 µs See Benchmarks for complete performance analysis. Efficient Shared Memory HORUS uses shared memory for fast IPC: 1. Efficient serialization with serde + bincode 2. Shared memory ring buffers for message passing 3. Lock-free operations where possible 4. Fixed-size message structures for safety Message Safety HORUS messages are memory-safe by design: - Fixed-size arrays instead of Vec for shared memory - [repr(C)] for consistent memory layout - Serde for safe serialization - No heap allocation in hot paths Next Steps - Installation - Get HORUS installed - Quick Start - Build your first HORUS node - Benchmarks - Production performance analysis - Examples - Real-world robotics applications","headings":"Core Concepts Architecture Overview Communication System Hub (Topic-Based Pub/Sub) Production Performance Efficient Shared Memory Message Safety Next Steps","category":"concepts"},{"id":23,"title":"Goals & Vision","description":"What HORUS is trying to achieve and the problems it solves","slug":"/concepts/goals","content":"Goals & Vision What is HORUS Trying to Achieve? HORUS aims to become the de facto standard for real-time robotics communication by providing an ultra-low latency, memory-safe, and developer-friendly framework that bridges the gap between research prototyping and production deployment. Core Objectives Sub-Microsecond Communication: Achieve 248ns-437ns latency for robotics messages, enabling real-time control loops at 1kHz+ frequencies Zero Compromise Performance: Deliver 100-270x faster performance than traditional frameworks without sacrificing safety or ease of use Memory Safety by Default: Leverage Rust's type system to eliminate entire classes of bugs common in C++ robotics frameworks Unified High-Level Workflow: Single command for build, run, and deployment across Rust and Python with minimal configuration (simple horus.yaml vs complex ROS XML) Dependency Isolation: Solve dependency hell with portable, isolated environments and reproducible builds Developer Experience First: From prototype to production without friction - auto-detect, auto-install, just run Problems HORUS Solves High IPC Latency in Traditional Frameworks Problem: Traditional middleware introduces 50-500µs of latency, which is too slow for high-frequency control loops required in modern robotics. HORUS Solution: - Shared memory architecture with zero-copy semantics - 248ns (Link) / 500ns (Hub) for CmdVel (16B messages) - 900ns (Link) / 2.2µs (Hub) for LaserScan (1.5KB messages) - Linear scaling with message size Impact: Enables 1kHz+ control loops for precise manipulation, high-speed drones, and real-time sensor fusion. Memory Safety Issues Problem: C++ frameworks are prone to memory leaks, use-after-free, data races, and segmentation faults that cause robot crashes in production. HORUS Solution: - Written in Rust with zero unsafe code - Fixed-size message structures prevent heap allocation bugs - Compile-time guarantees for thread safety and memory safety Impact: Drastically reduces debugging ti","headings":"Goals & Vision What is HORUS Trying to Achieve? Core Objectives Problems HORUS Solves High IPC Latency in Traditional Frameworks Memory Safety Issues Dependency Hell and \"Works On My Machine\" Complex Build and Runtime Management Poor Developer Experience Reinventing the Wheel Every Project Sharing Across Developers & Organizations Publish your package to the registry Others can discover it And install it in one command Team A builds and publishes a SLAM node Published: slam-cartographer v1.0.0 Install: horus pkg install slam-cartographer Team B discovers and uses it weeks later slam-cartographer  1.0.0  SLAM using cartographer  234  ⬇5.2k Use it directly in their code Lack of Multi-Language Support Cons HORUS Avoids Robotics Scenarios That Benefit from HORUS High-Speed Manipulation Drone Control & Stabilization Collaborative Robots (Cobots) Autonomous Vehicles Industrial Automation Research Prototyping Teleoperation & Haptics Multi-Robot Systems When NOT to Use HORUS The HORUS Vision","category":"concepts"},{"id":24,"title":"HFrame Transform System","description":"Lock-free coordinate frame management","slug":"/concepts/hframe","content":"HFrame Transform System HFrame is a lock-free coordinate frame system for real-time robotics applications. Performance HFrame 50ns 200ns 150ns Usage Configuration Presets Frames 256 1024 4096 Transform Type Time-Travel Queries","headings":"HFrame Transform System Performance Usage Configuration Presets Transform Type Time-Travel Queries","category":"concepts"},{"id":25,"title":"Hybrid Nodes & Processors","description":"Inject custom processing logic into HORUS nodes","slug":"/concepts/hybrid-nodes","content":"Hybrid Nodes & Processors HORUS nodes support a hybrid pattern that allows them to function as both hardware drivers AND customizable processing pipelines. This enables injecting user-defined processing logic without modifying node source code. Key Concepts - Zero-config default: Nodes work out-of-box as pure drivers - Optional customization: Inject processing via closures or traits - Type-safe: Compile-time guarantees for processor compatibility - Minimal overhead: No runtime cost when using defaults (monomorphization) - Ergonomic API: Simple closure-based or trait-based hooks The Processor Trait The core abstraction is the Processor trait: Basic Usage Default Mode (No Processing) With Inline Closure With Filter (Conditional Output) With Custom Processor Struct Builder Pattern Many hybrid nodes support a builder pattern for configuration: Processing Pipelines Chain multiple processors together using pipe(): Built-in Processor Types PassThrough (Default) No-op processor that passes data unchanged: ClosureProcessor Wraps a closure as a processor: FilterProcessor Closure that can skip outputs: Pipeline Chains two processors sequentially: Tap Runs a side-effect without modifying data: Extension Methods The ProcessorExt trait adds fluent methods: Hybrid Nodes in horuslibrary Many built-in nodes support the hybrid pattern: Sensor Nodes Navigation Nodes Control Nodes Lifecycle Hooks Processors can implement lifecycle methods: Helper Functions Convenience functions for creating processors: Example: Complete Vision Pipeline Performance Considerations The hybrid pattern uses Rust's monomorphization, so: - Default PassThrough: Zero overhead (optimized away) - Closures: Inlined when possible - Trait objects: Minimal vtable overhead - Pipelines: Flattened at compile time See Also - Core Concepts - Nodes - Node basics - Visual Odometry - Example hybrid node - Camera Node - Camera with processing - API Reference - Full API documentation","headings":"Hybrid Nodes & Processors Key Concepts The Processor Trait Basic Usage Default Mode (No Processing) With Inline Closure With Filter (Conditional Output) With Custom Processor Struct Builder Pattern Processing Pipelines Built-in Processor Types PassThrough (Default) ClosureProcessor FilterProcessor Pipeline Tap Extension Methods Hybrid Nodes in horuslibrary Sensor Nodes Navigation Nodes Control Nodes Lifecycle Hooks Helper Functions Example: Complete Vision Pipeline Performance Considerations See Also","category":"concepts"},{"id":26,"title":"Core Concepts","description":"Fundamental HORUS concepts and architecture","slug":"/concepts","content":"Core Concepts Understanding the fundamental concepts behind HORUS. Overview - What is HORUS? - Introduction to the framework - Architecture - System design and components - Goals - Design philosophy and objectives Core Components - Nodes - Computational units - Hub - Multi-producer multi-consumer pub/sub - Link - Point-to-point communication - Scheduler - Execution orchestration - Shared Memory - Zero-copy IPC Communication - Overview - Communication patterns - Configuration - Transport setup - Network - Distributed communication Advanced Concepts - Robot Architectures - Common robot patterns - Multi-Language - Rust + Python integration","headings":"Core Concepts Overview Core Components Communication Advanced Concepts","category":"concepts"},{"id":27,"title":"message! Macro","description":"Define custom message types with zero boilerplate","slug":"/concepts/message-macro","content":"message! Macro The message! macro provides a zero-boilerplate way to define custom message types in HORUS. With a single line, you get a fully-functional message type with all necessary traits implemented automatically. Why Use message!? The Problem Before the message! macro, defining a custom message required manual implementation: That's 15+ lines for a simple 2-field message! The Solution With message!, it's just one line: Done! You get the same functionality with 98% less code. Basic Usage Tuple-Style Messages (Recommended for Simple Types) Perfect for messages with 2-4 fields: Struct-Style Messages (For Complex Types) Use for messages with many fields or when field names improve clarity: What Gets Generated? For every message! invocation, HORUS automatically generates: 1. The Struct Definition 2. LogSummary Implementation 3. Full Hub/Link Compatibility Your message immediately works with all HORUS communication: Complete Example The following example demonstrates a temperature monitoring system: Advanced Features Using Tuple Fields Access tuple fields by index: Using Struct Fields Access struct fields by name: Logging Output The auto-generated LogSummary produces clean output: For large messages (like sensor data), this avoids expensive clones during logging. When to Use Each Style Use Tuple-Style When: - 2-4 fields that are related - Simple data like coordinates, colors, velocities - Field order is obvious (x/y, r/g/b, etc.) Use Struct-Style When: - 5+ fields that need names - Complex data where names improve clarity - Mixed types that aren't obviously ordered Comparison with Library Types HORUS library messages (like CmdVel, Image) already have custom LogSummary implementations for optimal performance: For most custom messages, the auto-generated LogSummary is sufficient. Override only when special formatting is needed for large data structures. Best Practices 1. Import Once Add these imports at the top of your file: 2. Define Messages Near Usage Keep message","headings":"message! Macro Why Use message!? The Problem The Solution Basic Usage Tuple-Style Messages (Recommended for Simple Types) Struct-Style Messages (For Complex Types) What Gets Generated? 1. The Struct Definition 2. LogSummary Implementation 3. Full Hub/Link Compatibility Complete Example Advanced Features Using Tuple Fields Using Struct Fields Logging Output When to Use Each Style Use Tuple-Style When: Use Struct-Style When: Comparison with Library Types Best Practices 1. Import Once 2. Define Messages Near Usage 3. Use Descriptive Names 4. Consider Field Order Common Patterns Timestamped Messages Status Messages Command Messages Limitations Cannot Override Pod/Zeroable Must Import LogSummary Summary Next Steps","category":"concepts"},{"id":28,"title":"Message Types","description":"Standard HORUS message types for robotics applications","slug":"/concepts/message-types","content":"Message Types HORUS provides a comprehensive library of standard message types for robotics applications. All messages are designed for shared memory efficiency with fixed-size structures and zero-copy semantics. Message Requirements All HORUS messages must implement: Required traits: - Clone: For shared memory operations - Debug: For logging and debugging - Serialize/Deserialize: For optional serialization Best practices: - Use fixed-size arrays instead of Vec - Prefer f32/f64 over variable-length types - Include timestamp fields for all time-sensitive data - Use [repr(C)] for C interop Typed Messages vs Generic Messages HORUS supports two fundamentally different approaches to messaging, each with distinct performance and usability tradeoffs. 1. Typed Messages (Recommended) What: Strongly-typed Rust structs that implement Serialize, Deserialize, and LogSummary. Examples: Pose2D, CmdVel, Imu, LaserScan - all messages in horuslibrary::messages Logging output: Benefits: - Ultra-fast: 248-481 nanoseconds IPC latency (zero-copy shared memory) - Clear logging: Custom LogSummary shows meaningful content - Type safety: Compile-time checks prevent type mismatches - IDE support: Autocomplete, type hints, inline documentation - Cross-language: Rust and Python see the same typed data Performance characteristics: - IPC latency: 0.248-0.481µs (message passing) - Logging overhead: 50-100ns (string formatting) - Total with logging: 400-600ns - Memory: Zero-copy - data shared directly in /dev/shm Use when: - Production code - Performance-critical paths (control loops, sensor fusion) - Real-time systems - Multi-team projects (clear contracts) - Long-term maintainable code 2. Generic Messages (Prototyping) What: Dynamic JSON/MessagePack data for arbitrary structures. Examples: Python dicts, Rust GenericMessage, any schema-less data Logging output (new implementation): Tradeoffs: - Flexibility: Any data structure, evolving schemas - Quick prototyping: No need to define Rust structs - ","headings":"Message Types Message Requirements Typed Messages vs Generic Messages 1. Typed Messages (Recommended) Python - Typed hub 2. Generic Messages (Prototyping) Python - Generic hub (string topic) Performance Comparison Table Real-World Impact Migration Path Phase 1: Prototyping with generic hub Phase 2: Production with typed hub When Generic Messages Make Sense Recommendation LogSummary Trait Why LogSummary? (Design Rationale) When is LogSummary called? Implementation Guidelines Examples from Standard Library Monitor Integration In terminal 1: Run your application In terminal 2: Start monitor Opens browser to http://localhost:3000 Performance Notes Geometry Messages Twist Pose2D Transform Point3 and Vector3 Quaternion Sensor Messages LaserScan IMU Odometry Range BatteryState Control Messages CmdVel Other Control Messages Vision Messages Navigation Messages Diagnostics Messages Custom Messages Creating Custom Messages Best Practices for Custom Messages Message Sizes and Performance Typical Message Sizes Optimization Tips Working with Messages in Nodes Publishing Messages Subscribing to Messages Complete Working Examples Quick Message Usage Pattern Quick Message Usage Pattern Next Steps","category":"concepts"},{"id":29,"title":"Multi-Language Support","description":"Use HORUS with Python and Rust","slug":"/concepts/multi-language","content":"Multi-Language Support HORUS supports multiple programming languages, allowing you to choose the best tool for each component of your robotics system. Supported Languages Rust (Native) Best for: High-performance nodes, control loops, real-time systems HORUS is written in Rust and provides the most complete API. All examples in the documentation use Rust by default. Getting Started: Learn more: Quick Start Python -Production-Ready: Full-featured Python API with advanced capabilities Best for: Rapid prototyping, AI/ML integration, data processing, visualization Python bindings provide a simple, Pythonic API for HORUS with production-grade features: - Per-node rate control - Different rates for different nodes (100Hz sensor, 10Hz logger) - Automatic timestamps - Built-in message timing and staleness detection - Typed messages - Optional type-safe messages from Rust (CmdVel, ImuMsg) - Multiprocess support - Process isolation and multi-language systems Perfect for integrating with NumPy, PyTorch, TensorFlow, and other Python libraries. Getting Started: Learn more: Python Bindings Cross-Language Communication All languages can communicate through HORUS's shared memory system. Simple Types (Numbers, Strings) Structured Messages - Type-Safe Hubs for Cross-Language Communication Important: For cross-language communication with structured data, use typed Hubs. Pass a message type to the Hub constructor to enable automatic serialization that Rust can understand. Python ↔ Rust with Typed Hubs Supported Message Types Pass these types to Hub() for cross-language communication: Description 2D position (x, y, theta) Velocity command (linear, angular) Usage Pattern: Generic Hubs (Python-Only or String Topics) For Python-to-Python communication or custom topics, pass a string: When to use which: - Typed Hubs (Hub(CmdVel), Hub(Pose2D)) - When communicating with Rust nodes - Generic Hub (Hub(\"topic\")) - For Python-only systems or custom data Choosing a Language Recommended Language Rus","headings":"Multi-Language Support Supported Languages Rust (Native) Select: Rust (option 2) Python Select: Python (option 1) Cross-Language Communication Simple Types (Numbers, Strings) Python publisher Structured Messages - Type-Safe Hubs for Cross-Language Communication Python ↔ Rust with Typed Hubs Python publisher (posepublisher.py) Create typed hub - pass message type to constructor Supported Message Types Create typed hubs - pass message type to constructor Generic Hubs (Python-Only or String Topics) Generic Hub - pass topic name as string Note: Generic hubs use JSON serialization for simple types Choosing a Language Mixed-Language Systems Running Mixed-Language Systems Mix Python and Rust nodes Mix Rust and Python sensor.py - Python sensor node Create Hub once outside tick function Run both together Both processes communicate via shared memory Next Steps","category":"concepts"},{"id":30,"title":"Network Communication","description":"Building distributed multi-machine systems with HORUS","slug":"/concepts/network-communication","content":"Network Communication HORUS supports network communication for building distributed systems across multiple machines. Both Hub and Link work transparently over the network with only a syntax change. Quick Start Link Network Example Hub Network Example Python Examples The same endpoint syntax works in Python: Link (Python): Hub (Python): Router (Python): See Python Bindings - Network Communication for full Python documentation. Endpoint Syntax HORUS uses a simple topic@address syntax to specify network endpoints: Link Endpoints (TCP) Producer (connects to consumer): Consumer (listens for producer): Hub Endpoints (UDP) Local Endpoints (Shared Memory) Network Backends Link: DirectBackend (TCP) Technology: TCP with TCPNODELAY Latency: 5-15µs Pattern: Point-to-point (1 producer → 1 consumer) Architecture: - Async Tokio I/O (event-driven, non-blocking) - Lock-free crossbeam channels (send/recv queues) - Buffer pooling (zero-allocation sends) - Binary serialization (bincode) When to use: - Point-to-point communication between exactly 2 machines - Control loops where 5-15µs latency is acceptable - Latest-value semantics (sensor data, state updates) - Guaranteed delivery and ordering (TCP reliability) Example: Hub: UdpDirectBackend (UDP) Technology: UDP with packet fragmentation Latency: &lt;50µs Pattern: Many-to-many pub/sub Architecture: - UDP sockets (connectionless) - Mutex-protected receive queues - Packet fragmentation for large messages - Polling with 100µs sleep When to use: - Broadcasting to multiple subscribers over network - Pub/sub patterns (many publishers, many subscribers) - Occasional packet loss acceptable - Lower overhead than TCP Example: Performance Characteristics Latency Comparison Link (SPSC) Speedup 248ns Baseline Network &lt;50µs Why Link is faster on network: 1. Lock-free channels (no mutex contention) vs mutex-protected queues 2. Event-driven I/O (async Tokio) vs polling with 100µs sleep 3. TCPNODELAY (sends immediately) vs UDP overhead 4. Buffer p","headings":"Network Communication Quick Start Link Network Example Hub Network Example Python Examples === MACHINE 1 (Producer) === === MACHINE 2 (Consumer) === Network hub with endpoint parameter Receive Method 1: Implicit router endpoint Method 2: Explicit RouterClient Endpoint Syntax Link Endpoints (TCP) Hub Endpoints (UDP) Local Endpoints (Shared Memory) Network Backends Link: DirectBackend (TCP) Hub: UdpDirectBackend (UDP) Performance Characteristics Latency Comparison Message Size Impact Frequency Guidelines Multi-Machine Topologies 1. Robot Fleet Coordination 2. Edge Computing Pipeline 3. Distributed Sensing Network 4. Drone with Ground Control Station Network Configuration Using Configuration Files Environment-Specific Endpoints Development (local) Production (network) Error Handling Connection Failures Timeouts and Heartbeats Graceful Degradation Network Performance Tuning 1. TCP Buffer Sizes Increase TCP buffer sizes (Linux) 2. UDP Buffer Sizes Increase UDP buffer sizes 3. Disable WiFi Power Saving Disable WiFi power saving 4. QoS and Traffic Shaping Mark HORUS packets with DSCP (Differentiated Services Code Point) Firewall Configuration Linux (ufw) Allow HORUS ports Linux (iptables) Allow inbound HORUS traffic Security Considerations Network Isolation Future: TLS Support Future feature (not yet implemented) Troubleshooting Connection Refused Check if consumer is listening Check firewall Test connectivity High Latency Measure ping latency Check network interface stats Disable WiFi power save Packet Loss Check packet loss Increase UDP buffers Check WiFi signal Best Practices Summary Next Steps","category":"concepts"},{"id":31,"title":"node! Macro Guide","description":"Write less code with the node! macro","slug":"/concepts/node-macro","content":"The node! Macro The problem: Writing HORUS nodes manually requires lots of boilerplate code. The solution: The node! macro generates all the boilerplate for you! Why Use It? Without the macro (47 lines): With the macro (13 lines): 73% less code! And it's easier to read. Basic Syntax Only the node name and tick are required! Everything else is optional. Sections Explained pub - Send Messages Define what this node sends: This creates: - A Hub<f32field called velocity - A Hub<Stringfield called status - Both connected to their respective topics sub - Receive Messages Define what this node receives: This creates: - A Hub<Stringfield called commands - A Hub<f32field called sensors - Both listening to their respective topics data - Internal State Store data inside your node: Access these as self.counter, self.buffer, etc. tick(ctx) - Main Loop This runs repeatedly (about 60 times per second): Keep this fast! It runs every frame. init(ctx) - Startup (Optional) Runs once when your node starts: Use this for: - Opening files/connections - Pre-allocating memory - One-time setup shutdown(ctx) - Cleanup (Optional) Runs once when your node stops: impl - Custom Methods (Optional) Add helper functions: Complete Examples Simple Publisher Simple Subscriber Pipeline (Sub + Pub) With State With Lifecycle Tips and Tricks Use Descriptive Names Keep tick() Fast Pre-allocate in init() Common Questions Do I need to import anything? Yes, import the prelude: Can I have multiple publishers? Yes! Can I skip sections I don't need? Yes! Only NodeName and tick are required: How do I use the node? Just create it and register it: The macro generates a new() method automatically. Troubleshooting \"Cannot find type in scope\" Import your message types: \"Expected ,, found {\" Check your syntax: Node name must be CamelCase Next Steps Now that you can write nodes quickly: 1. Try some examples - See real applications 2. Learn about Messages - Work with complex data 3. Master the Hub - Understand communicatio","headings":"The node! Macro Why Use It? Basic Syntax Sections Explained pub - Send Messages sub - Receive Messages data - Internal State tick(ctx) - Main Loop init(ctx) - Startup (Optional) shutdown(ctx) - Cleanup (Optional) impl - Custom Methods (Optional) Complete Examples Simple Publisher Simple Subscriber Pipeline (Sub + Pub) With State With Lifecycle Tips and Tricks Use Descriptive Names Keep tick() Fast Pre-allocate in init() Common Questions Do I need to import anything? Can I have multiple publishers? Can I skip sections I don't need? How do I use the node? Troubleshooting \"Cannot find type in scope\" \"Expected ,, found {\" Node name must be CamelCase Next Steps","category":"concepts"},{"id":32,"title":"Real-Time Nodes","description":"Build time-critical robotics applications with guaranteed response times using RTNode","slug":"/concepts/realtime-nodes","content":"Real-Time Nodes HORUS provides industrial-grade real-time support for time-critical robotics applications through the RTNode trait and safety monitoring infrastructure. Overview Real-time nodes (RTNode) enable deterministic execution for: - Surgical robots requiring guaranteed response times - Industrial robots with hard real-time control loops - Aerospace and defense systems with strict deadlines - Safety-critical autonomous vehicles Key Features RTNode Trait The RTNode trait extends the standard Node trait with real-time constraints: Priority Levels HORUS provides fine-grained priority control: Use Case Critical control loops Important sensors/actuators Normal processing Background tasks Custom priority Real-Time Classes Three RT classes for different timing requirements: Description Must never miss deadline Occasional miss tolerated Best effort timing Safety Monitor The safety monitor provides comprehensive runtime protection: - WCET Enforcement: Ensures nodes complete within budget - Deadline Monitoring: Tracks and responds to deadline misses - Watchdog Timers: Detects hung or crashed nodes - Emergency Stop: Immediate shutdown for critical failures Basic Usage Adding RT Nodes Safety-Critical Configuration For medical or aerospace applications: High-Performance Configuration For racing robots or competition systems: Advanced Features Formal Verification RTNode supports formal methods through contracts: Custom Deadline Policies Configure response to deadline misses: Fallback Nodes Implement N-version programming for redundancy: Robot Presets Quick configurations for common robot types: Standard Industrial Robot Medical/Surgical Robot Racing/Competition Robot Space Robotics Swarm Robotics Performance Characteristics Real-world performance on modern hardware: Performance 37ns &lt;5μs ±10μs 1ms &lt;1μs Mixed RT and Normal Nodes HORUS supports mixed criticality systems through priority-based scheduling: Best Practices WCET Budget Setting Set budgets 20-30% higher than","headings":"Real-Time Nodes Overview Key Features RTNode Trait Priority Levels Real-Time Classes Safety Monitor Basic Usage Adding RT Nodes Safety-Critical Configuration High-Performance Configuration Advanced Features Formal Verification Custom Deadline Policies Fallback Nodes Robot Presets Standard Industrial Robot Medical/Surgical Robot Racing/Competition Robot Space Robotics Swarm Robotics Performance Characteristics Mixed RT and Normal Nodes Best Practices WCET Budget Setting Deadline Configuration Priority Assignment Testing Under Load Migration Guide From Standard Nodes Troubleshooting WCET Violations Deadline Misses Emergency Stops Watchdog Timeouts Complete Example Next Steps","category":"concepts"},{"id":33,"title":"Robot Architectures","description":"Visual guides for composing built-in nodes into complete robot systems","slug":"/concepts/robot-architectures","content":"Robot Architectures This guide shows how to compose built-in nodes into complete robot systems. Each architecture includes visual diagrams, topic connections, and ready-to-run code. Philosophy: HORUS built-in nodes are designed to work together. Connect them via topics to build complex systems without writing custom code. Architecture Patterns The Pipeline Pattern The fundamental pattern in robotics: data flows from sensors through processing to actuators. Key principle: Lower priority numbers run first. Sensors (P:0) publish data before controllers (P:2) process it. 1. Mobile Robot Base (Differential Drive) The most common robot configuration: two-wheeled differential drive with joystick control. Architecture Diagram Topic Connections Topic To Node joystick.input DifferentialDriveNode DifferentialDriveNode f32 motor.right DcMotorNode (right) From Node Message Type LidarNode LaserScan obstacles PathPlannerNode PathPlannerNode CmdVel motor.left BldcMotorNode (left) DifferentialDriveNode f32 Code (35 lines) 3. Sensor Fusion System (LiDAR + IMU + Odometry) Combine multiple sensors for accurate robot localization. Architecture Diagram Topic Connections Topic To Node lidar.scan LocalizationNode ImuNode ImuData odom.twist LocalizationNode LocalizationNode Pose2D Code (25 lines) 4. Vision-Based Robot (Camera + AI Detection) A robot that uses computer vision for object detection and tracking. Architecture Diagram Topic Connections Topic To Node camera.image YOLOv8DetectorNode YOLOv8DetectorNode Detections trackedobjects FollowBehaviorNode FollowBehaviorNode CmdVel Code (30 lines) 5. Industrial Robot Arm (Multi-Joint Servo Control) A robot arm with multiple Dynamixel servos for precise manipulation. Architecture Diagram Topic Connections Topic To Node arm.trajectory DynamixelNode DynamixelNode JointState arm.endeffectorpose Application layer Priority Purpose 0 Emergency stop, watchdogs Sensors LidarNode, CameraNode, ImuNode 2 Data processing, detection Planning PathPlannerNo","headings":"Robot Architectures Architecture Patterns The Pipeline Pattern 1. Mobile Robot Base (Differential Drive) Architecture Diagram Topic Connections Code (20 lines) 2. Autonomous Mobile Robot (with Obstacle Avoidance) Architecture Diagram Topic Connections Code (35 lines) 3. Sensor Fusion System (LiDAR + IMU + Odometry) Architecture Diagram Topic Connections Code (25 lines) 4. Vision-Based Robot (Camera + AI Detection) Architecture Diagram Topic Connections Code (30 lines) 5. Industrial Robot Arm (Multi-Joint Servo Control) Architecture Diagram Topic Connections Priority Assignment Guidelines Standard Priority Layers Why This Order? Default Topic Names (Built-in Nodes) Next Steps","category":"concepts"},{"id":34,"title":"What is HORUS?","description":"A high-performance framework for building distributed systems with sub-microsecond IPC","slug":"/concepts/what-is-horus","content":"What is HORUS? HORUS is a framework for building applications with multiple independent components that communicate through ultra-low-latency shared memory. Each component handles one responsibility, and they connect together to form complex systems. The Core Idea Instead of writing one monolithic program, you build: - Independent Nodes - Each component is self-contained - Connected by Topics - Nodes communicate through named channels - Run by a Scheduler - HORUS manages execution order Example: A robot control system might have: - SensorNode (reads camera) - VisionNode (detects objects) - ControlNode (moves motors) - SafetyNode (prevents collisions) Each node runs independently, sharing data through topics like \"camera.image\", \"detected.objects\", \"motor.commands\". Key Features 1. Low-Latency Communication HORUS achieves sub-microsecond message latency through shared memory: Value 248 ns Median latency 450 ns Aspect ROS Typical latency 50-100 us (intra-machine DDS) Configuration XML files Target use case Multi-machine robotics Ecosystem Large Aspect Message Queues Latency 1-10 ms Scope Multi-machine Configuration Complex Persistence Yes Platform Notes Linux Native POSIX shm macOS Uses temp directory Windows Uses temp directory | Check shared memory (Linux): Performance Characteristics IPC Latency: - Min: 248ns - Median: 400ns - Max: 437ns - p99: 450ns Throughput: - Small messages (&lt;1KB): 2M+ msgs/sec - Large messages (1MB): Limited by memory bandwidth Memory Usage: - Framework overhead: 2MB - Per topic: Configurable (default 1MB) - Per node: Depends on implementation Built in Rust HORUS leverages Rust for: Safety - Compile-time guarantees: - No null pointer dereferences - No data races - No use-after-free bugs Performance - Zero-cost abstractions: - No garbage collection pauses - Predictable memory layout - LLVM optimizations Concurrency - Fearless concurrency: - Send/Sync traits prevent data races - Ownership prevents sharing mutable state Learning Path Start he","headings":"What is HORUS? The Core Idea Key Features 1. Low-Latency Communication 2. Clean APIs 3. Built-in Developer Tools Create a new project Run your application Monitor in real-time 4. Multi-Language Support Core Concepts Nodes Topics Hub Scheduler When to Use HORUS Suitable Applications Less Suitable Applications Comparison with Other Frameworks vs Monolithic Programs vs ROS (Robot Operating System) vs Message Queues (RabbitMQ, Kafka) Architecture Overview Technical Details Shared Memory Implementation Performance Characteristics Built in Rust Learning Path Next Steps","category":"concepts"},{"id":35,"title":"AI Integration","description":"Integrate computer vision and AI models into HORUS robotics applications","slug":"/development/ai-integration","content":"AI Integration Integrate computer vision and AI models into your HORUS applications using OpenCV, external Python scripts, or cloud APIs. HORUS's sub-microsecond communication is well-suited for combining real-time control with AI inference. Overview HORUS supports multiple AI integration patterns: Local Vision Processing (Real-Time) - OpenCV computer vision (optional feature flag) - Edge detection, tracking, blob detection - Camera capture and processing - 5-50ms typical latency External AI Services (Background Tasks) - Python ML models via subprocess or HTTP - Cloud APIs (OpenAI, Anthropic, etc.) - Custom inference servers - 50-5000ms typical latency Architecture Pattern: OpenCV Computer Vision HORUS includes optional OpenCV integration for camera capture and real-time vision processing. Enabling OpenCV Add to Cargo.toml: Using the Camera Node The built-in CameraNode supports OpenCV: Custom OpenCV Processing AI Model Inference HORUS can integrate with various AI model formats and inference engines commonly used in robotics. ONNX Runtime (Recommended) ONNX Runtime provides cross-platform inference for models from PyTorch, TensorFlow, scikit-learn, and more. Add dependencies: YOLOv8 Object Detection Example: Download YOLOv8 ONNX: TensorFlow Lite (Edge Devices) For embedded systems and edge devices: Add dependencies: MobileNet Classification: Tract (Pure Rust Inference) Tract is a pure-Rust ONNX/TensorFlow inference engine - no external dependencies! Add dependencies: Example: Model Format Comparison Use Case Edge Devices General (PyTorch, TF) TFLite tflite crate Pure Rust CoreML Via Python NVIDIA GPUs Task Local (GPU) Commands Mistral 7B Mistral 7B GPT-4 Vision+Text LLaVA 13B CodeLlama 7B GPT-4 | Python ML Integration Run Python ML models alongside your HORUS application using subprocess or HTTP. Pattern 1: Python Script via Subprocess Python inference script (objectdetector.py): HORUS node calling Python: Pattern 2: HTTP Inference Server Python FastAPI server (infe","headings":"AI Integration Overview OpenCV Computer Vision Enabling OpenCV Using the Camera Node Custom OpenCV Processing AI Model Inference ONNX Runtime (Recommended) Export from Ultralytics TensorFlow Lite (Edge Devices) Tract (Pure Rust Inference) Model Format Comparison Popular Models for Robotics Hugging Face TensorFlow Hub ONNX Model Zoo Large Language Models (LLMs) Local LLM Inference llama-cpp-rs (Recommended) Download a model (Llama 2, Mistral, Phi-2, etc.) Run with HORUS Candle (Pure Rust) Cloud LLM APIs OpenAI GPT-4 Anthropic Claude Vision-Language Models (VLMs) GPT-4 Vision for Scene Understanding Complete Example: Voice-Controlled Robot LLM Performance & Best Practices Model Recommendations Python ML Integration Pattern 1: Python Script via Subprocess Your ML model here (YOLOv8, TensorFlow, PyTorch, etc.) Pattern 2: HTTP Inference Server Cloud AI APIs OpenAI Vision Example Complete Example: Vision-Guided Robot Performance Considerations Latency Budget Optimization Tips Best Practices Next Steps","category":"development"},{"id":36,"title":"CLI Reference","description":"Complete guide to all HORUS commands","slug":"/development/cli-reference","content":"CLI Reference The horus command gives you everything you need to build, run, and manage your applications. This page covers all 10 commands. Quick Reference horus init - Initialize Workspace What it does: Initializes a HORUS workspace in the current directory, creating the necessary configuration files. Why it's useful: Quickly set up an existing directory as a HORUS project without creating new files from templates. Basic Usage All Options Examples Initialize existing code as HORUS project: Initialize with specific name: What Gets Created Running horus init creates: - horus.yaml - Project manifest with name and version This is useful when you have existing code and want to add HORUS support, or when setting up a workspace that will contain multiple HORUS projects. horus new - Create Projects What it does: Creates a new HORUS project with all the boilerplate set up for you. Why it's useful: Minimal configuration required. Select a language and begin development. Basic Usage All Options Examples Start with Rust + macros (easiest): Python for prototyping: Put it somewhere specific: horus run - Build and Run What it does: Compiles your code and runs it. Handles all the build tools for you. Why it's useful: One command works for Rust and Python. For Rust, it auto-generates Cargo.toml from horus.yaml and uses Cargo for compilation. For Python, it handles the appropriate tooling. Basic Usage All Options Why --release Matters Debug builds have significantly higher overhead than release builds due to runtime checks and lack of optimizations. Debug mode (default): Fast compilation, slower execution - Use case: Development iteration - Typical tick time: 60-200μs - Includes overflow checks, bounds checking, assertions Release mode (--release): Slower compilation, optimized execution - Use case: Performance testing, benchmarks, production deployment - Typical tick time: 1-3μs - Full compiler optimizations enabled Common Mistake: The tick time difference is dramatic: - Debug: 60","headings":"CLI Reference Quick Reference horus init - Initialize Workspace Basic Usage Initialize in current directory (uses directory name) Initialize with custom name All Options Examples Creates horus.yaml with project configuration What Gets Created horus new - Create Projects Basic Usage Interactive mode (asks you questions) Rust with node! macro (recommended for reduced boilerplate) Python project All Options Examples horus run - Build and Run Basic Usage Run current directory (finds main.rs or main.py) Run specific file Run optimized (release mode) All Options Why --release Matters You see: [IPC: 1862ns | Tick: 87μs] - Looks slow! You see: [IPC: 947ns | Tick: 2μs] - Actually fast! Why --clean Matters Examples Fast iteration, slower execution See real speed Clean removes cached dependencies from .horus/target/ Important: Single-File Projects Only Concurrent Multi-Process Execution horus check - Validate Environment Basic Usage Check current project Check specific package What It Checks Example Output Examples Ensure environment is ready Verify installation succeeded Identify missing dependencies horus sim2d - Launch 2D Simulator Basic Usage Launch default simulation Launch with world configuration Headless mode (for testing) All Options What You Get Examples Terminal 1: Launch simulator with world Terminal 2: Run your navigation code Terminal 3: Monitor Load a PGM/PNG map as world Integration with Your Code horus sim3d - Launch 3D Simulator Basic Usage Launch default 3D simulation Launch with URDF robot Headless mode for RL training All Options Features Examples Same seed = same simulation horus monitor - Monitor Everything Basic Usage Web monitor (opens in browser) Different port Text-based (for SSH) Reset monitor password before starting What You See Examples Terminal 1: Run your app Terminal 2: Watch it Visit http://your-computer-ip:3000 from phone horus pkg - Package Management Commands Install a package Remove a package List packages Publish current package to registry Unpublish a package from registry Examples First login Then publish from your project directory horus env - Environment Management Commands Save current environment Load saved environment Examples Creates horus-freeze.yaml On production machine horus auth - Login to Registry Commands Login with GitHub Generate API key (for CI/CD) Check who you are Logout Examples Opens browser for GitHub login Save the generated key in your CI secrets Common Workflows First Time Using HORUS Create a project Run it Monitor it (new terminal) Daily Development Make changes to code Test quickly Test for real Deploy to Production Clean build Save the environment Run in production mode Share Your Work Login once Publish Others can now: Troubleshooting \"command not found: horus\" \"Port already in use\" Use different port Or kill the old process Build is slow \"Failed to create Hub\" Clean all HORUS shared memory (if needed after crashes) Environment Variables Custom registry (for companies) Debug mode (see what's happening) CI/CD authentication Utility Scripts Next Steps","category":"development"},{"id":37,"title":"Error Handling","description":"Unified error types, result handling, and best practices for HORUS applications","slug":"/development/error-handling","content":"Error Handling HORUS provides a unified error handling system built on Rust's Result type, with rich error contexts and helpful diagnostics. Core Error Types HorusError The main error type for all HORUS operations: Error Variants Description File system and I/O errors Config Hardware backend errors Communication Node-specific errors Scheduling Memory allocation errors SharedMemory Parameter management errors Serialization Operation timeout NotFound Access denied InvalidInput Startup failure AlreadyExists Parsing errors CommandFailed Feature not enabled Internal Catch-all Source Type std::io::Error HorusError::Serialization serdeyaml::Error HorusError::Config std::num::ParseIntError HorusError::ParseError uuid::Error HorusError::Other Category Description FileNotFound Missing file ParseError Syntax/parsing error ValidationError Value validation failure MeshLoadError 3D mesh loading issue URDFError URDF parsing issue PhysicsError Physics configuration ConfigError Configuration error Unknown Unclassified error | Rich Error Output Best Practices 1. Use Specific Error Types 2. Add Context When Propagating 3. Handle Expected Errors Gracefully 4. Use Enhanced Errors for User-Facing Messages 5. Log Errors Before Propagating Node Error Handling In Tick Methods Initialization Errors Graceful Degradation Testing Error Handling Integration with anyhow For applications that prefer anyhow: See Also - Nodes - Understanding HORUS nodes - Diagnostics Messages - Status and error reporting - Troubleshooting - Common issues and solutions","headings":"Error Handling Core Error Types HorusError Error Variants Creating Errors Using Constructors Using Variants Directly Error Propagation Using the ? Operator Automatic Conversions Error Checking Query Error Types Pattern Matching Enhanced Errors (Sim3D) Creating Enhanced Errors Pre-built Error Constructors Error Categories Rich Error Output Best Practices 1. Use Specific Error Types 2. Add Context When Propagating 3. Handle Expected Errors Gracefully 4. Use Enhanced Errors for User-Facing Messages 5. Log Errors Before Propagating Node Error Handling In Tick Methods Initialization Errors Graceful Degradation Testing Error Handling Integration with anyhow See Also","category":"development"},{"id":38,"title":"Library Reference","description":"Complete reference for HORUS standard library - messages, tools, and APIs","slug":"/development/library-reference","content":"Library Reference The HORUS Standard Library (horuslibrary) provides ready-to-use message types, development tools, and utilities for robotics applications. Use these components to accelerate development and ensure compatibility across projects. Overview The library includes: - Standard Messages - Memory-safe message types for common robotics data - Built-in Nodes - Production-ready nodes for sensors, actuators, and control (see Built-in Nodes/Drivers) - Example Applications - Complete multi-node demonstrations - Development Tools - Simulators and testing utilities Installation: Import: Standard Messages All messages are designed for shared memory safety with fixed-size fields. Motion & Control CmdVel Velocity command for mobile robots. Size: 16 bytes Latency: 248ns (Link) / 500ns (Hub) Usage: Twist Full 3D velocity (position and orientation). Size: 48 bytes Use for: Drones, robotic arms, 3D movement PIDState PID controller state. Size: 64 bytes Sensors LaserScan 2D LIDAR scan data. Size: 1.5 KB Latency: 900ns (Link) / 2.2µs (Hub) Usage: IMU Inertial Measurement Unit data. Size: 304 bytes Latency: 400ns (Link) / 940ns (Hub) Image Camera image data. Note: For high-resolution images, consider using zero-copy loan() API. Navigation Odometry Robot position and velocity estimate. Size: 736 bytes Latency: 650ns Path Navigation path. Use for: Path planning, trajectory following Input KeyboardInput Keyboard events. Size: 16 bytes Usage: JoystickInput Game controller input. Typical mapping: - axes[0] - Left stick X - axes[1] - Left stick Y - axes[2] - Right stick X - axes[3] - Right stick Y - buttons[0] - A button - buttons[1] - B button Diagnostics Health Node health status. SystemInfo System diagnostics. Built-in Nodes The HORUS library includes 32 production-ready nodes with real hardware drivers for sensors, actuators, communication protocols, and control algorithms. For complete documentation on all built-in nodes, see: Built-in Nodes/Drivers Reference → Quick categorie","headings":"Library Reference Overview Standard Messages Motion & Control CmdVel Twist PIDState Sensors LaserScan IMU Image Navigation Odometry Path Input KeyboardInput JoystickInput Diagnostics Health SystemInfo Built-in Nodes Example Applications SnakeSim TankSim Development Tools Sim2D Feature Flags Or specific features: Best Practices Message Type Selection Node Configuration Error Handling Next Steps","category":"development"},{"id":39,"title":"Monitor Security","description":"Authentication for the HORUS monitor","slug":"/development/monitor-security","content":"Monitor Security The HORUS monitor supports password-based authentication for networked deployments. Setup On first run, set a password (or press Enter to skip): Reset password anytime with: API Authentication Security Details Value Argon2id Session timeout 5 attempts per 60 seconds Token size Password hash stored at /.horus/monitorpassword.hash. Network Access For production, use a reverse proxy with TLS. Recovery If locked out:","headings":"Monitor Security Setup API Authentication Login Returns: {\"token\": \"abc123...\"} Use token for requests Security Details Network Access Local only (default) Allow network access (set password first!) Recovery","category":"development"},{"id":40,"title":"Monitor Guide","description":"Monitor, debug, and manage your HORUS applications in real-time","slug":"/development/monitor","content":"Monitor Under Development: The HORUS Monitor is currently under active development. Core monitoring features work, but some functionality (parameter management UI, package browser) is still being finalized. Check back for updates as we complete this feature. Your mission control for robotics applications. Monitor performance, debug issues, and tune parameters - all from your browser, accessible from any device on your network. What is it? The HORUS Monitor is a web interface that lets you see inside your running robot system. Instead of tailing logs or SSH'ing into your robot, you get a visual, real-time view of everything happening. Access it from: - Your laptop while the robot runs - Your phone/tablet for mobile monitoring - Another team member's computer - Anywhere on your network Why use it? You want to know: \"Is my robot working?\" The monitor shows you at a glance: - All nodes running? (System health badge) - Performance good? (CPU, memory, tick rates) - Messages flowing? (Topic activity) - Any errors? (Error counts) Without the monitor: Grep logs, check processes, SSH into robot, hope you find the issue With the monitor: Open browser, see everything instantly You want to: \"Debug why it's not working\" Common problems the monitor solves: \"My subscriber isn't getting messages\" - Check Topics tab Is the topic there? - Check Graph view Are publisher and subscriber connected? - Check Logs Any connection errors? \"The robot is running slow\" - Check Nodes tab Which node is using 90% CPU? - Check tick rates Which node can't keep up? - Check Logs Any \"slow tick\" warnings? \"It worked yesterday, what changed?\" - Check Parameters What values are different? - Check Nodes Same nodes running as before? You want to: \"Tune parameters live\" Example: Tuning PID controller gains Without monitor: 1. Edit config file 2. Stop robot 3. Restart robot 4. Test behavior 5. Repeat 20 times With monitor: 1. Open Parameters tab 2. Edit pid.kp value 3. Watch robot respond instantly 4. Adjust u","headings":"Monitor What is it? Why use it? You want to know: \"Is my robot working?\" You want to: \"Debug why it's not working\" You want to: \"Tune parameters live\" Quick Start Start your robot In another terminal, start monitor What You Can Do 1. Monitor Performance 2. Debug Message Flow 3. Watch Real-Time Logs 4. Tune Parameters Live 5. Manage Packages 6. Deploy to Robots Common Scenarios Starting Your Day Something Broke Performance Tuning Team Collaboration Access From Anywhere Tips Quick Reference Troubleshooting Terminal UI Mode Next Steps","category":"development"},{"id":41,"title":"Parameters Guide","description":"Configure and tune your HORUS applications with runtime parameters","slug":"/development/parameters","content":"Parameters Guide Under Development: The parameters system is currently under active development. The core parameter API (ctx.params.get() and ctx.params.set()) works as documented, but the monitor UI for parameter management and some advanced features are still being finalized. Check back for updates. Runtime parameters in HORUS provide dynamic configuration without recompiling code. Adjust speeds, gains, thresholds, and behaviors on-the-fly for rapid prototyping and tuning. Why Parameters? Without parameters: With parameters: Benefits: - No recompilation - Change values without rebuilding - Live tuning - Adjust while robot is running - Persistence - Saved to disk automatically - Sharing - Export/import parameter sets - Safety - Fallback to defaults if missing Core Concepts Parameter Storage Parameters are stored in a thread-safe map: Location: /.horus/config/params.yaml Format: Parameter Types HORUS supports all JSON-compatible types: - Numbers - f64, i64, u64 (stored as Value::Number) - Strings - String (stored as Value::String) - Booleans - bool (stored as Value::Bool) - Arrays - Vec<T(stored as Value::Array) - Objects - HashMap<String, T(stored as Value::Object) Hierarchical Keys Use dot notation for organization: Benefits: - Clear organization - Avoid name collisions - Easy to export/import subsets - Natural grouping in monitor Using Parameters in Nodes Accessing Parameters Parameters are available via the NodeInfo context: Parameter Methods Get with default: Get optional: Set parameter: Type-specific getters: Live Reloading Check for updates every tick: Performance note: Parameter access is fast (80-350ns via Arc<RwLock), but avoid reading hundreds of parameters every tick. Cache values and reload periodically. Complex Parameter Types Arrays: Objects: Default Parameters HORUS provides sensible defaults on first run: Customization: 1. File is created on first launch 2. Edit directly or use monitor 3. Changes persist across restarts 4. Delete file to reset to de","headings":"Parameters Guide Why Parameters? Core Concepts Parameter Storage Parameter Types Hierarchical Keys Using Parameters in Nodes Accessing Parameters Parameter Methods Live Reloading Complex Parameter Types Default Parameters ~/.horus/config/params.yaml (auto-generated) Managing Parameters Via Monitor Start monitor Navigate to Parameters tab View all parameters Edit values inline Changes auto-save to disk Via Code Via File Edit Edit parameters file Changes take effect: - Immediately if node reloads - On next restart if not Use spaces (2 or 4), not tabs Comments are preserved Common Patterns PID Controller Tuning Feature Flags Environment-Specific Config Rate Limiting Best Practices Naming Conventions Good Bad Good Bad Good (snakecase) Bad (mixed casing) Always Provide Defaults Document Parameters Validate Parameter Values Export Parameter Sets Save current parameters to preset Parameters tab  Export  Save as \"aggressivetuning.yaml\" Switch to different preset Restart application to load new parameters Troubleshooting Parameters Not Loading Check YAML syntax Validate YAML Check permissions Should be readable Parameters Not Saving Create config directory Set permissions Manually save from code Type Mismatch Wrong - string Correct - number Lost Parameters After Update Backup After update, restore if needed Performance Considerations Access Speed Caching Strategy Next Steps","category":"development"},{"id":42,"title":"Sim3D Editor","description":"Interactive scene editor for 3D simulations with gizmos, selection, and property inspection","slug":"/development/sim3d-editor","content":"Sim3D Editor The Sim3D Editor provides an interactive scene editing interface for manipulating robots, objects, and environments during simulation. It integrates with Bevy's ECS and uses egui for the user interface. Enabling the Editor The editor is behind a feature flag. Enable it in your Cargo.toml: Or run with the feature: Editor Plugin Add the editor plugin to your Bevy app: Editor State The EditorState resource controls editor behavior: Gizmo Modes Description Move objects along axes Rotate objects Scale objects Disable gizmos Camera Modes Description Orbit around selection point Pan First-person fly camera Top Orthographic side view Front Selection System The selection system allows selecting entities via mouse clicks with physics-based raycasting. Making Entities Selectable Add the Selectable component to entities you want to be selectable: Working with Selection Access the Selection resource to query or modify selection: Selection Events Listen to selection changes: Selection Keyboard Shortcuts Action Select entity Shift+Click Toggle selection Escape Select all | Inspector Panel The inspector panel shows properties of selected entities: Making Components Inspectable Use Bevy's reflection system to expose components to the inspector: Hierarchy Panel The hierarchy panel shows the entity tree structure: Undo System The editor includes an undo/redo system for transform operations: Editor Camera The editor camera system provides multiple viewing modes: Custom Camera Settings Complete Editor Example See Also - Sim3D Overview - Full Sim3D documentation - Sim3D Recording - Recording and playback - Sim3D Multi-Robot - Multi-robot simulation","headings":"Sim3D Editor Enabling the Editor Editor Plugin Editor State Gizmo Modes Camera Modes Selection System Making Entities Selectable Working with Selection Selection Events Selection Keyboard Shortcuts Inspector Panel Making Components Inspectable Hierarchy Panel Undo System Editor Camera Custom Camera Settings Complete Editor Example See Also","category":"development"},{"id":43,"title":"Sim3D Multi-Robot","description":"Multi-robot simulation with namespacing, communication, swarm coordination, and formation control","slug":"/development/sim3d-multi-robot","content":"Sim3D Multi-Robot The Sim3D multi-robot system provides infrastructure for simulating multiple robots with inter-robot communication, swarm behaviors, formation control, and distributed coordination. Multi-Robot Plugin Add the multi-robot plugin to enable all multi-robot features: Robot Identification Each robot is identified by a unique RobotId for namespacing and communication. RobotId Robot Component Mark entities as robots with the Robot component: Multi-Robot Manager The MultiRobotManager resource tracks all registered robots: Manual Registration Robots are auto-registered, but you can manually manage them: Inter-Robot Communication Simulate message passing between robots with configurable channels. CommunicationManager Sending Messages Receiving Messages Communicator Component Add callbacks for message handling: Communication Statistics Swarm Coordination Implement swarm behaviors like flocking, separation, and cohesion. SwarmAgent Component Swarm Behavior Parameters Default 2.0 1.0 1.0 1.5 2.0 5.0 Formation Control Control robot formations with leader-follower patterns. FormationController Component Formation Types Description Robots in a horizontal line Circle 4-wide grid formation Wedge User-defined positions | Formation Scaling Dynamic Formation Changes Consensus Algorithms Distributed agreement algorithms for multi-robot systems. ConsensusState Resource Task Allocation Distributed task assignment for multi-robot teams. TaskAllocation Resource Complete Multi-Robot Example See Also - Sim3D Overview - Full Sim3D documentation - Sim3D Editor - Scene editing tools - Sim3D Recording - Recording and playback - Coordination Messages - HORUS coordination message types","headings":"Sim3D Multi-Robot Multi-Robot Plugin Robot Identification RobotId Robot Component Multi-Robot Manager Manual Registration Inter-Robot Communication CommunicationManager Sending Messages Receiving Messages Communicator Component Communication Statistics Swarm Coordination SwarmAgent Component Swarm Behavior Parameters Formation Control FormationController Component Formation Types Formation Scaling Dynamic Formation Changes Consensus Algorithms ConsensusState Resource Task Allocation TaskAllocation Resource Complete Multi-Robot Example See Also","category":"development"},{"id":44,"title":"Sim3D Recording","description":"Trajectory recording, time control, video export, and sensor data bags for simulation","slug":"/development/sim3d-recording","content":"Sim3D Recording The Sim3D recording system provides comprehensive tools for capturing simulation data including trajectories, sensor data, and video output. Recording Plugin Add the recording plugin to enable all recording features: Trajectory Recording Record the motion of entities over time for playback and analysis. TrajectoryPoint Each trajectory point captures the full state at a moment in time: Recording Sessions Use RecordingSession to capture multiple entity trajectories: TrajectoryRecorder Component Add to entities to automatically record their motion: Trajectory Analysis Query and analyze recorded trajectories: Trajectory Playback Play back recorded trajectories on entities: Time Control Control simulation time for debugging and analysis. TimeControl Resource TimeControlMode Description Real-time simulation Paused 0.01x - 1.0x speed FastForward Manual frame advance Preset VERYSLOW 0.25x HALFSPEED 1.0x DOUBLESPEED 4.0x MAXSPEED Scripted Time Control Create keyframed time control sequences: Time Statistics Monitor simulation time metrics: Video Export Capture simulation frames for video creation. VideoRecordingConfig Video Formats Description PNG frame sequence JPEG frame sequence Raw RGB bytes Recording Video Frame Conversion Utilities Screenshots Take individual screenshots: Sensor Data Bags Record sensor data in a rosbag-like format for replay and analysis. SensorData Types Recording Sensor Data RecordSensor Component Automatically record sensor entities: Sensor Bag Playback Play back recorded sensor data: Bag Statistics Analyze recorded bags: Query Bag Data Complete Example See Also - Sim3D Overview - Full Sim3D documentation - Sim3D Editor - Scene editing tools - Sim3D Multi-Robot - Multi-robot simulation","headings":"Sim3D Recording Recording Plugin Trajectory Recording TrajectoryPoint Recording Sessions TrajectoryRecorder Component Trajectory Analysis Trajectory Playback Time Control TimeControl Resource TimeControlMode Time Scale Presets Scripted Time Control Time Statistics Video Export VideoRecordingConfig Video Formats Recording Video Frame Conversion Utilities Screenshots Sensor Data Bags SensorData Types Recording Sensor Data RecordSensor Component Sensor Bag Playback Bag Statistics Query Bag Data Complete Example See Also","category":"development"},{"id":45,"title":"Simulation","description":"Test your robots in virtual environments with sim2d and sim3d","slug":"/development/simulation","content":"Simulation Test and validate your robot algorithms in virtual environments before deploying to real hardware. HORUS provides two simulation tools optimized for different use cases. Overview HORUS provides two levels of simulation: Tools sim2d, sim3d Built into nodes Environment Simulators Status Use Case Active Development Fast prototyping, navigation Available Realistic testing, RL training Node Simulation Mode Every hardware node (IMU, GPS, LiDAR, Camera, Serial, etc.) has a built-in simulation mode that generates synthetic data. See Node Simulation Mode below. Key Benefits: - Same code works in sim and reality - Write once, deploy anywhere - HORUS-native - Direct Hub integration, no middleware - Sub-microsecond IPC - Realistic latency testing - CI/CD ready - Headless mode for automated testing - No hardware required - Develop before hardware arrives sim2d - 2D Robotics Simulator Status: Active Development - Core features working, polish ongoing What is sim2d? A lightweight 2D top-down simulator built with Bevy and Rapier2D for fast iteration and testing. Perfect for: - Navigation algorithm development - Multi-robot coordination - Path planning testing - Sensor simulation (LiDAR, odometry, IMU) - CI/CD automated testing Not designed for: - Realistic 3D visualization - Camera/vision simulation - Complex robot modeling Quick Start Installation Run sim2d Features Visual Mode - Real-time 2D rendering with Bevy - Top-down view of robots and environment - Debug visualization (lidar rays, paths, collision shapes) - Interactive camera controls Physics - Rapier2D physics engine - Realistic differential drive kinematics - Collision detection and response - Configurable physics rate (default: 240 Hz) Sensors - 2D LiDAR: 360° scanning with configurable resolution - Odometry: Wheel encoder simulation with realistic noise - IMU: Angular velocity and acceleration - Ground truth: Perfect pose for debugging HORUS Integration Your robot code works unchanged in simulation: Same topi","headings":"Simulation Overview Environment Simulators Node Simulation Mode sim2d - 2D Robotics Simulator What is sim2d? Quick Start Installation Ubuntu/Debian - Install dependencies Set environment variables Run sim2d Launch simulator Or with specific options Features Visual Mode Physics Sensors HORUS Integration Usage Examples Test Navigation Algorithm Terminal 1: Launch simulator with maze Terminal 2: Run your navigation code Terminal 3: Monitor performance Headless Testing (CI/CD) Automated test script Start simulator in headless mode Wait for simulator to initialize Run test Stop simulator Custom Scenarios warehouse.yaml Configuration Command Reference Performance Known Limitations sim3d - 3D Robotics Simulator with RL Support Overview Features Dual-Mode Operation Robot Support Advanced Physics 3D Sensors Transform Frames (TF) Reinforcement Learning Create vectorized environment (1024 parallel instances) Scene Management Import Gazebo world Save current scene Load scene Architecture Technical Stack Planned Command Interface Visual mode (default) Headless RL training Load URDF robot Import Gazebo world Enable TF visualization Debug mode with editor Specific scenario Python RL Example trainnavigation.py Create environment Train agent Save policy Evaluate in visual mode Development Roadmap Performance Targets Detailed Sim3D Documentation Node Simulation Mode Why Simulation Mode? Rust Nodes with Simulation Python Nodes with Simulation Explicit simulation mode Auto-fallback: If hardware unavailable, switches to simulation Auto-Fallback Behavior Python: Auto-fallback on hardware error Simulation Data Quality Best Practices Start with simulation Then test with hardware Cargo.toml .github/workflows/test.yml Sim-to-Real Transfer Why HORUS Simulators Work for Real Robots Best Practices Develop in sim2d (fast iteration) Refine in sim3d (realistic testing) Deploy to real hardware Match real robot specs Comparison with Other Simulators Getting Help Documentation Community Examples Contributing Roadmap sim2d sim3d Next Steps","category":"development"},{"id":46,"title":"Static Analysis","description":"Compile-time detection of Link SPSC violations","slug":"/development/static-analysis","content":"Static Analysis horus check includes static analysis to detect Link SPSC violations before runtime. Link SPSC Violations Link is Single-Producer-Single-Consumer. Multiple producers or consumers on the same topic causes undefined behavior. Running What's Detected Detected Yes Link::consumer(\"topic\") called twice Yes Dynamic topic names (Link::producer(var)) Link vs Hub Use Link (248ns) Multiple producers or consumers","headings":"Static Analysis Link SPSC Violations Running What's Detected Link vs Hub","category":"development"},{"id":47,"title":"Testing HORUS Applications","description":"Unit testing, integration testing, and mocking for HORUS nodes","slug":"/development/testing","content":"Testing HORUS Applications Learn how to test your HORUS nodes and applications with complete, runnable examples using Rust's built-in test framework. Why Test HORUS Nodes? Testing ensures: - Nodes work in isolation before integration - Message passing is correct (right topics, right types) - Lifecycle methods behave properly (init, tick, shutdown) - Edge cases are handled (no messages, invalid data, etc.) - Refactoring doesn't break functionality Testing Strategies 1. Unit Testing a Single Node Test node behavior without running the scheduler. 2. Integration Testing Multiple Nodes Test nodes communicating through the Hub. 3. Mocking Hubs Isolate nodes by mocking their dependencies. Unit Testing a Single Node Test individual node behavior in isolation. Example: Testing a Temperature Sensor File: src/main.rs Run the Tests Expected Output: Key Testing Patterns 1. Test Node Creation: 2. Test Initialization: 3. Test Tick Logic: 4. Test Shutdown: Testing Multiple Nodes Together Test nodes communicating through topics. Example: Publisher-Subscriber Test File: src/main.rs Run Integration Tests Why --test-threads=1? - Prevents tests from running in parallel - Avoids shared memory conflicts between tests - Ensures deterministic behavior Expected Output: Mocking Hubs for Isolated Tests Test nodes without real Hub connections. Example: Mock Hub for Testing Testing Strategy Without Hub Mocks Since HORUS Hubs use real shared memory, full mocking is complex. Instead: 1. Extract Business Logic: 2. Test Tick with Real Hubs: 3. Use Shared State for Verification: Complete Testing Example A fully tested 3-node system. File: src/main.rs Run All Tests Output: Best Practices 1. Test Business Logic Separately Extract pure functions for easy testing: 2. Use Arc for Shared Test Data Share data between nodes for verification: 3. Add Small Delays for IPC Shared memory needs time to propagate: 4. Run Tests Sequentially Prevent shared memory conflicts: 5. Test Edge Cases Running Tests with cargo","headings":"Testing HORUS Applications Why Test HORUS Nodes? Testing Strategies 1. Unit Testing a Single Node 2. Integration Testing Multiple Nodes 3. Mocking Hubs Unit Testing a Single Node Example: Testing a Temperature Sensor Run the Tests Key Testing Patterns Testing Multiple Nodes Together Example: Publisher-Subscriber Test Run Integration Tests Mocking Hubs for Isolated Tests Example: Mock Hub for Testing Testing Strategy Without Hub Mocks Complete Testing Example Run All Tests Best Practices 1. Test Business Logic Separately 2. Use Arc for Shared Test Data 3. Add Small Delays for IPC 4. Run Tests Sequentially 5. Test Edge Cases Running Tests with cargo test Basic Commands Run all tests Run tests sequentially (recommended for HORUS) Run specific test Run tests with output Run tests matching pattern Test Organization Troubleshooting Tests Issue: Tests Fail Randomly Issue: \"Topic not found\" Errors Issue: Messages Not Received Next Steps","category":"development"},{"id":48,"title":"Complete Beginner's Guide to Robot Programming","description":"Learn robot programming fundamentals with HORUS. This guide covers installation, basic concepts, and building your first robot program.","slug":"/getting-started/complete-beginners-guide","content":"Complete Beginner's Guide to Robot Programming This guide introduces robot programming concepts and walks through building your first robot program with HORUS. No prior robotics experience is required. What You'll Learn By the end of this guide, you will: - Understand the fundamental concepts of robot programming - Install HORUS on your computer - Write your first robot program in Python - Create nodes that communicate with each other - Use the monitor to monitor your robot Prerequisites - Basic Python knowledge (variables, functions, loops) - A Linux, macOS, or Windows computer - Terminal/command line familiarity Part 1: Understanding Robot Programming How Robots Work A robot system consists of multiple components working together: - Sensors - Read data from the environment (cameras, distance sensors, GPS) - Processors - Make decisions based on sensor data (navigation, AI, control algorithms) - Actuators - Execute physical actions (motors, servos, grippers) Each component needs to communicate with others quickly and reliably. HORUS provides the communication infrastructure that connects these components. The Communication Challenge Consider a mobile robot navigating a room: 1. A LiDAR sensor scans the environment 10 times per second 2. A navigation algorithm processes the scan data 3. Motor controllers adjust wheel speeds 4. A safety system monitors for obstacles All components must share data with minimal delay. HORUS handles this communication through a publish/subscribe messaging system. HORUS Approach In HORUS, communication between components is straightforward: HORUS manages the underlying shared memory and synchronization. Part 2: Installation Follow the Installation Guide to install HORUS. The process takes approximately 5-10 minutes and includes: - Installing the Rust toolchain - Building and installing HORUS - Verifying the installation Once complete, verify the installation: Part 3: Your First Robot Program Understanding Nodes In HORUS, each component is","headings":"Complete Beginner's Guide to Robot Programming What You'll Learn Prerequisites Part 1: Understanding Robot Programming How Robots Work The Communication Challenge HORUS Approach Component 1: Publish sensor data Component 2: Receive the data Part 2: Installation Part 3: Your First Robot Program Understanding Nodes Create a Project Understanding the Code Counter to track messages This function runs repeatedly Create and run the node Run the Program Part 4: Node Communication Create robotwithsensor.py Node 1: Simulates a distance sensor Node 2: Controls motors based on sensor data Create nodes Run both nodes for 5 seconds Run the Example How It Works Part 5: Using the Monitor Launch the Monitor Testing the Monitor Part 6: Hardware Integration Example: Raspberry Pi GPIO Setup GPIO Built-in Nodes Part 7: Example Project - Line Following Robot Hardware Requirements Implementation Node 1: Read line sensors Node 2: Line following logic Node 3: Motor driver Create and run nodes Common Questions Do I need to learn Rust? Do I need hardware to get started? Can HORUS control multiple robots? What platforms does HORUS support? Next Steps Core Concepts Practical Guides Advanced Topics Getting Help","category":"getting-started"},{"id":49,"title":"Installation","description":"Install HORUS on Linux, macOS, or Windows","slug":"/getting-started/installation","content":"Installing HORUS This guide covers installing Rust, building HORUS, and verifying the installation. The process takes approximately 10-15 minutes. Platform Support HORUS has native cross-platform support: Status Notes Supported Recommended for production Ubuntu 22.04+ /dev/shm/horus/ Supported Tested and working Fedora 36+ /dev/shm/horus/ Supported Community maintained Raspberry Pi /dev/shm/horus/ Supported tmpfs-backed, full support Windows %TEMP%\\horus\\ Supported Linux mode in WSL Driver System Packages SocketCAN can-utils (optional) SPI devices Implemented i2cdev i2c-tools (Pi only) Serial devices Implemented GPIO libraspberrypi-dev (Pi only) PWM outputs Implemented RealSense librealsense2-dev Force-torque sensors Planned Platform Notes Linux Native POSIX shm, fastest macOS tmpfs-backed Windows Temp directory | Check available space: You should have at least 256MB. Most systems have 1-2GB. If you need more space (Linux only): Updating HORUS To update to the latest version: To preview changes before updating: Uninstalling To completely remove HORUS: The uninstaller will: 1. Remove the horus CLI binary (/.cargo/bin/horus) 2. Remove all cached libraries (/.horus/cache/) 3. Ask if you want to remove /.horus/ (contains auth, config, registry data) 4. Clean up shared memory files (platform-specific paths) 5. Leave project-local .horus/ directories untouched Manual uninstall (if needed): Linux/macOS: Windows (PowerShell): Troubleshooting Having installation issues? Try manual recovery: Common issues: - Missing packages: Install all required system dependencies (see above) - Raspberry Pi: Ensure GPIO/I2C packages are installed - Jetson Nano: Ensure CUDA/JetPack packages are installed See the Troubleshooting & Maintenance Guide for: - Common installation errors and detailed fixes - System dependency issues - Verify script (verify.sh) - Platform-specific problems - 15+ solved issues with step-by-step solutions Next Steps With HORUS installed, proceed to one of the followin","headings":"Installing HORUS Platform Support Prerequisites Quick Install (Recommended) 1. Install Rust (takes ~2 minutes) 2. Clone HORUS 3. Run automated installer (takes ~5 minutes) 4. Verify it works 5. Run full verification (optional but recommended) Step-by-Step Installation Step 1: Install Rust Step 2: Install Git (If You Don't Have It) Ubuntu/Debian Fedora Arch Linux Step 3: Clone HORUS Step 4: Run the Installer Step 5: Verify Installation Step 6: Run Full Verification (Recommended) Python Support 1. Install maturin (Python build tool) 2. Navigate to Python bindings 3. Build and install (takes ~3 minutes) Platform-Specific Notes Linux (Ubuntu/Debian) Linux (Fedora/RHEL) Raspberry Pi Install all dependencies Raspberry Pi specific packages (GPIO, I2C, SPI support) Enable I2C and SPI (required for sensors) Navigate to: Interface Options → I2C → Enable Navigate to: Interface Options → SPI → Enable NVIDIA Jetson Nano Install all dependencies Jetson specific packages (GPU acceleration) Verify CUDA is installed Hardware Driver Support (Optional) Available Hardware Drivers Installing Hardware Driver Packages Enable hardware interfaces Navigate to: Interface Options → I2C → Enable Navigate to: Interface Options → SPI → Enable Navigate to: Interface Options → Serial Port → Enable Setup virtual CAN for testing Test CAN tools Add Intel RealSense repository Install RealSense SDK Test camera Workflow: Development to Hardware Deployment 1. Install HORUS normally (no hardware packages needed) 2. Create and run your project 1. Install system packages on the robot 2. Enable hardware features in YOUR project's Cargo.toml Edit myrobot/Cargo.toml: 3. Build and run on the robot On the robot, in your project directory Supported Hardware Nodes Windows (Native) 1. Install Rust (using rustup-init.exe from rustup.rs) Download and run: https://win.rustup.rs/x8664 2. Clone HORUS (in PowerShell or Git Bash) 3. Build HORUS 4. Install CLI macOS (Native) 1. Install Rust 2. Install Xcode Command Line Tools (if not already installed) 3. Clone and build HORUS 4. Verify installation Understanding Shared Memory Linux macOS Windows (PowerShell) Temporarily increase to 2GB Make permanent: edit /etc/fstab (requires sudo) Add line: tmpfs /dev/shm tmpfs defaults,size=2G 0 0 Updating HORUS Navigate to HORUS directory Pull latest changes and reinstall Uninstalling Navigate to HORUS directory Run the uninstaller Remove CLI tool Remove global cache and config Remove source code Clean up shared memory (optional - HORUS auto-cleans sessions) Linux: macOS: Remove CLI tool Remove global cache and config Remove source code Clean up shared memory (optional - HORUS auto-cleans sessions) Troubleshooting Navigate to HORUS source directory Clean and reinstall Verify installation Next Steps","category":"getting-started"},{"id":50,"title":"Quick Start","description":"Build your first HORUS application in 10 minutes","slug":"/getting-started/quick-start","content":"Quick Start This tutorial demonstrates building a temperature monitoring system with HORUS. Estimated time: 10 minutes. What We're Building A system with two components: 1. Sensor - Generates temperature readings 2. Monitor - Displays the readings They'll communicate using HORUS's ultra-fast shared memory. Step 1: Create a New Project This creates: - main.rs - Your code (we'll customize this) - horus.yaml - Dependencies and project metadata - .horus/ - Auto-managed environment (local workspace + global cache) Note: .horus/ is automatically managed. For Rust projects, HORUS generates Cargo.toml from your horus.yaml using path references (no source copying). See Environment Management for details. Step 2: Write the Code Replace the generated main.rs with this complete example: Step 3: Run It! HORUS will automatically: - Scan dependencies from horus.yaml - Generate .horus/Cargo.toml from dependencies - Compile with Cargo (optimized) - Execute your program You'll see: Press Ctrl+C to stop. Understanding the Code The Hub - Communication Channel Both use the same topic name (\"temperature\"). The Hub manages all shared memory operations automatically. The Node Trait - Component Lifecycle Each component implements the Node trait: The Scheduler - Running Everything The scheduler runs your nodes in priority order: Running Nodes in Separate Processes The example above runs both nodes in a single process. HORUS uses a flat namespace (like ROS), so multi-process communication works automatically! Running in Separate Terminals Just run each file in a different terminal - they automatically share topics: Both use the same topic name (\"temperature\") → communication works automatically! Using Glob Pattern Run multiple files together: [TIP] See Shared Memory for details on the flat namespace architecture. Next Steps Add More Features Try modifying the code: 1. Add a temperature alert: 2. Add a second sensor: 3. Save data to a file: Learn More Concepts Now that you've built your first ","headings":"Quick Start What We're Building Step 1: Create a New Project Create a new HORUS project Select options in the interactive prompt: Language: Rust (option 2) Use macros: No (we'll learn the basics first) Step 2: Write the Code Step 3: Run It! Understanding the Code The Hub - Communication Channel The Node Trait - Component Lifecycle The Scheduler - Running Everything Running Nodes in Separate Processes Running in Separate Terminals Terminal 1: Run sensor Terminal 2: Run monitor (automatically connects!) Using Glob Pattern Next Steps Add More Features Learn More Concepts Common Questions Why do I need Box::new()? What's Option<&mut NodeInfo>? Can I use async/await? How do I stop the application? Where does the data go? Troubleshooting \"Failed to create Hub\" \"Address already in use\" Linux macOS Nothing prints What You've Learned Ready for More?","category":"getting-started"},{"id":51,"title":"Building Your Second Application","description":"Build a 3-node sensor pipeline with filtering and display","slug":"/getting-started/second-application","content":"Building Your Second Application Now that you've built your first HORUS application, let's create something more practical: a 3-node sensor pipeline that reads temperature data, filters out noise, and displays the results. What You'll Build A real-time temperature monitoring system with: 1. SensorNode: Publishes simulated temperature readings every second 2. FilterNode: Subscribes to raw temperatures, filters noise, republishes clean data 3. DisplayNode: Subscribes to filtered data, displays to console This demonstrates: - Multi-node communication patterns - Data pipeline processing - Real-time filtering - Monitor monitoring Architecture Step 1: Create the Project Step 2: Write the Code Replace main.rs with this complete, runnable code: Step 3: Run the Application Expected Output: Press Ctrl+C to stop: Step 4: Monitor with Monitor Open a second terminal and run: The monitor will show: Nodes Tab - SensorNode: Publishing to rawtemp every 1 second - FilterNode: Subscribing to rawtemp, publishing to filteredtemp - DisplayNode: Subscribing to filteredtemp Topics Tab - rawtemp (f32): Noisy temperature readings - filteredtemp (f32): Smooth temperature readings Metrics Tab - IPC Latency: 248ns-437ns (sub-microsecond!) - Tick Duration: How long each node takes to execute - Message Counts: Total messages sent/received Understanding the Code SensorNode Key Points: - Uses Instant to track time between publishes - Simulates realistic sensor data with noise - Publishes to \"rawtemp\" topic FilterNode Key Points: - Subscribes to \"rawtemp\", publishes to \"filteredtemp\" - Implements exponential moving average (EMA) filter - alpha = 0.3 balances responsiveness vs smoothness Filter Behavior: - High alpha (0.8): Fast response, less smoothing - Low alpha (0.2): Slow response, more smoothing DisplayNode Key Points: - Subscribes to \"filteredtemp\" - Only receives when new data is available - recv() returns None when no message (not an error!) Common Issues & Fixes Issue 1: No Output Displayed","headings":"Building Your Second Application What You'll Build Architecture Step 1: Create the Project Step 2: Write the Code Step 3: Run the Application Step 4: Monitor with Monitor Nodes Tab Topics Tab Metrics Tab Understanding the Code SensorNode FilterNode DisplayNode Common Issues & Fixes Issue 1: No Output Displayed Issue 2: Too Much/Too Little Smoothing Issue 3: Monitor Shows No Nodes Issue 4: Build Errors Experiments to Try 1. Change Update Rate 2. Add Temperature Alerts 3. Log Data to File 4. Add Multiple Sensors Key Concepts Demonstrated Next Steps Full Code","category":"getting-started"},{"id":52,"title":"Configuration Reference","description":"Complete reference for horus.yaml and .horus directory","slug":"/package-management/configuration","content":"Configuration Reference Complete guide to configuring HORUS projects via horus.yaml and understanding the auto-managed .horus/ directory. Quick Reference Minimal horus.yaml: Full horus.yaml: Project Metadata name (Required) Project name used for identification and package management. Type: String Required: Yes Constraints: - Must be unique within your organization - Use lowercase with hyphens (kebab-case) - No spaces or special characters except hyphens and underscores Examples: version (Required) Project version following semantic versioning. Type: String Required: Yes Format: MAJOR.MINOR.PATCH (semantic versioning) Examples: Best Practice: Always quote version strings to prevent YAML parsing issues. description (Optional) Human-readable description of your project. Type: String Required: No Default: None Examples: author (Optional) Project author or team name. Type: String Required: No Default: None Examples: license (Optional) Project license identifier. Type: String Required: No Default: None Common Values: Apache-2.0, MIT, GPL-3.0, BSD-3-Clause Examples: Build Configuration mode (Optional) Build mode for compilation. Type: String Required: No Default: debug Values: debug, release Examples: Override via CLI: language (Optional) Programming language for the project. Type: String Required: No Default: Auto-detected from file extensions Values: rust, python Examples: Auto-detection: - main.rs Rust - main.py Python Dependencies HORUS supports multiple package sources in horus.yaml: Syntax Installed via name or name@version horus pkg install or horus run crates.io serde, cargo:tokio@1 name or pip:name@version Auto-detected or explicit Git See below path:name:./path horus run | Basic Dependencies Type: Array of strings or objects Required: At least horus is recommended String format (simple): Object format (with version and features): Prefixed Dependencies (Custom Drivers) For explicit control over where packages come from, use prefixes: Cargo (crates.io): Pip (PyPI):","headings":"Configuration Reference Quick Reference Project Metadata name (Required) version (Required) description (Optional) author (Optional) license (Optional) Build Configuration mode (Optional) language (Optional) Dependencies Basic Dependencies Prefixed Dependencies (Custom Drivers) Dependency Fields Examples Ignore Patterns ignore (Optional) ignore.files ignore.directories ignore.packages Complete Ignore Example The .horus/ Directory Structure Global Cache vs Local Workspace What's Inside .horus/ Git Configuration Auto-managed HORUS environment Keep configuration When .horus/ is Created Cleaning .horus/ Complete Examples Single-Process Application Multi-Process Application (Backend) Multi-Process Application (GUI) Python Project Best Practices Version Your Configuration Use Semantic Versioning Pin Critical Dependencies Document Your Configuration Keep It Minimal Good (minimal) Overkill for simple projects Validation Missing Required Fields Invalid YAML Syntax Invalid Version Format Migration Guide From Cargo Projects From Python Projects Next Steps","category":"package-management"},{"id":53,"title":"Environment Management","description":"Save, share, and restore exact package environments","slug":"/package-management/environment-management","content":"Environment Management Environment management in HORUS allows you to capture, save, and restore the exact set of packages and versions used in your project. Perfect for reproducible builds, team collaboration, and deployment. Overview Think of environments like Python's requirements.txt or Node's package-lock.json: - Freeze your current environment to a file - Restore environments on different machines - Share setups with teammates - Deploy exact versions to production robots - Track environment history in version control Understanding HORUS's Hidden Environment HORUS automatically manages a hidden .horus/ environment in each project. Understanding the global vs local architecture helps you work efficiently across multiple projects. Global Cache (Shared Storage) Location: /.horus/cache/ All packages are downloaded once and stored here: Benefits: - Download once - Use in all projects - Saves disk space - No duplication - Faster setup - Cached packages install instantly - Works offline - Already have what you need Local Workspace (Project-Specific) Location: .horus/ in your project Each project gets its own isolated environment: Key Points: - Workspace marker - .horus/ identifies a HORUS project - Symlinks not copies - Points to global cache (lightweight!) - Isolated - Each project independent - Auto-managed - Created by horus run, not by you Automatic Workflow When you run horus run: 1. Reads horus.yaml dependencies 2. Checks global cache - already downloaded? 3. Downloads if missing: - HORUS registry first - crates.io fallback for external Rust crates 4. Compiles external crates (in global cache with cargo) 5. Symlinks to .horus/packages/ in your project 6. For Rust projects: Generates .horus/Cargo.toml from horus.yaml with path-based dependencies 7. Runs your code with correct environment You never touch .horus/ - It's automatic! Why This Matters Portable: horus.yaml works on any machine Lightweight: Projects stay small Isolated: Projects don't interfere Solving De","headings":"Environment Management Overview Understanding HORUS's Hidden Environment Global Cache (Shared Storage) Local Workspace (Project-Specific) Automatic Workflow Why This Matters Team member clones your project Without HORUS (traditional) Total: 1.5 GB duplicated! With HORUS (global cache) Total: 500 MB globally, ~10 KB per project! Different versions supported Both work - isolated environments Solving Dependency Hell Scenario: Global cache has broken package When you run: Uses local serde@1.0.150 (line 1010-1012 in run.rs) NEVER checks global cache Broken global version ignored! Option 1: Remove symlink and reinstall locally Option 2: Install different version locally Option 3: Clear global and reinstall Quick Start Save Your Environment Freeze to default file (horus-freeze.yaml) Freeze to custom file Freeze and publish to registry Restore an Environment Restore from local file Restore from registry Environment Files Format HORUS Environment Generated: 2025-10-09T14:32:15Z System: Linux 6.14.0-33-generic Total: 3 packages (+ 1 transitive dependency) File Locations Freezing Environments horus env freeze Basic Freeze Custom Output File Save to specific file Timestamp-based filename Publish to Registry Freeze and upload to registry Restoring Environments horus env restore Restore from File Restore from local file Restore from Registry Restore using environment ID Common Workflows Development Workflow 1. Clone project 2. Restore environment 3. Run project 1. Install new package 2. Test 3. Freeze updated environment 4. Commit changes Production Deployment 1. Test locally 2. Freeze environment 3. Publish to registry Output: envabc123def456 4. Deploy to robot Team Collaboration Team lead freezes environment Output: envteamdev001 Team members restore Multiple Environments Development Staging Production Switch to staging Switch to production Rollback Restore previous working environment Or restore from registry Environment Comparison Best Practices Version Control Add to git .gitignore (auto-generated by horus new) Environment Naming Good Bad Documentation Periodic Freezes Before major changes After successful testing Before deployment Environment Hygiene Remove unused packages Refreeze Troubleshooting Package Not Available Option 1: Update environment file Remove or replace unavailable package Option 2: Install alternative Option 3: Use cached version Checksum Mismatch Reinstall the package Version Conflicts Option 1: Install compatible version Option 2: Edit environment file manually Change pathfinding-utils version to compatible one Option 3: Remove conflicting package Registry Unavailable Use local file instead Ignoring Files and Packages The ignore Section Configuration Optional: Ignore files, directories, and packages Pattern Matching Use Cases Behavior Example Workflow Create some debug/experimental files Only main.py runs, debug files and experiments are ignored Ignored files can still be run explicitly Best Practices Next Steps","category":"package-management"},{"id":54,"title":"Package Management","description":"Install, publish, and manage reusable HORUS components","slug":"/package-management/package-management","content":"Package Management Note: Publishing packages requires the marketplace backend to be deployed. Installing public packages works immediately. HORUS provides a comprehensive package management system for sharing and discovering robotics components. Create reusable nodes, message types, and algorithms that the community can use. Overview The package system allows you to: - Install packages from multiple sources (HORUS registry, crates.io, PyPI) - Publish your work for others to use - Manage dependencies automatically - Version control with semantic versioning - Search and discover community packages Package Sources HORUS supports installing packages from multiple sources: Description Curated robotics packages Rust ecosystem packages Python ecosystem packages Git repositories (via horus.yaml) Local filesystem (via horus.yaml) Quick Start Installing a Package Automatic Source Detection HORUS automatically detects the package source: 1. First checks HORUS registry 2. Then checks both PyPI and crates.io 3. If found in multiple sources, prompts you to choose: System Package Detection If a package is already installed system-wide, HORUS offers to reuse it: What happens during installation: 1. Detects package source (HORUS registry, crates.io, or PyPI) 2. Downloads package from the appropriate source 3. Resolves dependencies automatically 4. Caches locally in /.horus/cache/ or .horus/packages/ 5. Makes package available for use Using an Installed Package Publishing Your Package Package Locations Local Packages Project-local (default): Why use local: - Different projects can use different versions - Clean separation per project - Easy to delete with project Global Packages System-wide (installed with -g flag): Naming conventions by source: Directory Format <name@<version/ <name@<version/ pypi<name@<version/ git<hash/ Why use global: - Share common packages across all projects - Save disk space (one copy for everything) - Faster install after first download Priority Order & Smar","headings":"Package Management Overview Package Sources Quick Start Installing a Package Install from HORUS registry Install from crates.io (auto-detected) Install from PyPI (auto-detected) Install specific version Install globally (share across all projects) Automatic Source Detection System Package Detection Using an Installed Package Publishing Your Package 1. Authenticate first (one-time) 2. Navigate to your project 3. Publish Package Locations Local Packages Global Packages Priority Order & Smart Dependency Resolution Default behavior (no flags) If package exists in global cache: Install to global cache Create symlink: .horus/packages/serde -> ~/.horus/cache/serde@1.0.228/ Disk efficient! If package NOT in global cache: Install directly to .horus/packages/serde@1.0.228/ No symlink, real directory Isolated from global! Scenario: Global cache has broken serde@1.0.228 Fix: Install working version locally Result: horus run will use this, ignoring broken global! Package Commands horus pkg install From HORUS registry From crates.io (auto-detected) From PyPI (auto-detected) Global installation Install to specific workspace Installing from crates.io Installing from PyPI Using Python Packages In your Python node Or HORUS automatically adds package paths when using horus run horus pkg remove Remove local package Remove from global cache Remove from specific workspace horus pkg list Search by keyword horus pkg unpublish Unpublish a specific version Skip confirmation prompt Authentication (for Publishing) Quick Authentication Setup Login with GitHub Verify you're logged in Remove credentials GitHub OAuth Login Run login command API Keys (for CI/CD) Interactive generation Set for session Use horus commands Save to file manually CI/CD Integration Install HORUS Copy project Build and publish Environment Variables Security Best Practices Verify permissions Should show: -rw------- (600) Fix if needed Backup credentials (encrypted) Creates ~/.horus/credentials.gpg Restore 1. Generate new key 2. Update CI/CD secrets with the new key (Do this manually in your CI/CD platform) 3. Test new key 4. Revoke old key via registry web interface Visit https://marketplace.horus-registry.dev to manage keys Authentication Troubleshooting Check current status Re-authenticate Verify credentials file exists Re-login (auto-refreshes token) Or use API key instead Verify key format Should start with: horuslive Check key status via registry web interface Visit https://marketplace.horus-registry.dev Generate new key Verify authentication Check package ownership via registry web interface Visit https://marketplace.horus-registry.dev For package ownership transfer, contact registry support Re-login Check browser popup blockers Verify GitHub account Advanced Authentication Topics Set registry URL Authenticate Use as normal Save current credentials Login with second account Switch back Publishing Packages Prerequisites Publishing Workflow 1. Navigate to package directory 2. Verify everything builds 3. Publish Adding Documentation and Source Links Documentation Options Source Repository Complete Publishing Example How Users See Your Links Version Management 1. Update version in Cargo.toml 2. Publish Dependency Management Automatic Resolution Specifying Dependencies Optional dependencies Package Structure Minimal Package Library Package (lib.rs) Node Implementation Example Usage Best Practices Package Design Good: Focused packages Bad: Kitchen sink package Documentation PID Controller Features Installation Usage Examples License Testing Run tests Run examples Build in release mode Versioning Strategy Changelog [1.2.0] - 2025-10-09 Added Fixed [1.1.0] - 2025-09-15 Added [1.0.0] - 2025-08-01 Common Workflows Creating a Package Library 1. Create new project as library 2. Update Cargo.toml 3. Implement in src/lib.rs 4. Add examples Create examples/demo.rs 5. Test 6. Publish Using Multiple Packages Install packages Use in your project Updating Dependencies Update specific package to newer version Check available versions on registry Troubleshooting Package Not Found Check spelling Search registry for correct package name Version Conflict Option 1: Update conflicting package Option 2: Pin version manually Edit Cargo.toml: Build Failures Clean and rebuild Check dependencies via registry web interface Visit https://marketplace.horus-registry.dev Install dependencies manually if needed Authentication Required Opens browser for GitHub OAuth Registry Unavailable Check internet connection Try again later (registry might be down) Use cached packages if available Registry API Direct API Access Next Steps","category":"package-management"},{"id":55,"title":"Using Pre-Built Nodes","description":"The idiomatic way to build HORUS applications with ready-made components","slug":"/package-management/using-prebuilt-nodes","content":"Using Pre-Built Nodes The HORUS Philosophy: Don't reinvent the wheel. Use comprehensive, battle-tested nodes from the marketplace and horuslibrary, then configure them to work together. Why Use Pre-Built Nodes? Advantages of pre-built nodes: - Production-ready and tested - Configure instead of coding - Focus on application logic, not infrastructure - Nodes use standard HORUS interfaces for interoperability Quick Example Instead of writing a PID controller from scratch, just install and configure: That's it! Production-ready PID control in 3 lines. Discovering Pre-Built Nodes From the Marketplace Web Interface: Browse by category: - Control - PID controllers, motion planners - Perception - Camera, LIDAR, sensor fusion - Drivers - Motor controllers, sensor interfaces - Safety - Emergency stop, watchdogs - Utilities - Loggers, data recorders CLI Search: From Standard Library The horuslibrary crate includes common nodes: Installation Patterns Installing from HORUS Marketplace Installing from crates.io Installing from PyPI Using Standard Library Add to your Cargo.toml: No installation needed - just import and use! The Idiomatic Pattern 1. Discover What You Need Example Goal: Build a mobile robot with keyboard control Required Nodes: - Input: Keyboard control - Control: Velocity command processing - Output: Motor driver 2. Search and Install 3. Configure and Compose That's it! A functional robot in 20 lines, no custom nodes needed. Common Workflows Mobile Robot Base Sensor Fusion System Vision Processing Pipeline Configuration Best Practices Use Builder Patterns Many nodes support fluent configuration: Parameter-Based Configuration Configure nodes via the parameter system: Adjust at runtime via monitor! Environment-Based Setup Composing Complex Systems Pipeline Pattern Chain nodes together via topics: Parallel Processing Multiple nodes at same priority run concurrently: Safety Layering Critical nodes run first: When to Build Custom Nodes Use pre-built nodes when: - Functi","headings":"Using Pre-Built Nodes Why Use Pre-Built Nodes? Quick Example Install from marketplace Discovering Pre-Built Nodes From the Marketplace Visit the marketplace in your browser Search for specific functionality From Standard Library Installation Patterns Installing from HORUS Marketplace Latest version Specific version Multiple packages Installing from crates.io Rust packages are auto-detected Installing from PyPI Python packages are auto-detected Using Standard Library The Idiomatic Pattern 1. Discover What You Need 2. Search and Install Check what's available Install what you need 3. Configure and Compose Common Workflows Mobile Robot Base Install components Sensor Fusion System Vision Processing Pipeline Configuration Best Practices Use Builder Patterns Parameter-Based Configuration Environment-Based Setup Save your configuration Deploy to another robot Composing Complex Systems Pipeline Pattern Parallel Processing Safety Layering When to Build Custom Nodes Finding the Right Node By Use Case By Hardware Search by device type By Category Package Quality Indicators Complete Example: Autonomous Robot Next Steps","category":"package-management"},{"id":56,"title":"Benchmarks","description":"Research-grade and production-validated performance testing with real robotics workloads","slug":"/performance/benchmarks","content":"HORUS Benchmarks: Research-Grade & Production-Validated Comprehensive performance validation combining academic rigor with real-world robotics workloads. Benchmark Quality Standards This benchmark suite meets both research publication standards and production validation requirements: Research-Grade Methodology - Statistical rigor: Criterion.rs with 20+ samples per measurement - Confidence intervals: Min/mean/max with outlier detection - Controlled methodology: 1s warm-up, 5s measurement phases - Reproducible: &lt;1% variance across measurements - Comprehensive coverage: 5 workload types, 4 scalability points Production Validation - Real workloads: Control loops, sensor fusion, I/O operations - Fault injection: Circuit breaker recovery testing - Scale testing: Validated up to 200 concurrent nodes - Mixed patterns: Combined blocking/non-blocking operations - Long-running: 25+ second fault tolerance tests Executive Summary HORUS delivers sub-microsecond to low-microsecond latency for production robotics applications: Size Throughput Headroom 16 B 2.7M msg/s 2,700x BatteryState 600 ns 1 Hz 304 B 1.8M msg/s 18,000x Odometry 1.1 μs 50 Hz 1.5 KB 633K msg/s 63,300x PointCloud (1K) 12 μs 30 Hz 120 KB 4.7K msg/s 157x Framework Medium Msg HORUS Link (SPSC) 160 ns 313 ns 1.1 μs ROS2 (DDS) 100-500 μs 20-50 μs 500 μs - 5 ms Message Size Hub Latency vs ROS2 16 B 313 ns 230-575x faster 104 B 600 ns 83-286x faster 304 B 940 ns 53-250x faster 736 B 1.1 μs 45-167x faster 1,480 B 2.2 μs 23-111x faster Application HORUS (Link) ROS2 Motor control 248 ns 50 μs 100 Hz 940 ns 53-125x Lidar SLAM 900 ns 100 μs 30 Hz 360 μs 14-42x Planning 600 ns 100 μs Methodology Benchmark Pattern: Ping-Pong HORUS uses the industry-standard ping-pong benchmark pattern for IPC latency measurement: Why Ping-Pong? - Industry standard: Used by ROS2, iceoryx2, ZeroMQ benchmarks - Prevents queue buildup: Each message acknowledged before next send - Realistic: Models request-response patterns in robotics - Comparab","headings":"HORUS Benchmarks: Research-Grade & Production-Validated Benchmark Quality Standards Research-Grade Methodology Production Validation Executive Summary Performance Highlights Key Findings Production Readiness Detailed Results CmdVel (Motor Control Command) LaserScan (2D Lidar Data) IMU (Inertial Measurement Unit) Odometry (Pose + Velocity) PointCloud (3D Perception) Small (100 points @ 30Hz) Medium (1,000 points @ 30Hz) Large (10,000 points @ 30Hz) Mixed Workload (Realistic Robot Loop) Comparison with traditional frameworks Latency Comparison Latency by Message Size Running Benchmarks Yourself Quick Run Expected Output Use Case Selection Message Type Guidelines Performance Characteristics Strengths Technical Details Real-World Applications Methodology Benchmark Pattern: Ping-Pong Test Environment Message Realism Statistical Rigor Measurement Details Scheduler Performance Enhanced Smart Scheduler Comprehensive Benchmark Results Scalability Performance Real-Time Performance RTNode Support RT Performance Characteristics Safety-Critical Configuration Real-Time Test Results Summary Next Steps","category":"performance"},{"id":57,"title":"Performance Optimization","description":"Get maximum performance from HORUS","slug":"/performance/performance","content":"Performance Optimization Why HORUS is Fast Shared Memory Architecture Zero network overhead: Data written once to /dev/shm, read directly by subscribers Zero serialization: Fixed-size structs copied directly to shared memory Zero-copy loan pattern: Publishers write directly to shared memory slots Cache-Optimized Structures 64-byte alignment: Matches CPU cache line size Padding prevention: False sharing eliminated with explicit padding Atomic operations: Lock-free operations with appropriate memory ordering Wait-Free & Lock-Free Operations Wait-free Link (SPSC): 87ns send latency - no CAS loops, bounded constant time Lock-free Hub (MPMC): 313ns latency - CAS-based for multi-producer coordination Per-consumer tracking: Each subscriber maintains independent position Benchmark Results Measured Latency Size HORUS (Link) Speedup 16B 87ns 230-575x IMU 500ns 80-150µs 1.5KB 400ns 68-750x PointCloud 360µs 500µs-1ms Key insight: Latency scales linearly with message size. Throughput HORUS can handle: - 12M+ messages/second for small messages (16B) with Link - 3M+ messages/second for small messages (16B) with Hub - 1M+ messages/second for medium messages (1KB) - 100K+ messages/second for large messages (100KB) Build Optimization Always Use Release Mode Debug builds are 10-100x slower: Why it matters: - Debug: 50µs per tick - Release: 500ns per tick - 100x difference for the same code Profile-Guided Optimization (PGO) Enable PGO for additional 10-20% speedup: Warning: Slower compilation, but faster execution. Target CPU Features CPU-Specific Optimizations: HORUS compiles with Rust compiler optimizations enabled in release mode. For advanced CPU-specific tuning, the framework is optimized for modern x86-64 and ARM64 processors. Gains: 5-15% from CPU-specific SIMD instructions (automatically enabled in release builds). Message Optimization Use Fixed-Size Types Impact: Fixed-size avoids heap allocations in hot path. Choose Typed Messages Over Generic Performance impact at 1kHz: - Ty","headings":"Performance Optimization Why HORUS is Fast Shared Memory Architecture Cache-Optimized Structures Wait-Free & Lock-Free Operations Benchmark Results Measured Latency Throughput Build Optimization Always Use Release Mode SLOW: Debug build FAST: Release build Profile-Guided Optimization (PGO) Cargo.toml Target CPU Features Message Optimization Use Fixed-Size Types Choose Typed Messages Over Generic FAST: Typed hub (Python) IPC: ~500ns, Logging: ~100ns SLOW: Generic hub IPC: ~10µs, Logging: ~5µs (100x slower logging!) Choose Appropriate Precision Minimize Message Size Batch Small Messages Node Optimization Keep tick() Fast Pre-Allocate in init() Avoid Unnecessary Cloning Minimize Logging Scheduler Optimization Understanding Tick Rate Use Priority Levels Minimize Node Count Ultra-Low-Latency Networking (Linux) Transport Options Enable iouring Transport Build with iouring support Enable Batch UDP (Linux) Batch UDP is automatically enabled on Linux - no extra dependencies needed Enable All Ultra-Low-Latency Features Build with all ultra-low-latency features (iouring) Smart Transport Selection Shared Memory Optimization Check Available Space Increase /dev/shm Size Increase to 4GB Clean Up Stale Topics Clean all HORUS shared memory (if needed after crashes) Choose Appropriate Capacity Profiling and Measurement Built-In Metrics IPC Latency Logging Manual Profiling CPU Profiling Profile your application View results Common Performance Pitfalls Pitfall: Using Debug Builds SLOW: 50µs/tick FAST: 500ns/tick Pitfall: Allocations in tick() Pitfall: Excessive Logging Pitfall: Large Message Types Pitfall: Synchronous I/O in tick() Performance Checklist Measuring Your Performance Latency Measurement Throughput Measurement Next Steps","category":"performance"},{"id":58,"title":"Async Nodes","description":"Python async/await support for non-blocking HORUS nodes","slug":"/python/api/async-nodes","content":"Async Nodes HORUS provides native Python async/await support through AsyncNode and AsyncHub classes. These enable non-blocking I/O operations, making it easy to integrate with async libraries, HTTP APIs, databases, and other async-native Python code. Overview Description Base class for async nodes with async def tick() AsyncHub AsyncNode The AsyncNode class lets you use Python's native async/await syntax: Lifecycle Methods Description One-time initialization before first tick async def tick() Cleanup when node stops | Running an AsyncNode AsyncHub AsyncHub provides async send/receive operations: API Reference Async Subscriptions Subscribe with async callbacks for reactive patterns: Utility Functions HORUS provides async utility functions: Complete Example: Async HTTP API Node When to Use AsyncNode Good use cases: - HTTP/REST API integration - Database operations (asyncpg, aioredis) - WebSocket connections - File I/O operations - Any I/O-bound operations Not ideal for: - CPU-bound computations (use regular Node with multiprocessing) - Real-time control loops requiring deterministic timing - Operations requiring &lt;1ms latency Mixing Sync and Async You can mix regular Node and AsyncNode in the same scheduler: See Also - Python Bindings - Core Python API - ML Utilities - ML inference helpers - Examples - More Python examples","headings":"Async Nodes Overview AsyncNode Lifecycle Methods Running an AsyncNode Create scheduler Add async node Run - scheduler handles the async event loop AsyncHub Create async hub Async send Async receive (waits for message) Try receive (returns None immediately if no message) API Reference Async Subscriptions Utility Functions Non-blocking sleep Run multiple async operations concurrently Wait with timeout Complete Example: Async HTTP API Node When to Use AsyncNode Mixing Sync and Async Both work together See Also","category":"python"},{"id":59,"title":"Python API","description":"HORUS Python bindings API reference","slug":"/python/api","content":"Python API Complete Python API documentation for HORUS. Python Bindings Full reference for the HORUS Python bindings: - Installation and setup - Creating nodes in Python - Publishing and subscribing - Per-node rate control - Automatic timestamps - Multiprocess support","headings":"Python API [Python Bindings](/python/api/python-bindings)","category":"python"},{"id":60,"title":"Python Bindings","description":"Production-ready Python API for HORUS robotics with advanced features","slug":"/python/api/python-bindings","content":"HORUS Python Bindings Production-Ready Python API for the HORUS robotics framework - combines simplicity with advanced features for professional robotics applications. Why HORUS Python? - Zero Boilerplate: Working node in 10 lines - Flexible API: Functional style or class inheritance - your choice - Production Performance: 500ns latency (same shared memory as Rust) - Per-Node Rate Control: Different nodes at different frequencies (100Hz sensor, 10Hz logger) - Automatic Timestamps: Built-in message timing and staleness detection - Typed Messages: Optional type-safe messages from Rust - Multiprocess Support: Process isolation and multi-language nodes - Pythonic: Feels like native Python, not wrapped C++ - Rich Ecosystem: Use NumPy, OpenCV, scikit-learn, etc. Quick Start Installation Automatic (Recommended) Python bindings are automatically installed when you run the HORUS installer: The installer will detect Python 3.9+ and automatically build and install the bindings. Manual Installation If you prefer to install manually or need to rebuild: Requirements: - Python 3.9+ - Rust 1.70+ - Linux (for shared memory support) Minimal Example This minimal example demonstrates functional-style node creation without class boilerplate. Core API Creating a Node Parameters: - name (str, optional): Node name (auto-generated if omitted) - pubs (str list[str], optional): Topics to subscribe from - tick (callable): Function called each cycle - rate (int, optional): Execution rate in Hz (default: 30) - init (callable, optional): Setup function - shutdown (callable, optional): Cleanup function Alternative: Class-Based Inheritance For those who prefer OOP, you can inherit from horus.Node: Both patterns work! Use functional style for simplicity or class inheritance for complex nodes with state. Node Functions Your tick function receives the node as a parameter: Node Methods: - node.send(topic, data) - Publish message - node.get(topic) - Get one message (returns None if empty) - node.getall(","headings":"HORUS Python Bindings Why HORUS Python? Quick Start Installation From HORUS root directory Install maturin (Python/Rust build tool) Build and install from source Minimal Example Core API Creating a Node Alternative: Class-Based Inheritance Use it Node Functions Running Nodes Single node Multiple nodes Examples 1. Simple Publisher 2. Subscriber 3. Pub/Sub Pipeline Create pipeline Run all together 4. Using Lambda Functions Producer (inline) Transformer (inline) 5. Multi-Topic Robot Controller 6. Lifecycle Management Advanced Features (Production-Ready) Priority-Based Execution Automatic Timestamps Multiprocess Execution Run multiple Python files as separate processes Mix Python and Rust nodes Mix Rust and Python sensornode.py controllernode.py Run both in separate processes Complete Example: All Features Together Create nodes Configure with different rates and priorities Check statistics Network Communication Hub Network Endpoints Local (shared memory) - default Network (UDP direct) Router (TCP broker for WAN/NAT traversal) Link Class (Point-to-Point) === MACHINE 1 (Producer) === Connects to consumer at 192.168.1.20:9000 === MACHINE 2 (Consumer) === Listens on port 9000 No \"@\" in endpoint = local shared memory Router Client (WAN/NAT Traversal) Create router client for explicit connection management Build endpoints through the router Use endpoints with Hub Router properties Default router (localhost:7777) Custom router address Start a local router (for development/testing) For production, use CLI instead: $ horus router start --port 7777 When to Use What Multi-Machine Example === ROBOT (192.168.1.50) === Local: Critical flight control (ultra-fast) Network: Telemetry to ground station Network: Commands from ground station === GROUND STATION (192.168.1.100) === Receive telemetry from robot Send commands to robot Integration with Python Ecosystem NumPy Integration OpenCV Integration scikit-learn Integration Advanced Patterns State Management Rate Limiting Error Handling Performance Tips 1. Use Per-Node Rate Control NEW: Use scheduler with per-node rates for optimal performance High-frequency sensor (100Hz) Medium-frequency control (50Hz) Low-frequency logging (10Hz) Monitor performance with getnodestats() 2. Monitor Message Staleness 3. Use Dicts for Messages Send messages as Python dicts (automatically serialized to JSON) Check message age using node method 4. Batch Processing 5. Keep tick() Fast GOOD: Fast tick BAD: Slow tick 6. Offload Heavy Processing 7. Use Multiprocess for CPU-Intensive Tasks Isolate heavy processing in separate processes Each node gets its own CPU core Development Building from Source Debug build (fast compile, slow runtime) Release build (slow compile, fast runtime) Build wheel for distribution Running Tests Install test dependencies Run all tests Run specific feature tests With coverage Test multiprocess execution (Phase 4) Mock Mode If Rust bindings aren't available, automatically falls back to mock You'll see: \"Warning: Rust bindings not available. Running in mock mode.\" Use for unit testing Python logic without HORUS running Debugging Tips Enable logging for specific nodes Check node statistics Monitor message timestamps Interoperability With Rust Nodes Cross-Language with Typed Hubs Python node with typed hub Generic Hub (String Topics) Generic Hub - for custom topics Common Patterns Producer-Consumer Producer Consumer Request-Response Periodic Tasks Troubleshooting Import Errors If you see: ModuleNotFoundError: No module named 'horus' Rebuild and install: Slow Performance Use release build (not debug) Check tick rate isn't too high Memory Issues Avoid accumulating data in closures BAD: GOOD: Monitor Integration and Logging Current Limitations Internal implementation (simplified) Scheduler Logging Flag Monitoring Python Nodes These print to console, not monitor Get stats after running Future Improvements See Also","category":"python"},{"id":61,"title":"Python Examples","description":"Python code examples for HORUS robotics applications","slug":"/python/examples","content":"Python Examples Complete Python examples demonstrating HORUS capabilities. All examples are available in the horuspy/examples/ directory. Available Examples Description Basic async node usage Rust-Python communication ML pose estimation Network Hub communication Network Link communication Custom message types High-performance patterns Multi-robot routing HTTP API integration Simple Async Example Basic async I/O with HORUS: Cross-Language Communication Communicate between Python and Rust nodes: Usage: ML Pose Estimation Using ONNX models with HORUS: Network Hub Example Distributed communication across machines: Custom Data Types Sending custom data structures: Running Examples See Also - Python Bindings - Core Python API - Async Nodes - Async/await support - ML Utilities - ML inference helpers - Multi-Language - Rust-Python integration","headings":"Python Examples Available Examples Simple Async Example Cross-Language Communication Python publisher, Rust subscriber Python subscriber, Rust publisher ML Pose Estimation Network Hub Example Local shared memory (same machine) Network UDP (cross-machine) Automatic transport selection Send locally Send over network Receive from network Custom Data Types Using GenericMessage for custom data Send Python dict (auto-serialized) Receive Running Examples Navigate to examples directory Run any example See Also","category":"python"},{"id":62,"title":"Python Documentation","description":"HORUS Python bindings, library, and examples","slug":"/python","content":"Python Documentation Python bindings for the HORUS robotics framework with the same performance as Rust. Sections API Reference Python API documentation and bindings reference. - Python Bindings - Complete Python API Library Python-specific nodes and utilities. - Message Library - Python message types - Hardware Nodes - Python hardware interfaces AI Integration Integrate HORUS with PyTorch, TensorFlow, and other ML frameworks.","headings":"Python Documentation Sections [API Reference](/python/api) [Library](/python/library) [AI Integration](/development/ai-integration)","category":"python"},{"id":63,"title":"Python Library","description":"Python-specific nodes and utilities for HORUS","slug":"/python/library","content":"Python Library Python-specific components for HORUS. Message Library Python message types compatible with Rust messages. Hardware Nodes Python implementations for hardware interfaces.","headings":"Python Library [Message Library](/python/library/python-message-library) [Hardware Nodes](/python/library/python-hardware-nodes)","category":"python"},{"id":64,"title":"Python ML Utilities","description":"Machine learning helper classes for PyTorch, TensorFlow, and ONNX integration in Python HORUS nodes","slug":"/python/library/ml-utilities","content":"Python ML Utilities HORUS provides Python ML utility classes in horus.mlutils for easy integration with popular machine learning frameworks. These helper classes handle model loading, preprocessing, inference, and performance tracking. Overview The mlutils module provides: Framework Any PyTorch TensorFlow/Keras ONNX Runtime Any Base Class: MLNodeBase All ML inference nodes inherit from MLNodeBase: PyTorch Integration PyTorchInferenceNode Usage with HORUS Node TensorFlow Integration TensorFlowInferenceNode ONNX Integration ONNXInferenceNode ONNX Runtime provides cross-platform inference for models exported from PyTorch, TensorFlow, and other frameworks. Preprocessing Utilities The module includes common preprocessing functions: ImageNet Preprocessing YOLO Preprocessing Non-Maximum Suppression Performance Monitoring Track inference performance in real-time: Available Statistics Description Average inference time minlatencyms Slowest inference stdlatencyms Median latency p95latencyms 99th percentile fps Zero-Copy Tensor Integration Combine ML utilities with HORUS tensor pool for zero-copy data sharing: Complete Example See Also - Python Bindings - Core Python API - GPU Tensor Sharing - Zero-copy GPU memory - AI Integration - Rust-native ML inference","headings":"Python ML Utilities Overview Base Class: MLNodeBase PyTorch Integration PyTorchInferenceNode Usage with HORUS Node Run TensorFlow Integration TensorFlowInferenceNode ONNX Integration ONNXInferenceNode Preprocessing Utilities ImageNet Preprocessing Standard ImageNet preprocessing for classification models Returns (1, C, H, W) normalized tensor YOLO Preprocessing Letterbox preprocessing for YOLO models Returns preprocessed image and transform params for postprocessing Non-Maximum Suppression Filter overlapping detections Performance Monitoring In your inference loop Get statistics Or print summary Available Statistics Zero-Copy Tensor Integration Create tensor pool Allocate tensor Zero-copy to numpy Zero-copy to PyTorch For GPU tensors Complete Example See Also","category":"python"},{"id":65,"title":"Python Hardware Nodes","description":"Ready-to-use Python nodes for sensors, actuators, and peripherals","slug":"/python/library/python-hardware-nodes","content":"Python Hardware Nodes HORUS provides ready-to-use Python nodes for common robotics hardware. These nodes handle the low-level hardware communication, letting you focus on your robot's logic. Overview Hardware Simulation UART/RS232 Yes JoystickNode pygame Keyboard Yes ImuNode smbus2 NMEA GPS Yes CameraNode opencv-python RPLidar Yes Parameter Default port \"/dev/ttyUSB0\" int Baud rate topicprefix \"serial\" int Data bits (5-8) parity 'N' float Stop bits (1/1.5/2) timeout 0.1 bool Enable simulation mode Parameter Default deviceid 0 str Topic name prefix deadzone 0.1 bool Enable simulation mode Parameter Default topicprefix \"keyboard\" bool Enable simulation mode Parameter Default i2cbus 1 int I2C device address topicprefix \"imu\" str TF frame ID accelscale 16384.0 float Gyroscope scale factor simulation False Message Type Simulation Data In simulation mode, the IMU generates: - Gravity vector: (0, 0, 9.81) m/s² - Small gyroscope drift over time - Temperature: 25°C constant GpsNode NMEA GPS receiver via serial port. Usage Parameters Type Description str Serial port baudrate 9600 str Topic name prefix frameid \"gps\" bool Enable simulation mode Parameter Default deviceid 0 int Frame width height 480 float Target framerate topicprefix \"camera\" str TF frame ID simulation False Message Type Example: Object Detection LidarNode 2D LiDAR scanner using RPLidar. Usage Parameters Type Description str Serial port topicprefix \"scan\" str TF frame ID numsamples 360 float Min range (meters) rangemax 12.0 bool Enable simulation mode Node SerialNode Zero axes/buttons KeyboardNode Gravity (0,0,9.81), small drift GpsNode Black frame with \"SIMULATION\" text LidarNode See Node Simulation Mode for details. Best Practices 1. Handle Missing Hardware 2. Use Topic Prefixes 3. Combine with Custom Nodes API Reference Data Classes Node Classes Top-Level Import See Also - Python Bindings - Core Python API - Node Simulation Mode - Simulation details - Built-in Nodes - Rust node reference","headings":"Python Hardware Nodes Overview Installation All hardware dependencies Or install individually Quick Start Create nodes (simulation mode if hardware unavailable) Run with scheduler SerialNode Usage Create serial node Topics: serial.rx - Incoming data (SerialData) serial.tx - Outgoing data (subscribe to send) Direct API Parameters Message Type JoystickNode Usage Topics: joy.state   - Full state (JoystickState) joy.axes    - List of axis values joy.buttons - List of button states Parameters Message Type Example: Tank Drive Control KeyboardNode Usage Topics: keyboard.events  - Key events (KeyboardState) keyboard.pressed - Currently pressed keys (set) Parameters Message Type Example: WASD Teleop ImuNode Usage Topics: imu - IMU data (ImuData) Parameters Message Type Simulation Data GpsNode Usage Topics: gps.fix - GPS fix data (GpsData) Parameters Message Type Simulation Data CameraNode Usage Topics: camera.image     - ImageData message camera.imageraw - Raw numpy array (for CV processing) Parameters Message Type Example: Object Detection LidarNode Usage Topics: scan - LaserScan data Parameters Message Type Supported Hardware Example: Obstacle Avoidance Simulation Mode Enabling Simulation Explicit simulation Auto-fallback (if hardware unavailable) Simulation Data Best Practices 1. Handle Missing Hardware Node will auto-fallback to simulation if hardware fails Check if running in simulation 2. Use Topic Prefixes Multiple cameras Subscribe to specific camera 3. Combine with Custom Nodes API Reference Data Classes Node Classes Top-Level Import All nodes available from main horus module See Also","category":"python"},{"id":66,"title":"Python Message Library","description":"Standard robotics message types for Python","slug":"/python/library/python-message-library","content":"Python Message Library (horus.library) The horus.library module provides typed message classes for robotics applications in Python. These messages are compatible with Rust and enable cross-language communication. Overview Key Features: - Cross-language compatible - Binary-compatible with Rust message types - Automatic timestamps - All messages include microsecond-precision timestamps - Validation methods - Built-in checks for finite values, normalized quaternions, etc. - Pickle support - Can be serialized for Python-only communication - NumPy integration - LaserScan uses NumPy arrays for zero-copy efficiency Geometry Messages Pose2D 2D robot pose (position + orientation). Fields: - x (float): X position in meters - y (float): Y position in meters - theta (float): Orientation in radians - timestamp (int, read-only): Microsecond timestamp Use with Hub: Twist 3D velocity (linear + angular). Fields: - linear (list[3]): Linear velocity [x, y, z] in m/s - angular (list[3]): Angular velocity [roll, pitch, yaw] in rad/s - timestamp (int, read-only): Microsecond timestamp Transform 3D transformation (translation + rotation quaternion). Fields: - translation (list[3]): Position [x, y, z] in meters - rotation (list[4]): Orientation quaternion [x, y, z, w] - timestamp (int, read-only): Microsecond timestamp Point3, Vector3, Quaternion Basic 3D geometric types. Control Messages CmdVel 2D velocity command (linear + angular). Fields: - linear (float): Forward velocity in m/s - angular (float): Angular velocity in rad/s (positive = counter-clockwise) - timestamp (int, read-only): Microsecond timestamp Use with Hub: Sensor Messages LaserScan 2D LIDAR scan data (360-point array). Fields: - ranges (NumPy array[360]): Distance readings in meters - anglemin (float): Start angle in radians - anglemax (float): End angle in radians - rangemin (float): Minimum valid range in meters - rangemax (float): Maximum valid range in meters - angleincrement (float): Angular resolution in radians - ti","headings":"Python Message Library (horus.library) Overview Option 1: Import everything (recommended) Option 2: Import specific types Geometry Messages Pose2D Create pose Static constructors Properties (read/write) Methods Twist Create 3D twist Create 2D twist (common for ground robots) Stop command Properties Validation Transform Create transform Static constructors Properties Methods Point3, Vector3, Quaternion Point3 - 3D position Vector3 - 3D vector with operations Quaternion - 3D rotation Control Messages CmdVel Create velocity command Stop command Properties Sensor Messages LaserScan Create laser scan Set ranges (must be exactly 360 elements) Set scan parameters Access ranges as NumPy array (zero-copy) Query methods Length Send Receive Cross-Language Compatibility Python sender Usage Patterns Robot Controller with Multiple Sensors Create hubs outside tick function Pose Tracking Track robot pose See Also","category":"python"},{"id":67,"title":"Control Messages","description":"Motor control, servo, PID, trajectory, and joint command messages","slug":"/rust/api/control-messages","content":"Control Messages HORUS provides comprehensive message types for controlling motors, servos, and multi-joint robotic systems. MotorCommand Direct motor control with multiple control modes. Control Modes: Value 0 1 2 3 Fields: Type u8 u8 f64 f64 f64 f64 bool u64 DifferentialDriveCommand Commands for differential drive robots. Fields: Type f64 f64 f64 bool u64 ServoCommand Position-controlled servo commands. Fields: Type u8 f32 f32 bool u64 PwmCommand PWM motor control for DC motors. Fields: Type u8 f32 u32 bool bool f32 u64 StepperCommand Stepper motor control with various modes. Control Modes: Value 0 1 2 3 Fields: Type u8 u8 f64 f64 f64 bool u16 u16 u64 PidConfig PID controller configuration. Fields: Type u8 f64 f64 f64 f64 f64 bool u64 TrajectoryPoint Single point in a trajectory. Fields: Type [f64; 3] [f64; 3] [f64; 3] [f64; 4] [f64; 3] f64 JointCommand Multi-joint command for robot arms and manipulators. Control Modes: Value 0 1 2 Fields: Type [[u8; 32]; 16] u8 [f64; 16] [f64; 16] [f64; 16] [u8; 16] u64 Motor Control Node Example See Also - Differential Drive Algorithm - Kinematics - PID Algorithm - PID controller implementation - DC Motor Node - Motor driver node - Servo Controller Node - Servo driver - Stepper Motor Node - Stepper driver","headings":"Control Messages MotorCommand DifferentialDriveCommand ServoCommand PwmCommand StepperCommand PidConfig TrajectoryPoint JointCommand Motor Control Node Example See Also","category":"rust"},{"id":68,"title":"Coordination Messages","description":"Multi-robot coordination, fleet management, task assignment, and formation control","slug":"/rust/api/coordination-messages","content":"Coordination Messages HORUS provides message types for coordinating multiple robots, fleet management, task assignment, swarm behavior, and formation control. RobotState Individual robot state information for fleet management. RobotType values: Description General purpose mobile robot Manipulator Drone/UAV Marine Fixed sensor/processing unit Tool Logistics robot Service RobotCapability flags: Bit 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Fields: Type [u8; 32] Pose2D Twist StatusLevel f32 u32 u32 f32 RobotType u8 f32 u64 FleetStatus Fleet-wide status overview (up to 64 robots). CoordinationMode values: Description Robots coordinate directly Centralized Multiple coordination levels MarketBased Emergent swarm behavior Field Description robots Robot states array robotcount Number of active robots fleetid Fleet identifier activetasks Total active tasks coordinationmode Fleet coordination mode coordinatorid Central coordinator ID emergencyactive Fleet-wide emergency averagebattery Average battery level commhealth Communication health (0.0-1.0) timestamp Nanoseconds since epoch Type Navigation Pick and place Transport Area/object inspection Cleaning Monitoring task Emergency Maintenance task DataCollection Communication relay Formation User-defined task Status Assigned Task executing Completed Task failed Cancelled Task suspended Aborted Fields: Type u32 [u8; 32] TaskType u8 u64 f64 u32 [u8; 64] u64 u64 TaskStatus u64 FormationControl Formation control parameters for coordinated movement. FormationType values: Description Line formation Column V-formation Circle Grid formation Diamond Follow a leader Custom Fields: Type FormationType [u8; 32] u8 [f64; 2] f64 f64 f64 Twist f32 bool u64 AuctionBid Market-based task allocation bid. BidStatus values: Description Bid submitted and active Won Bid lost the auction Withdrawn Bid expired Field Description taskid Task being bid on robotid Bidding robot ID bidvalue Bid value (cost/utility) estimatedtime Estimated completion time capabili","headings":"Coordination Messages RobotState FleetStatus TaskAssignment FormationControl AuctionBid Fleet Manager Node Example See Also","category":"rust"},{"id":69,"title":"horus_core","description":"Core runtime API - nodes, communication, and scheduling","slug":"/rust/api/core","content":"horuscore The core runtime crate for the HORUS robotics framework. Provides the fundamental building blocks for creating distributed real-time robotics systems. Node The fundamental trait for all computation units in HORUS. Required Methods name Returns the unique identifier for this node. Must be a static string. Returns: &'static str - The node's name Example: tick Called repeatedly by the scheduler. This is the main execution loop for the node. Parameters: - ctx - Optional mutable reference to node runtime context Example: Optional Methods init Called once before the first tick. Use for initialization that may fail. Parameters: - ctx - Mutable reference to node runtime context Returns: Result<()- Ok on success, Err on failure Default: Returns Ok(()) shutdown Called when the scheduler is stopping. Use for cleanup. Parameters: - ctx - Mutable reference to node runtime context Returns: Result<()- Ok on success, Err on failure Default: Returns Ok(()) onerror Called when an error occurs during tick execution. Parameters: - error - Error message string - ctx - Mutable reference to node runtime context Default: Logs the error Example Implementation Hub Generic multi-producer, multi-consumer (MPMC) pub/sub channel using shared memory. Type Parameters - T - Message type. Must implement: Send + Sync + Clone + Debug + Serialize + DeserializeOwned + 'static Constructors new Creates a new Hub with default capacity (1024 messages). Parameters: - topicname - Unique identifier for the topic Returns: HorusResult<Hub<TExample: newwithcapacity Creates a Hub with custom buffer capacity. Parameters: - topicname - Unique identifier for the topic - capacity - Maximum number of messages in buffer Returns: HorusResult<Hub<TExample: fromconfig Creates a Hub from configuration file (horus.toml). Parameters: - hubname - Name of the hub in config file Returns: HorusResult<Hub<TConfig Example: Methods send Sends a message to the topic. Non-blocking, 200ns latency. Parameters: - msg - Message ","headings":"horuscore Node Required Methods name tick Optional Methods init shutdown onerror Example Implementation Hub Type Parameters Constructors new newwithcapacity fromconfig Methods send recv gettopicname getmetrics getconnectionstate Network Endpoints Link Type Parameters Associated Types LinkRole LinkMetrics Scheduler Constructors new Builder Methods withname withcapacity withconfig enabledeterminism enablelearning withsafetymonitor Node Management add addwithtier addrt setnoderate setnodelogging Execution run runfor tick tickfor stop isrunning OS Integration (Linux) setrealtimepriority pintocpu lockmemory Example NodeInfo Constructors new Accessors name state metrics config Logging loginfo logdebug logwarning logerror State Management transitiontoerror transitiontocrashed restart Usage Pattern HorusError Factory Methods Predicates HorusResult Enums NodeState HealthStatus ConnectionState Structs NodeMetrics NodeConfig HubMetrics TopicMetadata Traits Channel Publisher Subscriber Performance","category":"rust"},{"id":70,"title":"Diagnostics Messages","description":"System monitoring, health checks, heartbeats, and error reporting","slug":"/rust/api/diagnostics-messages","content":"Diagnostics Messages HORUS provides message types for system monitoring, health checks, error reporting, and general diagnostics. Heartbeat Periodic signal indicating a node is alive and operational. Fields: Type [u8; 32] u32 u64 bool f64 u64 Status General-purpose status reporting. StatusLevel values: Value 0 1 2 3 Fields: Type StatusLevel u32 [u8; 128] [u8; 32] u64 EmergencyStop Critical safety message to immediately stop all robot motion. Fields: Type bool [u8; 64] [u8; 32] bool u64 ResourceUsage System resource utilization. Fields: Type f32 u64 f32 u64 f32 u64 u64 f32 u32 u64 DiagnosticValue Key-value pair for diagnostic reports. Value Type Constants: Value 0 1 2 3 Fields: Type [u8; 32] [u8; 64] u8 DiagnosticReport Diagnostic report with multiple key-value pairs (up to 16). Fields: Type [u8; 32] [DiagnosticValue; 16] u8 StatusLevel u64 NodeState Node execution state enumeration. NodeState values: Value 0 1 2 3 4 5 HealthStatus Node operational health status. HealthStatus values: Value 0 1 2 3 4 NodeHeartbeat Node status heartbeat with health information (written to shared memory). Fields: Type NodeState HealthStatus u64 u32 u32 u32 u64 u64 SafetyStatus Safety system status. Mode Constants: Value 0 1 2 Fields: Type bool bool bool bool bool u8 u32 u64 Diagnostics Node Example See Also - Coordination Messages - Fleet status, robot state - Safety Layer Algorithm - Safety monitoring implementation","headings":"Diagnostics Messages Heartbeat Status EmergencyStop ResourceUsage DiagnosticValue DiagnosticReport NodeState HealthStatus NodeHeartbeat SafetyStatus Diagnostics Node Example See Also","category":"rust"},{"id":71,"title":"Force & Tactile Messages","description":"Force sensing, tactile arrays, impedance control, and haptic feedback","slug":"/rust/api/force-messages","content":"Force & Tactile Messages HORUS provides message types for force/torque sensors, tactile arrays, impedance control, and haptic feedback systems commonly used in manipulation tasks. WrenchStamped 6-DOF force and torque measurement from force/torque sensors. Fields: Type Vector3 Vector3 Point3 [u8; 32] u64 Low-Pass Filtering TactileArray Pressure/force array from tactile sensors (fingertip sensors, skin patches). Arrangement Types: Value 0 1 2 Fields: Type [f32; 64] u8 u8 u8 u8 f32 f32 [u8; 32] u64 ImpedanceParameters Impedance control parameters for compliant manipulation. Fields: Type [f64; 6] [f64; 6] [f64; 6] [f64; 6] bool u64 ForceCommand Hybrid force/position control command. Fields: Type Vector3 Vector3 [bool; 6] Vector3 Vector3 Vector3 [f64; 6] f64 [u8; 32] u64 ContactInfo Contact detection and classification. ContactState values: Description No contact detected InitialContact Established contact ContactLoss Sliding contact Impact HapticFeedback Haptic feedback commands for user interfaces. Pattern Types: Value 0 1 2 Force Control Node Example See Also - Force-Torque Sensor Node - F/T sensor driver - Geometry Messages - Vector3, Point3 - Safety Layer Algorithm - Safety monitoring","headings":"Force & Tactile Messages WrenchStamped Low-Pass Filtering TactileArray ImpedanceParameters ForceCommand ContactInfo HapticFeedback Force Control Node Example See Also","category":"rust"},{"id":72,"title":"API Reference","description":"Complete API reference for the HORUS robotics framework","slug":"/rust/api","content":"API Reference Welcome to the HORUS API reference documentation. This section provides detailed documentation for all public types, traits, and functions in the HORUS framework. Crates Description Core runtime - nodes, communication, scheduling horusmessages Procedural macros (node!, message!) Type Module Node horuscore Hub<T horuscore Link<T horuscore Scheduler horuscore NodeInfo horuscore Type Module HorusError horuscore HorusResult<T horuscore Type Module Image horusmessages LaserScan horusmessages Imu horusmessages Twist horusmessages Pose horusmessages HORUS Version MSRV 0.1.x 1.70.0 | See Also - Core Concepts - Understanding HORUS architecture - Examples - Working code examples - Built-in Nodes - Pre-built node library","headings":"API Reference Crates Quick Reference Core Types Error Handling Message Types Import Patterns Minimal Import Full Import Version Compatibility See Also","category":"rust"},{"id":73,"title":"I/O & Industrial Messages","description":"Digital/analog I/O, SPI, I2C, serial, CAN bus, and Modbus messages","slug":"/rust/api/io-messages","content":"I/O & Industrial Messages HORUS provides message types for interfacing with digital/analog I/O, industrial protocols, and communication buses. DigitalIO Digital input/output pin states. Fields: Type [bool; 32] u8 [bool; 32] [bool; 32] [[u8; 16]; 32] [u8; 32] u64 AnalogIO Analog input/output channels. Fields: Type [f64; 16] u8 [[f64; 2]; 16] [[u8; 8]; 16] [[u8; 16]; 16] u8 f32 [u8; 32] u64 SpiMessage SPI bus transaction. SPI Modes: Value CPHA 0 0 MODE1 0 2 0 MODE3 1 Fields: Type u8 u8 u8 u32 u8 [u8; 256] [u8; 256] u16 bool bool bool bool u64 I2cMessage I2C bus transaction. Transaction Types: Value 0 1 2 3 Clock Speeds: Value 100,000 400,000 1,000,000 Fields: Type u16 u8 u8 [u8; 256] u8 u8 u32 bool u8 u64 SerialData Serial/UART data. Parity Options: Value 0 1 2 Fields: Type [u8; 64] [u8; 1024] u16 u32 u8 u8 u8 u64 CanFrame CAN bus frame (CAN 2.0 and CAN-FD). Constants: Value 8 64 0x7FF 0x1FFFFFFF Fields: Type u32 bool bool bool [u8; 64] u8 bool bool bool [u8; 16] u64 ModbusMessage Modbus RTU/TCP communication. Function Codes: Value 1 2 3 4 5 6 15 16 Fields: Type u8 u8 u16 u16 [u16; 32] u8 u8 u16 bool u64 NetworkStatus Network interface status. SafetyRelayStatus Safety relay monitoring. I/O Node Example See Also - I2C Bus Node - I2C driver node - SPI Bus Node - SPI driver node - CAN Bus Node - CAN driver node - Serial Node - Serial/UART driver - Modbus Node - Modbus communication - Digital I/O Node - GPIO driver","headings":"I/O & Industrial Messages DigitalIO AnalogIO SpiMessage I2cMessage SerialData CanFrame ModbusMessage NetworkStatus SafetyRelayStatus I/O Node Example See Also","category":"rust"},{"id":74,"title":"horus_macros","description":"Procedural macros for reducing boilerplate","slug":"/rust/api/macros","content":"horusmacros Procedural macros for reducing boilerplate in HORUS applications. node! Declarative macro for creating HORUS nodes with minimal boilerplate. Syntax Sections pub - Publishers Define topics this node publishes to. Generated code: - Hub<Typefield for each publisher - Automatic initialization in new() sub - Subscribers Define topics this node subscribes to. Generated code: - Hub<Typefield for each subscriber - Automatic initialization in new() data - Internal State Define internal fields with default values. tick(ctx) - Main Loop Required. Called every scheduler cycle (60 Hz by default). init(ctx) - Initialization Called once before the first tick. shutdown(ctx) - Cleanup Called once when the scheduler stops. impl - Custom Methods Add helper methods to the node. Generated Code The macro generates: 1. Struct definition with all fields 2. new() constructor that initializes Hubs 3. Node trait implementation 4. Default trait implementation Examples Minimal Node Publisher Only Subscriber Only Full Pipeline With Lifecycle Usage message! Macro for defining custom message types compatible with HORUS communication. Syntax Features The macro automatically implements: - Clone, Debug - Serialize, Deserialize (serde) - LogSummary trait for debugging - Default trait - Fixed-size representation for shared memory Example With Arrays Complex Types Best Practices Keep tick() Fast Pre-allocate in init() Use Descriptive Names Handle Errors Gracefully Troubleshooting \"Cannot find type in scope\" Import message types: \"Expected ,, found {\" Check arrow syntax: \"Node name must be CamelCase\" ctx is Option, not direct reference See Also - node! Macro Guide - Detailed tutorial - message! Macro Guide - Custom messages - horuscore API - Core types reference","headings":"horusmacros node! Syntax Sections pub - Publishers sub - Subscribers data - Internal State tick(ctx) - Main Loop init(ctx) - Initialization shutdown(ctx) - Cleanup impl - Custom Methods Generated Code Examples Minimal Node Publisher Only Subscriber Only Full Pipeline With Lifecycle Usage message! Syntax Features Example With Arrays Complex Types Best Practices Keep tick() Fast Pre-allocate in init() Use Descriptive Names Handle Errors Gracefully Troubleshooting \"Cannot find type in scope\" \"Expected ,, found {\" \"Node name must be CamelCase\" ctx is Option, not direct reference See Also","category":"rust"},{"id":75,"title":"horus_messages","description":"Standard message types for robotics communication","slug":"/rust/api/messages","content":"horusmessages Standard message types for robotics communication. All messages are designed for zero-copy shared memory transport. Geometry Spatial primitives for position, orientation, and motion. Twist 3D velocity command with linear and angular components. Constructors Methods Description Returns true if all values are finite Method distanceto(&other) Normalize theta to [-π, π] isvalid() Transform Full 3D transformation (translation + quaternion rotation). Constructors Methods Description Check if quaternion is normalized normalizerotation() Point3 3D point in space. Methods Vector3 3D vector for representing directions and velocities. Methods Description Vector length normalize() Dot product cross(&other) Quaternion Quaternion for 3D rotation representation. Constructors Sensor Standard sensor data formats. LaserScan 2D LiDAR scan data with 360 range measurements. Constructors Methods Description Get angle for range index israngevalid(index) Count valid readings minrange() Example Imu IMU sensor data (orientation, angular velocity, acceleration). Constructors Methods Description Set orientation from Euler angles hasorientation() Check if all values are finite angularvelocityvec() Get linear acceleration as Vector3 Method setframes(frame, child) Update pose and velocity isvalid() NavSatFix GPS/GNSS position data. Constants Methods Description Create from coordinates hasfix() Check coordinate validity horizontalaccuracy() Distance to another position (Haversine) Method new(voltage, percentage) Check if below threshold iscritical() Estimated time in seconds Method data() Get metadata string if present tovalue::<T() Example Performance Notes All message types are optimized for shared memory transport: Size 64 bytes 32 bytes 1.5 KB Variable 4.5 KB For best performance, prefer typed messages over GenericMessage when possible. Detailed Message Documentation For comprehensive documentation of specialized message types, see: Description Image, CameraInfo, Detection, Compr","headings":"horusmessages Geometry Twist Constructors Methods Pose2D Constructors Methods Transform Constructors Methods Point3 Methods Vector3 Methods Quaternion Constructors Sensor LaserScan Constructors Methods Example Imu Constructors Methods Odometry Methods NavSatFix Constants Methods BatteryState Constants Methods Range Vision Image ImageEncoding CameraInfo Detection Control MotorCommand ServoCommand PidConfig GenericMessage Constructors Methods Example Performance Notes Detailed Message Documentation","category":"rust"},{"id":76,"title":"Machine Learning Messages","description":"ML model inference, training, pose estimation, and LLM integration messages","slug":"/rust/api/ml-messages","content":"Machine Learning Messages HORUS provides message types for ML model inference, training, object detection, pose estimation, and LLM integration in robotics applications. Tensor Generic tensor for ML model inputs and outputs. DataType values: Rust f32 f64 i8 i16 i32 i64 u8 u16 u32 u64 bool Fields: Type Vec<f32 Vec<usize DataType Option<String Predictions Generic predictions from ML classification models. Fields: Type Vec<u32 Vec<f32 Option<Vec<String HashMap<String, String Detection Object detection bounding box result. Fields: Type [f32; 4] u32 Option<String f32 Option<u32 DetectionArray Array of object detections from a single image. Fields: Type Vec<Detection u32 u32 u64 SegmentationMask Semantic segmentation per-pixel predictions. Fields: Type Vec<u8 u32 u32 u32 Vec<String u64 Keypoint Single keypoint in pose estimation. Fields: Type f32 f32 Option<f32 f32 String Pose Human pose estimation result for a single person. Fields: Type Vec<Keypoint f32 u32 Option<[f32; 4] PoseArray Multi-person pose estimation results. Fields: Type Vec<Pose u32 u32 u64 Classification Top-K classification results. Fields: Type Vec<u32 Vec<String Vec<f32 u64 FeatureVector Feature embeddings for similarity search and transfer learning. Fields: Type Vec<f32 Option<String u64 ModelInfo ML model metadata and configuration. ModelFormat values: Description Open Neural Network Exchange TFLite PyTorch (.pt/.pth) TensorFlow Tract runtime format TensorRT Apple CoreML Field Description name Model name version Model version (semver) format Model format inputshapes Input tensor shapes outputshapes Output tensor shapes inputnames Input tensor names outputnames Output tensor names metadata Additional metadata Field Description latencyms Inference latency (ms) throughput Samples per second modelname Model identifier batchsize Batch size used timestampns Nanoseconds since epoch Field Description role \"system\", \"user\", or \"assistant\" content Message content Field Description messages Conversation history ","headings":"Machine Learning Messages Tensor Predictions Detection DetectionArray SegmentationMask Keypoint Pose PoseArray Classification FeatureVector ModelInfo InferenceMetrics LLM Messages ChatMessage LLMRequest LLMResponse TrainingMetrics TrajectoryPoint (Imitation Learning) DeploymentConfig ML Inference Node Example See Also","category":"rust"},{"id":77,"title":"Navigation Messages","description":"Path planning, goals, waypoints, occupancy grids, and cost maps","slug":"/rust/api/navigation-messages","content":"Navigation Messages HORUS provides message types for autonomous navigation, path planning, mapping, and localization systems. Goal Navigation goal specification with tolerance and timeout. Fields: Type Pose2D f64 f64 f64 u8 u32 u64 GoalStatus Goal execution status enumeration. Status Values: Value 0 1 2 3 4 5 6 GoalResult Goal status feedback with progress information. Fields: Type u32 GoalStatus f64 f64 f32 [u8; 64] u64 Waypoint Single waypoint in a navigation path. Fields: Type Pose2D Twist f64 f32 bool Path Navigation path with up to 256 waypoints. Fields: Type [Waypoint; 256] u16 f64 f64 [u8; 32] [u8; 32] u64 PathPlan Simplified path plan for basic navigation. Fields: Type Vec<[f32; 3] [f32; 3] u32 u64 OccupancyGrid 2D occupancy grid map for navigation. Occupancy Values: Meaning Unknown 0 Probably free 50-99 Occupied Field Description resolution Meters per pixel width Map width in pixels height Map height in pixels origin Map origin (bottom-left) data Occupancy values frameid Coordinate frame metadata Map metadata timestamp Nanoseconds since epoch Value 0 Increasing cost (near obstacles) 253 Reserved Field Description occupancygrid Base occupancy map costs Cost values (0-255) inflationradius Inflation radius (meters) costscalingfactor Cost decay factor lethalcost Lethal obstacle threshold Field Description position Obstacle position [x, y] velocity Obstacle velocity [vx, vy] radius Obstacle radius (meters) timehorizon Collision prediction horizon obstacleid Tracking ID Field Description obstacles Obstacle array count Number of valid obstacles timestamp Nanoseconds since epoch | Navigation Node Example See Also - A Path Planning - A pathfinding implementation - Pure Pursuit Algorithm - Path tracking controller - Occupancy Grid Algorithm - Grid-based mapping - Geometry Messages - Pose2D, Twist","headings":"Navigation Messages Goal GoalStatus GoalResult Waypoint Path PathPlan OccupancyGrid CostMap VelocityObstacle VelocityObstacles Navigation Node Example See Also","category":"rust"},{"id":78,"title":"Perception Messages","description":"3D perception, point cloud, and depth sensing message types","slug":"/rust/api/perception-messages","content":"Perception Messages HORUS provides message types for 3D perception tasks including point clouds, depth images, bounding boxes, and plane detection. PointCloud 3D point cloud message compatible with ROS PointCloud2 format. Fields: Type u32 u32 [PointField; 16] u8 bool u32 u32 Vec<u8 [u8; 32] u64 PointField Describes a field within the point cloud data: PointFieldType values: Rust i8 u8 i16 u16 i32 u32 f32 f64 BoundingBox3D 3D bounding box for object detection. Fields: Type Point3 Vector3 Quaternion [u8; 32] f32 u32 u64 BoundingBoxArray3D Array of 3D bounding boxes (max 32). DepthImage Depth image from depth cameras (RealSense, Kinect, etc.). Fields: Type u32 u32 Vec<u16 u16 u16 f32 [u8; 32] u64 PlaneDetection Detected planar surface. Fields: Type [f64; 4] Point3 Vector3 [f64; 2] u32 f32 [u8; 16] u64 PlaneArray Array of detected planes (max 16). Use in Nodes See Also - Geometry Messages - Point3, Vector3, Quaternion - Vision Messages - Image, Detection, Segmentation - Depth Camera Node - Depth camera driver","headings":"Perception Messages PointCloud PointField BoundingBox3D BoundingBoxArray3D DepthImage PlaneDetection PlaneArray Use in Nodes See Also","category":"rust"},{"id":79,"title":"Tensor Messages","description":"Zero-copy tensor types for ML workloads","slug":"/rust/api/tensor-messages","content":"Tensor Messages Zero-copy tensor sharing between nodes for ML/AI workloads. HorusTensor A 200 byte descriptor pointing to data in shared memory: TensorDtype Size 4 2 2 1 1 TensorDevice With TensorPool Python Interop","headings":"Tensor Messages HorusTensor TensorDtype TensorDevice With TensorPool Python Interop","category":"rust"},{"id":80,"title":"TensorPool API","description":"Zero-copy tensor memory management for high-performance robotics and AI/ML","slug":"/rust/api/tensor-pool","content":"TensorPool API HORUS provides efficient tensor memory management through shared memory pools, enabling zero-copy data sharing between processes for both CPU and GPU tensors. Overview The TensorPool system consists of: - TensorPool - CPU tensor allocation via shared memory - CudaTensorPool - GPU tensor allocation with CUDA IPC support - TensorHandle - RAII wrapper for automatic memory management - HorusTensor - Lightweight tensor descriptor (metadata only) CPU TensorPool Creating a Pool Allocating Tensors Supported Data Types Rust u8 u16 u32 u64 i8 i16 i32 i64 f32 f64 GPU TensorPool (CUDA) Enable with the cuda feature: Creating a GPU Pool GPU Tensor Allocation Cross-Process GPU Sharing HorusTensor Structure The tensor descriptor that gets shared between processes: Python API Performance CPU TensorPool Latency 100ns Cross-process access GPU TensorPool Latency 260µs Allocation (1080p) 3.4ms IPC handle transfer 156µs Pool open IPC vs Memcpy For a 1080p RGB f32 tensor (24MB): Latency 2.26ms 26ns Best Practices 1. Reuse pools: Create pools once at startup, not per-tensor 2. Match dtypes: Ensure sender and receiver use same dtype 3. Close IPC handles: Always close imported handles to prevent leaks 4. Check CUDA availability: Guard GPU code with cudaavailable() See Also - GPU Tensor Sharing - Detailed CUDA IPC guide - Zero-Copy Shared Memory - How HORUS achieves zero-copy","headings":"TensorPool API Overview CPU TensorPool Creating a Pool Allocating Tensors Supported Data Types GPU TensorPool (CUDA) Creating a GPU Pool GPU Tensor Allocation Cross-Process GPU Sharing HorusTensor Structure Python API Check CUDA availability Create tensor pool Allocate CPU tensor Transfer to GPU Get IPC handle for sharing Zero-copy PyTorch integration Performance CPU TensorPool GPU TensorPool IPC vs Memcpy Best Practices See Also","category":"rust"},{"id":81,"title":"Vision Messages","description":"Camera, image, calibration, and visual detection messages","slug":"/rust/api/vision-messages","content":"Vision Messages HORUS provides message types for cameras, images, camera calibration, and visual detection/recognition systems. Image Raw image data message. ImageEncoding values: Channels Description 1 8-bit monochrome Mono16 2 3 8-bit RGB Bgr8 3 4 8-bit RGBA Bgra8 4 2 YUV 4:2:2 Mono32F 4 3 32-bit float RGB BayerRggb8 1 1 16-bit depth (mm) Field Description width Image width in pixels height Image height in pixels encoding Pixel encoding format step Bytes per row (with padding) data Row-major image data frameid Camera identifier timestamp Nanoseconds since epoch Format \"jpeg\" PNG compression \"webp\" Fields: Type [u8; 8] Vec<u8 u32 u32 [u8; 32] u64 CameraInfo Camera calibration information. Camera Matrix (3x3): Projection Matrix (3x4): Fields: Type u32 u32 [u8; 16] [f64; 8] [f64; 9] [f64; 9] [f64; 12] [u8; 32] u64 RegionOfInterest Region of interest (bounding box) in an image. Fields: Type u32 u32 u32 u32 bool Detection Visual detection/recognition result. Fields: Type [u8; 32] f32 RegionOfInterest Option<Transform u32 u64 DetectionArray Array of visual detections (up to 32). Fields: Type [Detection; 32] u8 u32 u32 [u8; 32] u64 StereoInfo Stereo camera pair information. Fields: Type CameraInfo CameraInfo f64 f64 Vision Processing Node Example See Also - ML Messages - DetectionArray, Tensor, Predictions - Perception Messages - PointCloud, DepthImage - TensorPool API - Zero-copy tensor memory","headings":"Vision Messages Image CompressedImage CameraInfo RegionOfInterest Detection DetectionArray StereoInfo Vision Processing Node Example See Also","category":"rust"},{"id":82,"title":"Advanced Examples","description":"Complex patterns, state machines, multi-process systems, and Python integration","slug":"/rust/examples/advanced-examples","content":"Advanced Examples Advanced HORUS patterns for complex robotics systems. These examples demonstrate state machines, priority-based safety systems, multi-process architectures, and cross-language communication. Prerequisites: Complete Basic Examples first. 1. State Machine Node Implement complex behavior using state machines - ideal for autonomous robots with multiple operating modes. File: statemachine.rs Run it: Key Concepts: - Enum for states: Idle, Moving, ObstacleDetected, Rotating, Escaped - Match expression handles state transitions - Each state defines behavior and next state - Log state transitions for debugging 2. Priority-Based Safety System Use node priorities to ensure safety-critical tasks always run first - essential for production robotics. File: safetysystem.rs Run it: Key Concepts: - Priority 0 (Critical): Emergency stop - runs first, always - Priority 1 (High): Motor control - runs after safety checks - Priority 4 (Background): Logging - runs last, non-critical - Lower number = higher priority - Safety systems should always check estop before acting 3. Python Multi-Process System Build a complete sensor monitoring system with Python nodes running as independent processes. Project Structure Sensor Node nodes/sensor.py: Controller Node nodes/controller.py: Logger Node nodes/logger.py: Run All Nodes Concurrently Output: Key Features: - Independent Processes: Each node runs in its own process - Shared Memory IPC: Nodes communicate via HORUS topics (/dev/shm/horus/) - Color-Coded Output: Each node has a unique color - Graceful Shutdown: Ctrl+C stops all processes cleanly - Zero Configuration: No launch files needed 4. Rust + Python Cross-Language System Mix Rust and Python nodes in the same application. Rust Sensor Node nodes/rustsensor.rs: Python Controller Node nodes/pycontroller.py: Rust Actuator Node nodes/rustactuator.rs: Run Mixed System HORUS automatically detects file types and compiles/runs appropriately! Key Concepts: - Rust nodes: High perform","headings":"Advanced Examples 1. State Machine Node 2. Priority-Based Safety System 3. Python Multi-Process System Project Structure Sensor Node Controller Node Logger Node Run All Nodes Concurrently Make scripts executable Run all nodes as separate processes 4. Rust + Python Cross-Language System Rust Sensor Node Python Controller Node Rust Actuator Node Run Mixed System 5. Advanced Python Features Create nodes with different rates Run all nodes When to Use Multi-Process vs Single-Process Multi-Process (Concurrent Execution) Single-Process Performance Notes Multi-Process IPC Performance Single-Process Performance Testing Multi-Node Systems Next Steps","category":"rust"},{"id":83,"title":"Basic Examples","description":"Simple HORUS patterns for beginners","slug":"/rust/examples/basic-examples","content":"Basic Examples Learn HORUS fundamentals through simple, focused examples. Each example is complete and runnable with horus run. Estimated time: 30-45 minutes Prerequisites - HORUS installed (Installation Guide) - Completed Quick Start - Basic Rust knowledge 1. Basic Publisher-Subscriber The foundational pattern in HORUS: one node publishes data, another subscribes. Publisher Node File: publisher.rs Run it: Subscriber Node File: subscriber.rs Run it: HORUS uses a flat namespace (like ROS), so processes automatically share topics: Both use the same topic name (\"sensordata\") → communication works automatically! Combined Application File: pubsub.rs Run it: Key Concepts: - Publisher uses Hub::new(\"topic\") to create publisher - Subscriber uses same topic name \"sensordata\" - Priority matters: Publisher (0) runs before Subscriber (1) - recv() returns Option<T- handle None gracefully 2. Robot Velocity Controller Control a robot using standard CmdVel messages. File: robotcontroller.rs Run it: Key Concepts: - CmdVel is a standard robotics message type - CmdVel::new(linear, angular) creates velocity commands - Differential drive: left = linear - angular, right = linear + angular - Use shutdown() to send safe stop commands 3. Lidar Obstacle Detection Process laser scan data to detect obstacles and stop the robot. File: obstacledetector.rs Run it: Key Concepts: - LaserScan has 360 range readings (one per degree) - scan.minrange() finds closest obstacle - scan.israngevalid(index) checks if reading is good - Safety nodes should run at HIGH priority 4. PID Controller Implement a PID controller for position tracking. File: pidcontroller.rs Run it: Key Concepts: - PID = Proportional + Integral + Derivative - Proportional: immediate response to error - Integral: corrects accumulated error - Derivative: dampens oscillations - Tune gains (Kp, Ki, Kd) for your system 5. Multi-Node Pipeline Chain multiple processing stages together. File: pipeline.rs Run it: Key Concepts: - Data flows: Sen","headings":"Basic Examples Prerequisites 1. Basic Publisher-Subscriber Publisher Node Subscriber Node Terminal 1 Terminal 2 (automatically connects!) Combined Application 2. Robot Velocity Controller 3. Lidar Obstacle Detection 4. PID Controller 5. Multi-Node Pipeline Next Steps","category":"rust"},{"id":84,"title":"Rust Examples","description":"Working examples demonstrating HORUS patterns in Rust","slug":"/rust/examples","content":"Rust Examples Learn HORUS through working examples. Basic Examples Fundamental patterns for beginners: - Publisher-Subscriber communication - State machines - Multi-node systems - Error handling patterns Advanced Examples See Advanced Examples for complex patterns including: - State machines with persistence - Multi-process systems - Cross-language (Rust + Python) systems","headings":"Rust Examples [Basic Examples](/rust/examples/basic-examples) Advanced Examples","category":"rust"},{"id":85,"title":"Rust Documentation","description":"HORUS Rust API, library, and examples","slug":"/rust","content":"Rust Documentation Complete Rust documentation for the HORUS robotics framework. Sections API Reference Core Rust API documentation including Node, Hub, Link, Scheduler, and message types. Library Built-in nodes and algorithms ready to use in your projects. - Built-in Nodes - Sensors, motors, controllers - Algorithms - PID, Kalman, pathfinding, and more Examples Working examples demonstrating HORUS patterns. - Basic Examples - Publisher-subscriber, state machines","headings":"Rust Documentation Sections [API Reference](/rust/api) [Library](/rust/library) [Examples](/rust/examples)","category":"rust"},{"id":86,"title":"AABB Collision Detection","description":"Fast axis-aligned bounding box collision detection","slug":"/rust/library/algorithms/aabb","content":"AABB Collision Detection Axis-Aligned Bounding Box (AABB) collision detection for fast broad-phase collision checking. AABBs are rectangles aligned with coordinate axes, enabling extremely efficient intersection tests. Source Code - AABB Implementation Features - AABB vs AABB intersection - Point containment test - Ray intersection with distance - Box merging and expansion - Center and size queries Quick Start API Reference Constructors Collision Tests Description Check AABB-AABB overlap containspoint(x, y) Check if fully contains another AABB rayintersect(origin, direction) Properties Returns Box width height() (centerx, centery) area() Transformations Description Grow box by margin on all sides merge(&other) Public Fields Example: Robot Collision Checking Example: Broad-Phase Collision Detection Use AABB for fast filtering before expensive narrow-phase checks: Example: Sensor Range Checking Example: Safety Zones Example: Ray Casting for LIDAR Simulation Performance Characteristics AABB collision detection is O(1) per pair: Complexity O(1) O(1) O(1) O(1) For n objects, naive all-pairs checking is O(n²). For better performance with many objects, use spatial partitioning (quad-tree, grid). Limitations AABBs are conservative approximations: - May report false positives for rotated or complex shapes - Don't account for actual object geometry - Best used as broad-phase filter before precise checks For rotated boxes, consider Oriented Bounding Boxes (OBB) or use AABB as a quick filter. See Also - Occupancy Grid - Grid-based mapping - RRT - Path planning with collision checking - Safety Layer - Robot safety enforcement - A Pathfinding - Grid-based navigation","headings":"AABB Collision Detection Source Code Features Quick Start API Reference Constructors Collision Tests Properties Transformations Public Fields Example: Robot Collision Checking Example: Broad-Phase Collision Detection Example: Sensor Range Checking Example: Safety Zones Example: Ray Casting for LIDAR Simulation Performance Characteristics Limitations See Also","category":"rust"},{"id":87,"title":"A* Pathfinding","description":"Grid-based optimal pathfinding using heuristic search","slug":"/rust/library/algorithms/astar","content":"A Pathfinding Grid-based optimal pathfinding algorithm using heuristic search. A finds the shortest path between two points while avoiding obstacles. Source Code - A Implementation Features - Optimal pathfinding with admissible heuristics - 8-directional movement (diagonal allowed) - Configurable heuristic weight for speed/optimality tradeoff - Euclidean, Manhattan, and Diagonal distance heuristics - Obstacle-aware grid navigation Quick Start API Reference Constructor Creates a new A planner with the specified grid dimensions. Configuration Methods Description Set start position setgoal(x, y) Mark cell as obstacle clearobstacle(x, y) Set entire grid (true = obstacle) clearobstacles() Set heuristic function setheuristicweight(w) Enable/disable diagonal movement Heuristic Characteristics Euclidean Admissible, smooth paths Manhattan Fast, grid-aligned paths Diagonal Chebyshev distance Grid Size Notes 100×100 Real-time planning 500×500 Large indoor maps 1000×1000 Outdoor environments | For larger maps, consider: - Using RRT for continuous spaces - Hierarchical planning with multiple resolutions - Caching and incremental replanning Example: Dynamic Replanning See Also - RRT - Sampling-based planning for complex spaces - Pure Pursuit - Path following controller - Occupancy Grid - Grid-based mapping - Path Planner Node - Ready-to-use planning node","headings":"A Pathfinding Source Code Features Quick Start API Reference Constructor Configuration Methods Planning Utility Methods Heuristics Heuristic Weight Movement Options Working with Occupancy Grids Converting to World Coordinates Performance Example: Dynamic Replanning See Also","category":"rust"},{"id":88,"title":"Differential Drive","description":"Forward and inverse kinematics for two-wheeled mobile robots","slug":"/rust/library/algorithms/differential-drive","content":"Differential Drive Kinematics algorithms for differential drive (two-wheeled) mobile robots. Convert between robot velocity commands and wheel speeds, and compute odometry. Source Code - Differential Drive Implementation Features - Forward kinematics (wheel speeds → robot velocity) - Inverse kinematics (robot velocity → wheel speeds) - Odometry calculation from wheel encoders - Configurable wheel base and radius - Unit conversions (angular ↔ linear) Quick Start API Reference Constructor Description Distance between wheel centers (m) Radius of drive wheels (m) Kinematics Methods Unit Conversions Odometry Kinematics Equations Inverse Kinematics Convert robot velocity to wheel speeds: Where: - v = linear velocity (m/s) - ω = angular velocity (rad/s) - L = wheel base (m) Forward Kinematics Convert wheel speeds to robot velocity: Odometry Update pose from wheel speeds: Example: Motor Controller Example: Odometry Node Common Robot Configurations Wheel Base 0.16 m 0.287 m 0.235 m 0.38 m 0.15 m Motion Types Pure Translation (Straight Line) Pure Rotation (Spin in Place) Arc Motion Velocity Limits Calculate maximum achievable velocities: See Also - Differential Drive Node - Ready-to-use node - PID Controller - Motor speed control - Odometry Node - Odometry publishing - Pure Pursuit - Path following","headings":"Differential Drive Source Code Features Quick Start API Reference Constructor Kinematics Methods Unit Conversions Odometry Kinematics Equations Inverse Kinematics Forward Kinematics Odometry Example: Motor Controller Example: Odometry Node Common Robot Configurations Motion Types Pure Translation (Straight Line) Pure Rotation (Spin in Place) Arc Motion Velocity Limits See Also","category":"rust"},{"id":89,"title":"Extended Kalman Filter (EKF)","description":"State estimation for 2D robot localization using sensor fusion","slug":"/rust/library/algorithms/ekf","content":"Extended Kalman Filter (EKF) Extended Kalman Filter for 2D robot localization with pose and velocity estimation. Handles nonlinear motion models through linearization. Source Code - EKF Implementation Features - 2D pose estimation (x, y, theta) - Velocity state tracking (vx, vy, omega) - Prediction (time update) and correction (measurement update) steps - Configurable process and measurement noise - Uncertainty tracking via covariance matrix State Vector The EKF tracks a 6-dimensional state: State x y theta vx vy omega Quick Start API Reference Constructor Creates an EKF with default noise parameters and zero initial state. State Methods Description Set full state vector getstate() Get (x, y, theta) tuple getvelocity() Reset to zero state Method setcovariance(P) Get covariance matrix getpositionuncertainty() Noise Configuration Description Set 6×6 process noise setodometrynoise(R) Filter Steps Description Time update (motion model) updateodometry([x, y, θ]) Motion Model The EKF uses a constant-velocity motion model: Velocities are assumed constant between updates. The model handles angle wrapping to [-π, π] automatically. Tuning Noise Parameters Process Noise (Q) Represents model uncertainty - how much the true state can deviate from the motion model: Guidelines: - Higher Q → Trust model less, adapt faster to changes - Lower Q → Trust model more, smoother estimates - Increase velocity Q for dynamic robots - Increase position Q on rough terrain Measurement Noise (R) Represents sensor uncertainty: Guidelines: - Match actual sensor noise characteristics - Higher R → Trust measurements less - Lower R → Trust measurements more - Use sensor datasheets for initial values Example: Fusing Odometry and GPS Example: Integration with HORUS Nodes Uncertainty Growth Without measurements, uncertainty grows over time: Each measurement update reduces uncertainty. This is the core benefit of Kalman filtering. Comparison: EKF vs Kalman Filter EKF Nonlinear 6 (pose + vel) Automatic wra","headings":"Extended Kalman Filter (EKF) Source Code Features State Vector Quick Start API Reference Constructor State Methods Covariance Methods Noise Configuration Filter Steps Motion Model Tuning Noise Parameters Process Noise (Q) Measurement Noise (R) Example: Fusing Odometry and GPS Example: Integration with HORUS Nodes Uncertainty Growth Comparison: EKF vs Kalman Filter See Also","category":"rust"},{"id":90,"title":"Algorithms Library","description":"Pure computational algorithms for robotics - pathfinding, state estimation, control, and more","slug":"/rust/library/algorithms","content":"Algorithms Library HORUS provides a comprehensive library of pure computational algorithms for robotics. These are standalone implementations with no I/O dependencies, making them easy to test, reuse, and integrate into any node or application. Key Benefits - No I/O Dependencies - Pure computation, no hardware coupling - Fully Tested - 107+ unit tests across all algorithms - Reusable - Use in nodes, applications, or standalone - Well-Documented - Each includes usage examples and API documentation Available Algorithms Category Motion Planning Motion Planning Path Tracking State Estimation State Estimation State Estimation Control Kinematics Mapping Collision Safety Quick Start All algorithms are available through horuslibrary::algorithms: Example: Path Planning + Following Combine algorithms for complete robot navigation: Example: State Estimation Pipeline Combine sensors for robust localization: Algorithm Categories Motion Planning Algorithms for finding collision-free paths: - A - Best for grid-based maps with known obstacles - RRT - Best for high-dimensional or continuous spaces State Estimation Algorithms for estimating robot state from noisy sensors: - EKF - Full 6-state (pose + velocity) estimation with nonlinear models - Kalman Filter - Simpler linear estimation for 1D tracking - Sensor Fusion - Weighted combination of multiple sensors Control Algorithms for controlling actuators: - PID - Classic feedback control for motors, servos, etc. - Pure Pursuit - Path-following controller for mobile robots Kinematics Algorithms for robot motion models: - Differential Drive - Two-wheel robot kinematics and odometry Mapping Algorithms for environment representation: - Occupancy Grid - 2D probabilistic obstacle map Safety Algorithms for safe operation: - AABB - Fast bounding box collision detection - Safety Layer - Multi-level safety enforcement Integration with Nodes Algorithms integrate naturally with HORUS nodes: See Also - Built-in Nodes - Pre-built nodes using these ","headings":"Algorithms Library Key Benefits Available Algorithms Quick Start Example: Path Planning + Following Example: State Estimation Pipeline Algorithm Categories Motion Planning State Estimation Control Kinematics Mapping Safety Integration with Nodes See Also","category":"rust"},{"id":91,"title":"Kalman Filter","description":"Linear state estimation with configurable dimensions","slug":"/rust/library/algorithms/kalman-filter","content":"Kalman Filter Linear Kalman Filter for optimal state estimation with Gaussian noise. Supports arbitrary state and measurement dimensions with configurable system models. Source Code - Kalman Filter Implementation Features - Multi-dimensional state estimation - Configurable state transition matrix (F) - Configurable measurement matrix (H) - Prediction and update steps - Process and measurement noise covariances When to Use Use EKF Instead Nonlinear motion 1D tracking Pose estimation Generic estimation Quick Start API Reference Constructor Description Number of state variables nmeasurements State Methods Description Set state vector getstate() Model Configuration Description State transition matrix (n×n) setmeasurementmatrix(H) Process noise covariance (n×n) setmeasurementnoise(R) Filter Operations Description Time update (prediction step) update(measurement) Kalman Filter Equations Prediction Step Update Step Example: Position-Velocity Tracking Track a moving object with position measurements: Example: Signal Filtering Use Kalman filter to smooth noisy sensor data: Tuning Guidelines Process Noise (Q) Controls how much the model can deviate: Effect Smooth output, slow to adapt Medium (0.1) Responsive, may be noisy R Value Low (0.01) Balanced High (1.0) Initialization Example: 2D Position Tracking Track X and Y position with velocity: Comparison: Kalman Filter vs EKF Kalman Filter Linear only Configurable Simpler Generic tracking None For 2D robot localization with pose (x, y, θ), use EKF instead. See Also - EKF - Nonlinear robot localization - Sensor Fusion - Multi-sensor combination - PID Controller - Feedback control","headings":"Kalman Filter Source Code Features When to Use Quick Start API Reference Constructor State Methods Model Configuration Filter Operations Kalman Filter Equations Prediction Step Update Step Example: Position-Velocity Tracking Example: Signal Filtering Tuning Guidelines Process Noise (Q) Measurement Noise (R) Initialization Example: 2D Position Tracking Comparison: Kalman Filter vs EKF See Also","category":"rust"},{"id":92,"title":"Occupancy Grid","description":"2D grid-based environment mapping for robot navigation","slug":"/rust/library/algorithms/occupancy-grid","content":"Occupancy Grid Grid-based environment representation for robot navigation and mapping. Supports binary and probabilistic occupancy with efficient ray tracing for sensor integration. Source Code - Occupancy Grid Implementation Features - Binary occupancy (free/occupied) - Probabilistic occupancy (0.0 - 1.0) - Ray tracing for sensor data integration - World-to-grid coordinate conversion - Configurable resolution and origin Quick Start API Reference Constructor Cell Manipulation Description Mark cell as occupied (1.0) setfree(x, y) Set occupancy probability (0.0-1.0) clear() Cell Queries Returns Occupancy probability isfree(x, y) true if probability &ge; 0.5 isvalid(x, y) Coordinate Conversion Description World → grid coordinates gridtoworld(gx, gy) Set world origin of grid[0][0] Method getdimensions() Cell size in meters Use Case Grid Size Indoor navigation 200×200 = 10m² Outdoor navigation 500×500 = 50-100m² Detailed mapping 1000×1000 = 10-20m² Coarse planning 100×100 = 50-100m² Grid Size 100×100 2 MB 1000×1000 See Also - A Pathfinding - Grid-based planning - RRT - Continuous space planning - AABB Collision - Fast collision detection - LIDAR Node - LIDAR data processing","headings":"Occupancy Grid Source Code Features Quick Start API Reference Constructor Cell Manipulation Cell Queries Coordinate Conversion Grid Properties Ray Tracing Example: Building a Map from LIDAR Example: Integration with A Planning Example: Probabilistic Mapping Example: HORUS Node Integration Resolution Guidelines Memory Usage See Also","category":"rust"},{"id":93,"title":"PID Controller","description":"Classic feedback control algorithm with anti-windup protection","slug":"/rust/library/algorithms/pid","content":"PID Controller Classic Proportional-Integral-Derivative feedback control algorithm for position, velocity, and process control. Source Code - PID Implementation Features - Proportional, integral, and derivative terms - Anti-windup protection for integral term - Output limiting - Error deadband for noise rejection - Configurable gains at runtime Quick Start API Reference Constructor Description Proportional gain - response to current error ki Derivative gain - response to rate of change Method setgains(kp, ki, kd) Clamp output range setintegrallimits(min, max) Ignore small errors reset() Compute Description Desired target value feedback Time step in seconds Method geterror() Accumulated integral term getderivative() (Kp, Ki, Kd) tuple getstate() PID Tuning Guide Understanding the Terms Proportional (P): Responds to current error - Higher Kp → Faster response, more overshoot - Too high → Oscillation - Too low → Slow, steady-state error Integral (I): Eliminates steady-state error - Accumulates error over time - Higher Ki → Faster error elimination - Too high → Overshoot, oscillation - Anti-windup prevents runaway accumulation Derivative (D): Dampens oscillations - Responds to rate of change - Higher Kd → More damping, noise sensitivity - Too high → Sluggish response, noise amplification Tuning Methods Ziegler-Nichols Method: 1. Set Ki = 0, Kd = 0 2. Increase Kp until sustained oscillation (Ku) 3. Measure oscillation period (Tu) 4. Calculate: Kp = 0.6×Ku, Ki = 2×Kp/Tu, Kd = Kp×Tu/8 Manual Tuning: 1. Start with small Kp, Ki = 0, Kd = 0 2. Increase Kp until acceptable response 3. Add Ki to eliminate steady-state error 4. Add Kd to reduce overshoot Typical Gain Values Kp Kd 1-5 0.01-0.1 Position control 0.5-5 2-10 1-10 | Anti-Windup Prevent integral term from growing unbounded when output is saturated: When to use integral limits: - System has hard actuator limits - Large sustained errors expected (e.g., startup) - Preventing dangerous overshoot Error Deadband Ignore small","headings":"PID Controller Source Code Features Quick Start API Reference Constructor Configuration Methods Compute State Inspection PID Tuning Guide Understanding the Terms Tuning Methods Typical Gain Values Anti-Windup Error Deadband Example: Motor Velocity Control Example: Position Control Example: Cascaded PID Integration with HORUS Nodes See Also","category":"rust"},{"id":94,"title":"Pure Pursuit","description":"Geometric path tracking controller for mobile robots","slug":"/rust/library/algorithms/pure-pursuit","content":"Pure Pursuit Geometric path tracking controller that steers a robot toward a look-ahead point on the path. Simple, robust, and widely used for mobile robot navigation. Source Code - Pure Pursuit Implementation Features - Simple geometric path following - Configurable look-ahead distance - Suitable for differential drive robots - Smooth trajectory tracking - Automatic goal detection Quick Start API Reference Constructor Creates a Pure Pursuit controller with the specified look-ahead distance in meters. Configuration Methods Description Set path as Vec<(f64, f64) setlookaheaddistance(d) Set look-ahead bounds setgoaltolerance(d) Reset to path start Method isgoalreached(pose) Reference to current path getcurrentsegment() Look-Ahead Distance Tuning The look-ahead distance is the key parameter: Guidelines Recommended Look-Ahead 0.2 - 0.4 m 0.5-1.0 m/s 0.8 - 1.5 m Controller Cons Pure Pursuit May cut corners Stanley More complex MPC Computationally expensive PID No path awareness | See Also - A Pathfinding - Path planning - RRT - Sampling-based planning - Differential Drive - Robot kinematics - Path Planner Node - Ready-to-use planning","headings":"Pure Pursuit Source Code Features Quick Start API Reference Constructor Configuration Methods Control State Inspection Look-Ahead Distance Tuning Guidelines Adaptive Look-Ahead Integration with Path Planning HORUS Node Integration Handling Edge Cases Empty Path Robot Off Path Sharp Turns Comparison with Other Controllers See Also","category":"rust"},{"id":95,"title":"RRT (Rapidly-exploring Random Tree)","description":"Sampling-based path planning for complex and high-dimensional spaces","slug":"/rust/library/algorithms/rrt","content":"RRT (Rapidly-exploring Random Tree) Sampling-based motion planning algorithm for finding paths in complex, continuous spaces. RRT builds a tree by randomly sampling the space and connecting samples to the nearest tree node. Source Code - RRT Implementation Features - Probabilistically complete path planning - No grid discretization required - Handles complex obstacle environments - Configurable sampling and growth parameters - Goal biasing for faster convergence When to Use RRT Use A When Grid-based maps Complex/narrow passages 2D navigation Unknown optimal path needed Static environments Method Default setmaxiterations(n) 1000 setstepsize(d) 0.5 setgoaltolerance(d) 0.3 setgoalbias(p) 0.1 Method addobstacle((x, y), radius) Remove all obstacles Method reset() Number of nodes in tree RRT::pathcost(&path) Parameter Tuning Step Size Controls how far the tree extends toward each sample: Guidelines: - Set to 10% of average obstacle spacing - Smaller for narrow passages - Larger for open spaces Goal Bias Probability of sampling the goal directly: Guidelines: - 5-10% for exploration - 20-30% for direct paths - Balance exploration vs exploitation Max Iterations Goal Tolerance How close to goal counts as \"reached\": Example: Dynamic Replanning Example: Path Smoothing RRT paths are often jagged. Smooth them for better execution: Example: Multiple Goals Plan to multiple potential goals: Performance Considerations Impact Planning time Coverage vs speed Convergence speed Collision checks Typical Performance Iterations 100-500 500-2000 2000-10000 Comparison with A See Also - A Pathfinding - Grid-based optimal planning - Pure Pursuit - Path following - Path Planner Node - Ready-to-use planning - Occupancy Grid - Environment mapping","headings":"RRT (Rapidly-exploring Random Tree) Source Code Features When to Use RRT Quick Start API Reference Constructor Configuration Methods Obstacle Management Planning Utility Methods Parameter Tuning Step Size Goal Bias Max Iterations Goal Tolerance Example: Dynamic Replanning Example: Path Smoothing Example: Multiple Goals Performance Considerations Typical Performance Comparison with A See Also","category":"rust"},{"id":96,"title":"Safety Layer","description":"Multi-layered safety monitoring and enforcement for robot control","slug":"/rust/library/algorithms/safety-layer","content":"Safety Layer Multi-layered safety monitoring and enforcement system for robot control. Provides configurable checks for velocity, obstacle distance, battery level, and temperature with automatic status classification. Source Code - Safety Layer Implementation Features - Velocity limiting and checking - Obstacle distance monitoring - Battery level monitoring - Temperature monitoring - Three-level status: Safe, Warning, Critical - Per-check enable/disable - Configurable thresholds Quick Start API Reference Constructor Default limits: - Max velocity: 2.0 m/s - Min obstacle distance: 0.3 m - Min battery: 10% - Max temperature: 80°C Threshold Configuration Description Maximum safe velocity (m/s) Minimum obstacle clearance (m) Minimum battery level (%) Maximum temperature (°C) Enable/Disable Checks Description Toggle velocity monitoring enableobstaclecheck(bool) Toggle battery monitoring enabletemperaturecheck(bool) Individual Checks Returns true if velocity ≤ max checkobstacledistance(d) battery ≥ min checktemperature(t) Comprehensive Check Returns: - SafetyStatus::Safe - All values within limits - SafetyStatus::Warning - Values at or slightly past limits - SafetyStatus::Critical - Values significantly past limits Velocity Limiting Clamps velocity to [-maxvelocity, +maxvelocity]. Safety Status Thresholds Warning &gt; max &lt; min &lt; min &gt; max Example: Motion Controller with Safety Example: Battery-Aware Navigation Example: HORUS Node Integration Example: Configurable Safety Profiles Best Practices 1. Always enable safety - Even in simulation 2. Set conservative defaults - Tune up, not down 3. Monitor all channels - Don't disable checks without reason 4. Log safety events - Track warnings and violations 5. Test failure modes - Verify behavior at limits See Also - PID Controller - Velocity control - AABB Collision - Collision detection - Differential Drive - Velocity commands - Sensor Fusion - Combining sensor data","headings":"Safety Layer Source Code Features Quick Start API Reference Constructor Threshold Configuration Enable/Disable Checks Individual Checks Comprehensive Check Velocity Limiting Safety Status Thresholds Example: Motion Controller with Safety Example: Battery-Aware Navigation Example: HORUS Node Integration Example: Configurable Safety Profiles Best Practices See Also","category":"rust"},{"id":97,"title":"Sensor Fusion","description":"Multi-sensor combination with variance-weighted averaging","slug":"/rust/library/algorithms/sensor-fusion","content":"Sensor Fusion Combine measurements from multiple sensors for improved state estimation using variance-weighted fusion. Source Code - Sensor Fusion Implementation Features - Variance-weighted sensor fusion - Time-based measurement weighting - Complementary filtering for IMU fusion - Automatic stale measurement handling - Sensor health monitoring Quick Start API Reference Constructor Adding Measurements Description Unique identifier for the sensor value Measurement uncertainty (σ²) timestamp Fusion Methods Description Variance-weighted fusion fusewithtime(currenttime) Combined uncertainty complementaryfilter(high, low, alpha) Management Description Remove all measurements removesensor(id) Number of active sensors setmaxage(seconds) Variance-Weighted Fusion Measurements are combined inversely proportional to their variance: Lower variance sensors contribute more to the final estimate. Example: GPS + Odometry Fusion Time-Weighted Fusion More recent measurements receive higher weight: The time weight decays exponentially: Complementary Filter Classic IMU fusion for combining accelerometer and gyroscope: Choosing Alpha Effect More accelerometer influence 0.95 Standard for IMU 0.99 Multi-Axis Fusion Fuse each axis independently: HORUS Node Integration Sensor Variance Guidelines Typical Variance 0.001 - 0.01 m² 0.01 - 0.1 m² 1 - 10 m² 10 - 100 m² 0.001 - 0.01 m² 0.01 - 0.1 m² Grows with time See Also - EKF - Full state estimation - Kalman Filter - Linear estimation - IMU Node - IMU data processing - GPS Node - GPS integration","headings":"Sensor Fusion Source Code Features Quick Start API Reference Constructor Adding Measurements Fusion Methods Management Variance-Weighted Fusion Example: GPS + Odometry Fusion Time-Weighted Fusion Complementary Filter Choosing Alpha Multi-Axis Fusion HORUS Node Integration Sensor Variance Guidelines See Also","category":"rust"},{"id":98,"title":"BatteryMonitorNode","description":"INA219/INA226 power monitoring with battery state estimation","slug":"/rust/library/built-in-nodes/battery-monitor","content":"BatteryMonitorNode Battery and power monitoring node using INA219/INA226 I2C current/voltage sensors. Provides real-time monitoring of voltage, current, power consumption, and battery state of charge for mobile robots and autonomous systems. Source Code - BatteryMonitorNode Implementation - Battery Sensor Messages Features - INA219 and INA226 sensor support - Voltage monitoring (0-26V for INA219, 0-36V for INA226) - Current monitoring (±3.2A for INA219, ±20A for INA226 with shunt) - Power calculation - Battery state of charge (SOC) estimation - Remaining runtime estimation - Low battery warnings - Configurable alert thresholds - Multiple sensors for multi-battery systems - Simulation fallback Quick Start Hardware Drivers Covered This node provides production-ready drivers for: Primary Support (Full Hardware Integration): - INA219 - Voltage/current monitor (0-26V, ±3.2A) - INA226 - High-precision voltage/current monitor (0-36V, ±20A) Supported Battery Chemistries: - LiPo/LiFePO4 (1S-6S+ configurations) - Li-ion (18650, 21700, custom packs) - NiMH (6-12 cell packs) - Lead-acid (6V, 12V, 24V systems) - Custom battery packs Additional I2C Sensors (Planned): - BQ27441 - Single-cell fuel gauge - MAX17043 - LiPo fuel gauge - LC709203F - Battery state estimation - ACS712 - Current sensing modules Applications Best Suited For Mobile Robots: - Autonomous delivery robots - Service robots (indoor navigation) - Agricultural robots - Inspection drones (ground-based) - Educational robot platforms Aerial Systems: - Small drones (≤3.2A with INA219) - Fixed-wing UAVs (with INA226) - Multicopter platforms - Tethered systems Industrial Applications: - AGVs (Automated Guided Vehicles) - Battery-powered tools - Portable measurement equipment - Solar power monitoring - UPS systems Research Platforms: - Power consumption analysis - Battery discharge testing - Energy efficiency optimization - Runtime prediction research Why Use This Node? For Small Robots (INA219): - Real-time power monitor","headings":"BatteryMonitorNode Source Code Features Quick Start Hardware Drivers Covered Applications Best Suited For Why Use This Node? Customization Options What Can Be Configured Extensibility Patterns Hardware Setup System Requirements Install I2C tools Enable I2C Verify I2C device INA219 Wiring INA226 Wiring (Same as INA219) Enabling Features Output: Auto-detected hardware nodes (features: i2c-hardware) Sensor Comparison INA219 INA226 Configuration Sensor Selection I2C Addresses Shunt Resistor Battery Configuration Measurement Configuration Alert Thresholds Usage Patterns Reading Battery Data Battery Alerts Energy Consumption Tracking Complete Example: Battery Monitor System Message Format BatteryData BatteryAlert Alert Types Battery Chemistry Voltage Curves LiPo (3.7V nominal per cell) LiFePO4 (3.2V nominal per cell) Best Practices Troubleshooting Multi-Battery Systems See Also","category":"rust"},{"id":99,"title":"BldcMotorNode","description":"Brushless motor and ESC control with 10+ protocol support","slug":"/rust/library/built-in-nodes/bldc-motor","content":"BldcMotorNode Brushless DC (BLDC) motor and Electronic Speed Controller (ESC) node supporting 10+ protocols including PWM, OneShot, DShot, CAN, and serial. Controls up to 8 motors simultaneously for drones, rovers, and robotic systems. Source Code - BldcMotorNode Implementation - Motor Control Messages Features - Up to 8 BLDC motors/ESCs - 10+ protocols: PWM, OneShot125, OneShot42, MultiShot, DShot150/300/600/1200, KISS, CAN, UART - Bidirectional DShot (telemetry) - 3D mode (reverse thrust) - Arming/disarming safety - Failsafe configuration - Motor direction reversal - Calibration routines - Simulation fallback Quick Start Hardware Setup System Requirements Wiring Example (4 motors) IMPORTANT: - Always connect common ground between Pi and ESC - Use separate power supply for motors (not Pi's 5V) - Calibrate ESCs before first use Enabling Features There are three ways to enable the required gpio-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using BldcMotorNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Supported Protocols PWM (Standard RC) OneShot125 OneShot42 MultiShot DShot (Digital Shot) KISS (UART-based) CAN Bus Configuration Motor Setup Throttle Range Motor Direction Arming Failsafe 3D Mode (Bidirectional) Usage Patterns Setting Motor Throttle Arming Sequence Reading Telemetry (DShot) ESC Calibration Complete Example: Quadcopter Message Format BldcCommand Command Types BldcTelemetry (DShot) Protocol Comparison Update Rate Telemetry Best For 50 Hz No Basic/legacy OneShot125 0.25ms No 32 kHz No Racing DShot600 0.1ms Yes Variable Yes High-performance KISS 2ms Yes 1 kHz Yes Industrial | Best Practices 1. Use DShot600 for modern ESCs: 2. Always implement arming: 3. Configure failsafe: 4. Common ground is critical: 5. Use separate power for motors: 6. Mon","headings":"BldcMotorNode Source Code Features Quick Start Hardware Setup System Requirements Install GPIO library Enable GPIO and PWM Wiring Example (4 motors) Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Supported Protocols PWM (Standard RC) OneShot125 OneShot42 MultiShot DShot (Digital Shot) KISS (UART-based) CAN Bus Configuration Motor Setup Throttle Range Motor Direction Arming Failsafe 3D Mode (Bidirectional) Usage Patterns Setting Motor Throttle Arming Sequence Reading Telemetry (DShot) ESC Calibration Complete Example: Quadcopter Message Format BldcCommand Command Types BldcTelemetry (DShot) Protocol Comparison Best Practices ESC Calibration Procedure Troubleshooting Safety Guidelines Graceful Shutdown See Also","category":"rust"},{"id":100,"title":"CameraNode","description":"Vision camera for image capture and computer vision","slug":"/rust/library/built-in-nodes/camera","content":"CameraNode Vision camera node for image capture supporting USB cameras, Raspberry Pi Camera Module, and network cameras. Provides image streaming for computer vision, object detection, and visual navigation. Source Code - CameraNode Implementation - Vision Messages Features - USB cameras (V4L2) - Raspberry Pi Camera Module - IP cameras (RTSP/HTTP) - Configurable resolution and framerate - Multiple encoding formats (RGB, BGR, Mono, YUV) - JPEG/PNG image compression - OpenCV integration - Camera calibration data - Hardware fallback to simulation Quick Start Publishes to: camera.image (images) and camera.camerainfo (calibration data). Requires: Camera hardware and the opencv-backend feature. Hardware Setup Hardware-Only: This node requires actual camera hardware. For testing without hardware, use the sim2d or sim3d simulation tools instead. Enabling Features There are three ways to enable the required opencv-backend feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using CameraNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Construction Configuration Methods Monitoring Methods Configuration Parameters Type Description u32 Camera device identifier (0 for default camera) width 640 u32 Image height in pixels fps 30.0 ImageEncoding Pixel encoding format compressimages false u8 Compression quality (0-100, higher = better) Topic Description camera.image Raw image frames from camera camera.camerainfo Camera calibration and intrinsic parameters Resolution Aspect Ratio QVGA 4:3 640 x 480 Standard robotics vision SVGA 4:3 1280 x 720 HD video, object detection Full HD 16:9 3840 x 2160 Ultra high detail (requires bandwidth) Encoding Color Mono8 No 2 High-precision grayscale Rgb8 Yes 3 OpenCV compatibility Rgba8 Yes 2 Video compression, streaming Depth16 No Bandwidth","headings":"CameraNode Source Code Features Quick Start Hardware Setup Enabling Features Output: Auto-detected hardware nodes (features: opencv-backend) Configuration Construction Configuration Methods Monitoring Methods Configuration Parameters Topics Publishers Usage Patterns Single Camera Setup Stereo Camera Setup Low Latency Setup Image Processing Pipeline Message Types Image ImageEncoding CameraInfo Supported Formats and Resolutions Common Resolutions Encoding Formats Bandwidth Considerations Performance Considerations Framerate Guidelines CPU Usage Memory Usage Troubleshooting Issue: Camera not found Check available cameras on Linux Kill processes using camera Issue: Permission denied (Linux) Add user to video group Or change device permissions (temporary) Then logout and login again Issue: Low framerate Issue: Wrong colors / inverted colors Issue: Unsupported resolution Check supported formats (Linux) Camera Calibration See Also","category":"rust"},{"id":101,"title":"CanBusNode","description":"CAN bus communication with support for J1939, CANopen, and DeviceNet","slug":"/rust/library/built-in-nodes/can-bus","content":"CanBusNode Controller Area Network (CAN) bus communication node for automotive, industrial, and robotics applications. Supports standard and extended identifiers, CAN-FD, and protocol-specific configurations. Source Code - CanBusNode Implementation - CAN Message Types Features - SocketCAN interface (Linux) - Standard (11-bit) and Extended (29-bit) identifiers - CAN-FD support (up to 2 Mbit/s data phase) - Configurable bitrates (125k, 250k, 500k, 1M) - ID filtering (whitelist/blacklist) - Listen-only and loopback modes - Bus-off auto-recovery - J1939, CANopen, DeviceNet presets - Hardware fallback to simulation Quick Start Hardware Setup System Requirements Setup Virtual CAN (Testing) Setup Real CAN Hardware Enabling Features There are three ways to enable the required can-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using CanBusNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Bitrate CAN-FD Operating Modes ID Filtering Usage Patterns Sending CAN Frames Receiving CAN Frames Error Monitoring Protocol Presets J1939 (Trucks/Heavy Vehicles) Example J1939 frame: CANopen (Industrial Automation) Example CANopen frame: DeviceNet (Industrial Control) Message Format CanFrame CanError Error Types Complete Example Testing with can-utils Statistics Troubleshooting Problem: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. Check if interface exists: ip link show can0 2. Create virtual CAN: sudo ip link add dev can0 type vcan && sudo ip link set up can0 3. Check kernel modules: lsmod | grep can 4. Test with can-utils: candump can0 Best Practices 1. Always handle errors: 2. Use ID filtering for performance: 3. Enable auto-restart for reliability: 4. Test with virtual CAN before hardware: 5. Monitor bus load: See Also - I2cBusNode - I2C communic","headings":"CanBusNode Source Code Features Quick Start Hardware Setup System Requirements Install CAN utilities Load SocketCAN kernel module Setup Virtual CAN (Testing) Create virtual CAN interface Verify Setup Real CAN Hardware For physical CAN interfaces (e.g., MCP2515) Verify Enabling Features Output: Auto-detected hardware nodes (features: can-hardware) Configuration Bitrate CAN-FD Operating Modes ID Filtering Usage Patterns Sending CAN Frames Receiving CAN Frames Error Monitoring Protocol Presets J1939 (Trucks/Heavy Vehicles) CANopen (Industrial Automation) DeviceNet (Industrial Control) Message Format CanFrame CanError Error Types Complete Example Testing with can-utils Send test frame Monitor bus Generate random traffic Replay captured traffic Statistics Troubleshooting Best Practices See Also","category":"rust"},{"id":102,"title":"CloudLLMNode","description":"Cloud LLM integration for natural language robot control","slug":"/rust/library/built-in-nodes/cloud-llm","content":"CloudLLMNode Cloud LLM integration node for natural language understanding and generation. Connect your robot to OpenAI (GPT-4) or Anthropic (Claude) APIs for intelligent human-robot interaction. Source Code - CloudLLMNode Implementation - ML Messages Features - OpenAI API support (GPT-4, GPT-3.5-Turbo, GPT-4-Turbo) - Anthropic API support (Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku) - Streaming responses - Rate limiting and retry logic - Token usage tracking - Conversation context management - Temperature and top-p control Requirements Enable the ml-inference feature in your horus.yaml: Set your API key as an environment variable: Quick Start Configuration LLMConfig Type Description LLMProvider API provider model \"gpt-4\" String API key maxtokens 2048 f32 Sampling temperature (0.0-2.0) topp 1.0 u64 Request timeout stream false usize Conversation history length Topic Description {inputtopic} User prompts {inputtopic}/system System prompt updates Topic Description {outputtopic} Generated responses {outputtopic}/stream Streaming chunks {outputtopic}/usage Token statistics Model Output (per 1K tokens) GPT-3.5-Turbo $0.0015 GPT-4 $0.06 GPT-4-Turbo $0.03 Claude 3 Haiku $0.0.1.6 Claude 3.5 Sonnet $0.015 | See Also - KeyboardInputNode - Text input - JoystickNode - Manual control - PathPlannerNode - Autonomous navigation","headings":"CloudLLMNode Source Code Features Requirements For OpenAI For Anthropic Quick Start Configuration LLMConfig Preset Configurations Topics Subscribed Topics Published Topics Usage Examples Voice Command Processing Conversational Robot Task Planning Streaming Responses Safety Considerations Cost Estimation See Also","category":"rust"},{"id":103,"title":"CollisionDetectorNode","description":"Collision detection and avoidance from sensor data","slug":"/rust/library/built-in-nodes/collision-detector","content":"CollisionDetectorNode Collision detection node processing data from ultrasonic sensors, LiDAR, depth cameras, and other proximity sensors. Provides collision warnings and automatic stopping for obstacle avoidance. Source Code - CollisionDetectorNode Implementation - Diagnostics Messages Features - Multi-sensor fusion - Configurable safety zones - Distance thresholds - Directional collision detection - Velocity-based prediction - Auto-stop triggering - Warning levels (caution, warning, critical) - Simulation support Quick Start Usage See Also - UltrasonicNode - Distance sensors - LidarNode - Laser scanning - DepthCameraNode - 3D depth - EmergencyStopNode - E-stop","headings":"CollisionDetectorNode Source Code Features Quick Start Usage See Also","category":"rust"},{"id":104,"title":"DcMotorNode","description":"Basic DC motor control with PWM and direction","slug":"/rust/library/built-in-nodes/dc-motor","content":"DcMotorNode Basic DC motor control node providing PWM speed control and direction switching for up to 8 motors. Simple interface for brushed DC motors using H-bridge drivers like L298N, TB6612, DRV8833, and similar motor drivers. Source Code - DcMotorNode Implementation - Motor Control Messages Features - Up to 8 DC motors - PWM speed control (0-100%) - Forward/reverse/brake control - Configurable PWM frequency - Current limiting (driver-dependent) - Soft start/acceleration - Multiple driver support (L298N, TB6612, DRV8833) - Simulation fallback Quick Start Hardware Setup System Requirements L298N H-Bridge Wiring TB6612 Driver Wiring Enabling Features There are three ways to enable the required gpio-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using DcMotorNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Supported Drivers L298N TB6612FNG DRV8833 Custom/Generic Configuration Motor Setup PWM Configuration Motor Direction Speed Limits Acceleration Control Modes Speed Control Direction Control Brake/Coast Stop Usage Patterns Basic Motor Control Differential Drive Complete Example: Tank Drive Message Format DcMotorCommand Command Types Best Practices 1. Use appropriate PWM frequency: 2. Enable acceleration for smooth starts: 3. Set speed limits to protect motors: 4. Use brake instead of coast for precision: 5. Monitor current if driver supports it: 6. Separate motor power from logic: H-Bridge Truth Table L298N / Generic IN2 LOW HIGH LOW HIGH PWM on ENA/ENB controls speed. TB6612 / DRV8833 AIN2 LOW HIGH LOW HIGH PWM on PWMA/PWMB controls speed. Troubleshooting Problem: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. Check GPIO permissions 2. Install libraspberrypi-dev 3. Enable GPIO in raspi-config 4. Verify wiring with multimeter Problem: Motor","headings":"DcMotorNode Source Code Features Quick Start Hardware Setup System Requirements Install GPIO library Enable GPIO and PWM L298N H-Bridge Wiring TB6612 Driver Wiring Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Supported Drivers L298N TB6612FNG DRV8833 Custom/Generic Configuration Motor Setup PWM Configuration Motor Direction Speed Limits Acceleration Control Modes Speed Control Direction Control Brake/Coast Stop Usage Patterns Basic Motor Control Differential Drive Complete Example: Tank Drive Message Format DcMotorCommand Command Types Best Practices H-Bridge Truth Table L298N / Generic TB6612 / DRV8833 Troubleshooting Graceful Shutdown Automatic Emergency Stop Manual Emergency Stop Shutdown Logging Safety Guidelines See Also","category":"rust"},{"id":105,"title":"DepthCameraNode","description":"RGB-D camera interface for 3D vision sensors","slug":"/rust/library/built-in-nodes/depth-camera","content":"DepthCameraNode RGB-D camera interface for 3D vision sensors that capture color and depth data. Supports Intel RealSense, Stereolabs ZED, Microsoft Kinect, and other depth-sensing cameras for 3D mapping, SLAM, and manipulation tasks. Source Code - DepthCameraNode Implementation - Perception Messages Features - Intel RealSense D400/L500 series - Stereolabs ZED, ZED 2, ZED 2i, ZED Mini - Microsoft Kinect v1, v2, Azure Kinect - Orbbec Astra, Femto - Luxonis OAK-D series - RGB-D output (color + depth) - Point cloud generation - Post-processing filters (spatial, temporal, hole-filling) - IMU data support (D435i, ZED2i) - Hardware fallback to simulation Quick Start Publishes to: depthcamera.rgb.image, depthcamera.depth.image, depthcamera.pointcloud, depthcamera.camerainfo Requires: Camera hardware and realsense or zed feature (auto-detected by horus run). Supported Cameras Models Range D415, D435, D435i, D455, L515 0.3-10m Stereolabs Passive Stereo Kinect v1, Kinect v2, Azure Kinect 0.5-5m Orbbec Structured Light / ToF OAK-D, OAK-D Lite, OAK-D Pro 0.2-35m Parameter Default cameramodel Required (u32, u32) RGB resolution (width, height) depthresolution (640, 480) u32 Frame rate in Hz depthrange (0.3, 10.0) bool Enable point cloud generation aligndepthtocolor true Topics Publishers Type Image DepthImage PointCloud CameraInfo Usage Patterns Basic Depth Sensing Obstacle Detection Point Cloud for 3D Mapping Hybrid Pattern with Processing Message Types DepthImage PointCloud Camera Model Presets Intel RealSense D435 Intel RealSense L515 Azure Kinect Troubleshooting Issue: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. Check camera is connected: lsusb Resolution CPU Usage 640x480 Low 30fps Mapping, manipulation 1280x720 High -50% fps 3D reconstruction | Simulation Mode When hardware is unavailable, the node operates in simulation mode: - Generates synthetic depth patterns - Useful for algorithm development and testing - No hardware dependencies required See Also - Ca","headings":"DepthCameraNode Source Code Features Quick Start Supported Cameras Hardware Setup Intel RealSense Install librealsense2 Verify camera connection Check USB permissions Enabling Features Output: Auto-detected hardware nodes (features: realsense) Configuration Construction Configuration Methods Configuration Parameters Topics Publishers Usage Patterns Basic Depth Sensing Obstacle Detection Point Cloud for 3D Mapping Hybrid Pattern with Processing Message Types DepthImage PointCloud Camera Model Presets Intel RealSense D435 Intel RealSense L515 Azure Kinect Troubleshooting Issue: \"Hardware unavailable - using SIMULATION mode\" Issue: Low frame rate Issue: Noisy depth data Performance Considerations Simulation Mode See Also","category":"rust"},{"id":106,"title":"DepthEstimationNode","description":"Monocular depth estimation using neural networks","slug":"/rust/library/built-in-nodes/depth-estimation","content":"DepthEstimationNode Real-time monocular depth estimation from single RGB images using neural networks like MiDaS, DPT, and Depth Anything. Generates depth maps without requiring stereo cameras or depth sensors. Source Code - DepthEstimationNode Implementation - ML Messages Features - MiDaS v2/v3 model support - DPT (Dense Prediction Transformer) support - Depth Anything support (small, base, large) - Metric depth estimation (optional) - Colorized depth visualization - GPU acceleration - Relative and metric depth modes Requirements Enable the onnx feature in your horus.yaml: Quick Start Supported Models MiDaS Models Config Speed midassmall() Fast midasv21() Medium midashybrid() Medium midaslarge() Slow Depth Anything Models Config Speed depthanythingsmall() Fast depthanythingbase() Medium depthanythinglarge() Slow Configuration DepthConfig Options Type Description DepthModelType Model architecture inputsize [384, 384] bool Enable GPU acceleration deviceid 0 usize CPU threads metricdepth false f32 Depth scaling factor mindepth 0.1 f32 Maximum depth (meters) enablevisualization true bool Invert depth output Topic Description {inputtopic} Input RGB images Topic Description {outputtopic} Estimated depth map {outputtopic}.visualization Colorized depth (if enabled) {outputtopic}.metrics Performance metrics Model CPU (i7-12700) MiDaS Small 15-20 FPS 45-60 FPS Better MiDaS DPT 4-6 FPS 50-60 FPS Good Depth Anything B 6-10 FPS 25-35 FPS Best | Limitations - Monocular estimation - Relative depth only without ground truth scale - Indoor/outdoor bias - Models trained on specific datasets may not generalize - Reflective surfaces - Glass, mirrors, and water cause artifacts - Low texture - Uniform surfaces lack depth cues Integration with Other Nodes Point Cloud Generation Collision Avoidance See Also - DepthCameraNode - Hardware depth cameras (RealSense, etc.) - CameraNode - RGB camera input - ONNXInferenceNode - Generic ONNX inference - CollisionDetectorNode - Collision detection","headings":"DepthEstimationNode Source Code Features Requirements Quick Start Supported Models MiDaS Models Depth Anything Models Configuration DepthConfig Options Topics Subscribed Topics Published Topics Usage Examples Basic Depth Estimation Obstacle Detection Depth-Based Navigation With GPU Acceleration Model Downloads MiDaS v2.1 Small (fast) MiDaS v2.1 (balanced) MiDaS DPT-Large (highest quality) Depth Anything (convert from PyTorch) See: https://github.com/LiheYoung/Depth-Anything Performance Limitations Integration with Other Nodes Point Cloud Generation Collision Avoidance See Also","category":"rust"},{"id":107,"title":"DifferentialDriveNode","description":"Differential drive kinematics for 2-wheeled robots","slug":"/rust/library/built-in-nodes/differential-drive","content":"DifferentialDriveNode Differential drive controller for 2-wheeled mobile robots. Converts linear and angular velocity commands to left/right wheel velocities using inverse kinematics. Source Code - DifferentialDriveNode Implementation - Velocity Command Messages Features - Velocity command input (Twist message with linear + angular) - Wheel velocity output (DifferentialDriveCommand) - Configurable wheel base and radius - Velocity limiting (linear and angular) - Odometry integration and publishing - Graceful shutdown (auto-stop on Ctrl+C) Quick Start Subscribes to: cmdvel (Twist) Publishes to: drivecommand (DifferentialDriveCommand), odom (Odometry) Configuration Construction Configuration Methods Configuration Parameters Type Description f32 Distance between wheels (meters) wheelradius 0.1 f32 Maximum linear velocity (m/s) maxangularvel π Topics Subscribers Type Twist Publishers Type DifferentialDriveCommand Odometry Usage Patterns Basic Movement Commands Complete Robot Setup Joystick Control Kinematics Inverse Kinematics (velocity command to wheel speeds) Forward Kinematics (wheel speeds to robot velocity) Message Types Twist For differential drive, only linear[0] (forward) and angular[2] (yaw) are used. Graceful Shutdown DifferentialDriveNode automatically stops the robot when your application receives Ctrl+C (SIGINT/SIGTERM): - Zero velocity command published to motors - Robot coasts to a stop - Critical for autonomous vehicle safety Troubleshooting Issue: Robot turns instead of going straight Cause: Wheel radius or motor calibration mismatch Solution: Verify wheel measurements and motor performance. Consider using encoder feedback for closed-loop control. Issue: Robot velocity doesn't match command Cause: Wheel slip, motor saturation, or incorrect wheel radius Solution: - Verify wheel radius measurement - Reduce velocity limits: diffdrive.setvelocitylimits(0.5, 1.0); - Use encoder feedback for closed-loop control Issue: Jerky motion Cause: Rapid velocity changes","headings":"DifferentialDriveNode Source Code Features Quick Start Configuration Construction Configuration Methods Configuration Parameters Topics Subscribers Publishers Usage Patterns Basic Movement Commands Complete Robot Setup Joystick Control Kinematics Inverse Kinematics (velocity command to wheel speeds) Forward Kinematics (wheel speeds to robot velocity) Message Types Twist Graceful Shutdown Troubleshooting Issue: Robot turns instead of going straight Issue: Robot velocity doesn't match command Issue: Jerky motion Performance Considerations Update Rate CPU Usage Memory Usage See Also","category":"rust"},{"id":108,"title":"DigitalIONode","description":"GPIO input/output for switches, LEDs, and digital signals","slug":"/rust/library/built-in-nodes/digital-io","content":"DigitalIONode Digital I/O node for GPIO input and output. Controls LEDs, reads buttons/switches, and interfaces with digital sensors and actuators. Source Code - DigitalIONode Implementation - I/O Messages Features - Digital input (buttons, switches, sensors) - Digital output (LEDs, relays, solenoids) - Pull-up/pull-down resistors - Interrupt-based input - Debouncing for switches - PWM output - Multiple GPIO pins - Simulation support Quick Start Requires: GPIO hardware and the gpio-hardware feature. Enabling Features There are three ways to enable the required gpio-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using DigitalIONode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Usage See Also - EmergencyStopNode - E-stop button input - ServoControllerNode - PWM output","headings":"DigitalIONode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Configuration Usage See Also","category":"rust"},{"id":109,"title":"DynamixelNode","description":"Dynamixel smart servo control with 18+ model support","slug":"/rust/library/built-in-nodes/dynamixel","content":"DynamixelNode Dynamixel smart servo controller supporting 18+ servo models across Protocol 1.0 and 2.0. Provides position, velocity, and torque control for robot arms, humanoids, grippers, and articulated mechanisms. Source Code - DynamixelNode Implementation - Motor Control Messages Features - 18+ Dynamixel models (AX, MX, X, P, PRO series) - Protocol 1.0 and 2.0 support - Up to 253 servos on one bus - Position, velocity, current/torque control - Multi-turn absolute positioning - PID gain tuning - Temperature and voltage monitoring - Compliance/stiffness control - Sync/bulk read/write for performance - Hardware fallback to simulation Quick Start Hardware Setup System Requirements Wiring (Daisy Chain) Power Requirements: - AX/MX series: 11-14.8V (3S LiPo) - X/XM series: 11-14.8V (3S LiPo) - XL series: 6-9V (2S LiPo) - PRO/P series: 24V U2D2 or USB2Dynamixel Enabling Features There are three ways to enable the required serial-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using DynamixelNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Supported Models Protocol 1.0 (Legacy) Protocol 2.0 (Modern) Configuration Bus Setup Adding Servos Operating Modes PID Gains Limits Usage Patterns Position Control Velocity Control Current Control (Torque) Synchronized Motion Bulk Read Complete Example: Robot Arm Message Format DynamixelCommand Command Types DynamixelStatus Hardware Error Codes Advanced Features Compliance Control Profile Control (X series) Indirect Addressing Dynamixel Wizard Use Dynamixel Wizard to: - Scan for servos - Update firmware - Change servo IDs - Test movements - Configure PID gains Best Practices 1. Use Protocol 2.0 for new projects: 2. Set appropriate limits: 3. Use sync write for coordinated motion: 4. Monitor temperature and voltage: 5. Disabl","headings":"DynamixelNode Source Code Features Quick Start Hardware Setup System Requirements Install USB-serial drivers Add user to dialout group Verify port Wiring (Daisy Chain) U2D2 or USB2Dynamixel Enabling Features Output: Auto-detected hardware nodes (features: serial-hardware) Supported Models Protocol 1.0 (Legacy) Protocol 2.0 (Modern) Configuration Bus Setup Adding Servos Operating Modes PID Gains Limits Usage Patterns Position Control Velocity Control Current Control (Torque) Synchronized Motion Bulk Read Complete Example: Robot Arm Message Format DynamixelCommand Command Types DynamixelStatus Hardware Error Codes Advanced Features Compliance Control Profile Control (X series) Indirect Addressing Dynamixel Wizard Available from ROBOTIS website Runs on Windows/Linux/Mac Best Practices Troubleshooting Graceful Shutdown See Also","category":"rust"},{"id":110,"title":"EmbeddingNode","description":"Feature embedding extraction using CLIP, DINOv2, and other vision models","slug":"/rust/library/built-in-nodes/embedding","content":"EmbeddingNode Real-time feature embedding extraction using neural networks like CLIP, DINOv2, ResNet, and EfficientNet. Produces dense feature vectors useful for image similarity, zero-shot classification, visual navigation, and place recognition. Source Code - EmbeddingNode Implementation - ML Messages Features - CLIP vision encoder support (ViT-B/32, ViT-B/16, ViT-L/14) - DINOv2 support (small, base, large) - ResNet and EfficientNet feature extraction - Batch processing capability - L2 normalization (optional) - GPU acceleration - Cosine similarity computation Use Cases - Image similarity search - Find similar images in a database - Zero-shot classification - Classify without training data - Visual place recognition - Loop closure in SLAM - Robot navigation - Visual landmark matching - Object re-identification - Track objects across cameras Requirements Enable the onnx feature in your horus.yaml: Quick Start Supported Models CLIP Models Config Speed clipvitb32() Fast clipvitb16() Medium clipvitl14() Slow DINOv2 Models Config Speed dinov2small() Fast dinov2base() Medium dinov2large() Slow Other Models Config Notes resnet50() ImageNet features EfficientNet-B0 1280 Configuration EmbeddingConfig Options Type Description EmbeddingModelType Model architecture inputsize [224, 224] usize Output dimension usegpu false u32 GPU device ID numthreads 4 bool Apply L2 normalization normalizemean Model-specific [f32; 3] Input normalization std Topic Description {inputtopic} Input RGB images Topic Description {outputtopic} Feature embeddings {outputtopic}.metrics Performance metrics Model CPU (i7-12700) CLIP ViT-B/32 30-40 FPS 150+ FPS 512 CLIP ViT-L/14 10-15 FPS 180+ FPS 384 DINOv2 Base 15-25 FPS 60+ FPS 1024 | Best Practices 1. Normalize embeddings - Always use L2 normalization for cosine similarity 2. Match preprocessing - Use the same normalization as model training 3. GPU for real-time - CPU is sufficient for &lt;10 FPS, GPU for higher 4. Cache reference embeddings - Pre-comp","headings":"EmbeddingNode Source Code Features Use Cases Requirements Quick Start Supported Models CLIP Models DINOv2 Models Other Models Configuration EmbeddingConfig Options Topics Subscribed Topics Published Topics Usage Examples Basic Embedding Extraction Image Similarity Search Visual Place Recognition Zero-Shot Classification with CLIP With GPU Acceleration Model Downloads CLIP Models Export CLIP visual encoder to ONNX DINOv2 Models Export DINOv2 to ONNX Performance Best Practices See Also","category":"rust"},{"id":111,"title":"EmergencyStopNode","description":"Emergency stop (E-stop) system for safety-critical applications","slug":"/rust/library/built-in-nodes/emergency-stop","content":"EmergencyStopNode Emergency stop (E-stop) node for immediate system shutdown in dangerous situations. Monitors physical e-stop buttons, software triggers, and watchdog timers for safety-critical robotics applications. Source Code - EmergencyStopNode Implementation - Diagnostics Messages Features - Physical e-stop button input - Software e-stop triggers - Watchdog timer monitoring - Motor disable on trigger - System state preservation - Auto-reset or manual reset - Latching/non-latching modes - Multiple trigger sources - Simulation support Quick Start Configuration Usage See Also - SafetyMonitorNode - System health monitoring - CollisionDetectorNode - Collision prevention - BatteryMonitorNode - Battery safety","headings":"EmergencyStopNode Source Code Features Quick Start Configuration Usage See Also","category":"rust"},{"id":112,"title":"EncoderNode","description":"Quadrature encoder reading for position and velocity measurement","slug":"/rust/library/built-in-nodes/encoder","content":"EncoderNode Quadrature encoder node for reading rotary encoders on motors and wheels. Provides position, velocity, and direction information for closed-loop control and odometry. Source Code - EncoderNode Implementation - Encoder Sensor Messages Features - Quadrature encoder support (AB phase via GPIO) - Position counting (64-bit) - Velocity calculation - Direction detection - Configurable resolution, wheel radius, and gear ratio - Hardware GPIO backend with simulation fallback - Builder pattern with hybrid processor support Quick Start Publishes to: odom topic with position, velocity, and heading data. Requires: GPIO hardware and the gpio-hardware feature. Enabling Features There are three ways to enable the required gpio-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using EncoderNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Construction Configuration Methods State Query Methods Configuration Parameters Type Description f64 Pulses per revolution (PPR) wheelradius 0.1 f64 Gear ratio (motor rotations / wheel rotations) frameid \"odom\" String Child frame identifier Application Notes Wheel odometry Balance accuracy and CPU usage Velocity feedback Higher rate for responsive control Position control Moderate rate for stable control High-speed motors Fast motors need fast feedback | Calibration Encoder Resolution Calibration 1. Mark a reference point on the wheel 2. Rotate exactly one revolution 3. Count pulses received 4. Compare to nominal specification Wheel Radius Calibration 1. Mark starting position 2. Drive robot a known distance (e.g., 10 meters) 3. Read encoder distance 4. Calculate actual radius: Gear Ratio Calibration 1. Count motor shaft rotations for one wheel rotation 2. Calculate gear ratio: gearratio = motorrotations / wheelrot","headings":"EncoderNode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Configuration Construction Configuration Methods State Query Methods Configuration Parameters Encoder Resolution Usage Patterns Basic Motor Feedback Wheel Odometry for Mobile Robot Geared Motor System Encoder with PID Control Message Types Odometry Pose2D Twist Encoder Types Quadrature Encoders Single Channel Encoders Velocity Calculation Distance Conversion Troubleshooting Issue: Missed Counts Issue: Incorrect Direction Issue: Noisy Velocity Readings Issue: Distance Drifts Over Time Performance Considerations CPU Usage Recommended Tick Rates Calibration Encoder Resolution Calibration Wheel Radius Calibration Gear Ratio Calibration See Also","category":"rust"},{"id":113,"title":"ForceTorqueSensorNode","description":"6-axis force/torque sensor for robot arms and manipulation","slug":"/rust/library/built-in-nodes/force-torque","content":"ForceTorqueSensorNode 6-axis force/torque sensor node for measuring forces (Fx, Fy, Fz) and torques (Tx, Ty, Tz). Supports ATI, OnRobot, and Robotiq F/T sensors for robot arms, grippers, and haptic feedback. Source Code - ForceTorqueSensorNode Implementation - Force Messages Features - 6-axis measurement (3 force + 3 torque) - ATI Mini/Nano series - OnRobot HEX-E, Robotiq FT 300 - Configurable sample rates - Bias/tare calibration - Threshold detection - Hardware fallback to simulation Quick Start Requires: Serial port access and the netft feature for hardware F/T sensor support. Enabling Features There are three ways to enable the required netft feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using ForceTorqueSensorNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Usage See Also - DynamixelNode - Robot arm servos - ServoControllerNode - PWM servo control","headings":"ForceTorqueSensorNode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: netft) Usage See Also","category":"rust"},{"id":114,"title":"GpsNode","description":"GPS/GNSS receiver for positioning and navigation","slug":"/rust/library/built-in-nodes/gps","content":"GpsNode GPS/GNSS satellite navigation receiver for positioning, navigation, and time synchronization with multi-constellation support. Compatible with u-blox, MediaTek, GlobalSat, Adafruit, SparkFun, and any NMEA-compatible GPS receiver. Source Code - GpsNode Implementation - Navigation Messages Features - NMEA 0183 protocol support - Multi-constellation (GPS, GLONASS, Galileo, BeiDou) - Position (latitude/longitude), altitude, speed - Course/heading, satellite count, DOP metrics - Fix quality validation (satellite count, HDOP) - Configurable baud rates (4800.1.6200) - Simulation fallback when hardware unavailable - Serial port auto-detection Quick Start Publishes to: gps.fix topic with latitude, longitude, altitude, and accuracy data. Hardware Setup Wiring Diagram USB GPS Modules USB GPS modules appear as /dev/ttyUSB0 or /dev/ttyACM0: Raspberry Pi UART For hardware UART on Raspberry Pi: 1. Disable serial console: 2. Edit /boot/config.txt: 3. Reboot and use /dev/ttyAMA0 or /dev/serial0 Enabling Features There are three ways to enable the required nmea-gps feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using GpsNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Construction Configuration Methods Query Methods Configuration Parameters Type Description GpsBackend GPS backend (Simulation, NmeaSerial) updateratehz 1.0 u16 Minimum satellites required for valid fix maxhdop 20.0 String Coordinate frame identifier serialport \"/dev/ttyUSB0\" u32 Serial communication baud rate Topic Description gps.fix GPS position, velocity, and accuracy data HDOP Accuracy &lt;1 &lt;5m Excellent Navigation, autonomous vehicles 2-5 10-25m Moderate Coarse positioning 10-20 50-100m Poor Unreliable, should reject | Satellite Count Minimum satellites for position fix: - 3 satellites:","headings":"GpsNode Source Code Features Quick Start Hardware Setup Wiring Diagram USB GPS Modules List USB serial devices Check dmesg for connection Raspberry Pi UART Interface Options -> Serial Port \"Would you like a login shell accessible over serial?\" -> No \"Would you like serial port hardware enabled?\" -> Yes Disable Bluetooth to free up UART Enabling Features Output: Auto-detected hardware nodes (features: nmea-gps) Configuration Construction Configuration Methods Query Methods Configuration Parameters Serial Port Configuration Topics Publishers Usage Patterns Position Monitoring Geo-Fencing Speed and Heading Tracking Message Types NavSatFix GPS Accuracy and HDOP HDOP Values Satellite Count Typical Accuracy Common GPS Modules u-blox NEO-6M/NEO-7M/NEO-8M u-blox ZED-F9P (RTK) Adafruit Ultimate GPS (MTK3339) GlobalSat BU-353 Best Practices Troubleshooting Issue: No GPS fix / \"Waiting for GPS fix\" Issue: \"Failed to open GPS serial port\" Issue: Poor accuracy / High HDOP Issue: Stationary drift Simulation Mode See Also","category":"rust"},{"id":115,"title":"I2cBusNode","description":"I2C/TWI bus communication for sensors, displays, and peripherals","slug":"/rust/library/built-in-nodes/i2c-bus","content":"I2cBusNode I2C (Inter-Integrated Circuit) bus communication node for interfacing with sensors, displays, EEPROMs, power monitors, and other I2C peripherals. Supports multiple I2C buses and device addressing. Source Code - I2cBusNode Implementation - I2C Message Types Features - Multiple I2C bus support (I2C-0, I2C-1, etc.) - Configurable clock speed (100kHz, 400kHz, 1MHz) - 7-bit device addressing - Four transaction types: READ, WRITE, READREGISTER, WRITEREGISTER - Automatic retries on failure - Device labeling for debugging - Simulated devices for testing - Hardware fallback to simulation Quick Start Hardware Setup System Requirements Enabling Features There are three ways to enable the required i2c-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using I2cBusNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Verify Hardware Example output: This shows devices at 0x40 and 0x68. Configuration Bus and Clock Speed Reliability Device Management Custom Topics Usage Patterns Reading from a Device Writing to a Device Register Read/Write Common Devices MPU6050 IMU (0x68) INA219 Power Monitor (0x40, 0x41, 0x44, 0x45) OLED Display (0x3C, 0x3D) Error Handling Error Codes Meaning Success 1 Unknown transaction type 3 Device did not acknowledge (hardware) | Troubleshooting Problem: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. Check if I2C device exists: ls /dev/i2c- 2. Check permissions: ls -l /dev/i2c-1 3. Add user to i2c group: sudo usermod -a -G i2c $USER 4. Reboot: sudo reboot 5. Verify with i2cdetect: i2cdetect -y 1 Statistics Bus Scanning Example output: Message Format Transaction Types Clock Speed Constants Best Practices 1. Always check transaction success: 2. Use device labels for debugging: 3. Enable retries for unreliable connections: 4. Use sim","headings":"I2cBusNode Source Code Features Quick Start Hardware Setup System Requirements Install I2C tools Enable I2C interface Add user to i2c group Log out and back in for group to take effect Enabling Features Output: Auto-detected hardware nodes (features: i2c-hardware) Verify Hardware List I2C buses Scan for devices on bus 1 Configuration Bus and Clock Speed Reliability Device Management Custom Topics Usage Patterns Reading from a Device Writing to a Device Register Read/Write Common Devices MPU6050 IMU (0x68) INA219 Power Monitor (0x40, 0x41, 0x44, 0x45) OLED Display (0x3C, 0x3D) Error Handling Error Codes Troubleshooting Statistics Bus Scanning Message Format Transaction Types Clock Speed Constants Best Practices See Also","category":"rust"},{"id":116,"title":"ImageProcessorNode","description":"Computer vision and image processing utilities","slug":"/rust/library/built-in-nodes/image-processor","content":"ImageProcessorNode Image processing node providing computer vision utilities for object detection, color filtering, edge detection, and feature extraction using OpenCV. Source Code - ImageProcessorNode Implementation - Vision Messages Features - Color space conversion (RGB, HSV, grayscale) - Thresholding and filtering - Edge detection (Canny, Sobel) - Blob detection - Contour finding - Object tracking - ArUco marker detection - QR code detection - Image resizing and cropping - Simulation support Quick Start Requires: OpenCV installation and the opencv-backend feature. Enabling Features There are three ways to enable the required opencv-backend feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using ImageProcessorNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Usage Object Detection Color Tracking ArUco Markers Common Operations HSV Color Ranges See Also - CameraNode - Image capture - DepthCameraNode - 3D vision - CollisionDetectorNode - Obstacle avoidance","headings":"ImageProcessorNode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: opencv-backend) Configuration Usage Object Detection Color Tracking ArUco Markers Common Operations HSV Color Ranges See Also","category":"rust"},{"id":117,"title":"ImuNode","description":"Inertial Measurement Unit with accelerometer, gyroscope, and magnetometer","slug":"/rust/library/built-in-nodes/imu","content":"ImuNode Inertial Measurement Unit (IMU) node supporting MPU6050, BNO055, ICM20948, and other I2C-based IMUs. Provides accelerometer, gyroscope, magnetometer data, and sensor fusion for orientation estimation in robots, drones, and stabilization systems. Source Code - ImuNode Implementation - IMU Sensor Messages Features - MPU6050/6500 (6-axis: accel + gyro) - BNO055 (9-axis with hardware fusion) - ICM20948 (9-axis: accel + gyro + mag) - Raw sensor data output - Sensor fusion (Mahony/Madgwick filters) - Quaternion and Euler angle output - Configurable sample rates (up to 1000Hz) - Builder pattern for easy configuration - Hardware fallback to simulation Quick Start Publishes to: imu topic with orientation, angular velocity, and linear acceleration data. Supported Hardware Type I2C Address 6-axis 0x68 (0x69 alt) BNO055 Accel + Gyro + Mag + Fusion 9-axis 0x68 (0x69 alt) Parameter Default frameid \"imulink\" f32 Target sample rate in Hz (1.0-1000.0) topic \"imu\" ImuBackend Hardware backend i2cbus \"/dev/i2c-1\" u8 I2C address of the IMU Sample Rate Use Case 10-50 Hz Power saving mode 100 Hz Normal operation 200-500 Hz High-speed tracking 1000 Hz Vibration analysis | See Also - GpsNode - GPS positioning - EncoderNode - Wheel encoders - OdometryNode - Position tracking - LocalizationNode - Sensor fusion","headings":"ImuNode Source Code Features Quick Start Supported Hardware Enabling Features Output: Auto-detected hardware nodes (features: bno055-imu) or Hardware Setup MPU6050/6500 Wiring BNO055 Wiring Configuration Construction Methods Builder Pattern (Recommended) Configuration Methods Hardware Backend Options Configuration Parameters Usage Patterns Reading IMU Data Orientation Monitoring with Euler Angles Motion Detection Message Types Imu Helper Methods Coordinate Frames IMU Frame Convention Rotation Convention Quaternion Orientation Troubleshooting Issue: No IMU data published Issue: I2C communication errors Check I2C devices Verify IMU address (common: 0x68, 0x69) Reduce I2C bus speed if needed (in /boot/config.txt) Issue: Noisy accelerometer data Issue: Gyroscope drift Best Practices Performance Considerations See Also","category":"rust"},{"id":118,"title":"Built-in Nodes/Drivers","description":"Production-ready nodes and hardware drivers included in horus_library","slug":"/rust/library/built-in-nodes","content":"Built-in Nodes/Drivers The horuslibrary includes a comprehensive collection of 38 production-ready nodes and hardware drivers for building robotics applications. All hardware nodes support automatic simulation fallback when hardware is unavailable. Don't see your hardware or driver? If the current HORUS library doesn't include a node for your specific hardware, please consider publishing it to the HORUS Registry so the community can benefit from your work. See Package Management for details. Quick Start Overview Production-Ready Hardware Integration All built-in nodes are production-grade drivers with real hardware support, not prototypes: - Real hardware drivers - I2C, GPIO, Serial, CAN, USB integrated - Simulation fallback - Test without hardware (automatic) - Error handling - 17-42 error cases per node with recovery - Safety features - Battery alerts, emergency stop, watchdogs - Documentation - 27k+ lines with hardware setup guides - Extensible - Wrap nodes to add custom logic Use built-in nodes as-is for 90% of robotics applications. Wrap them only when you need custom algorithms on top. API Design Philosophy HORUS built-in nodes follow a consistent API pattern: 1. Simple construction - NodeType::new()? with sensible defaults 2. Explicit configuration - set() methods with named parameters 3. Runtime access - getstate() methods to read current values 4. Pub/sub communication - Standard Hub/Link messaging 5. Lifecycle hooks - init(), tick(), shutdown() automatically called Example: Usage Patterns Pattern 1: Use as-is (90% of cases) Pattern 2: Wrap for custom logic (10% of cases) When to Use Built-in Nodes vs Custom Nodes Use built-in nodes when: - Hardware is supported (see node documentation) - Standard behavior is sufficient - You need rapid development - Production reliability is important Create custom nodes when: - Hardware is not yet supported (then publish to marketplace!) - You need specialized algorithms - You're integrating proprietary systems - You're b","headings":"Built-in Nodes/Drivers Quick Start Overview Production-Ready Hardware Integration API Design Philosophy Usage Patterns When to Use Built-in Nodes vs Custom Nodes HORUS Philosophy: Plug-and-Play Nodes, Not Raw Drivers Why Nodes, Not Drivers? Customization with Freedom Custom Drivers & Community Nodes Publish your custom node package Others can install it Node Categories Communication Protocols Motor Controllers Sensors Control & Navigation Safety & Monitoring User Interfaces Computer Vision Machine Learning & AI Hardware Support Automatic Fallback Hardware Detection Enabling Hardware Support Raspberry Pi / Debian-based Enable interfaces Output: Auto-detected hardware nodes (features: i2c-hardware, gpio-hardware) Feature Flags Common Patterns Multi-Sensor Setup Motor Control System Communication Gateway Next Steps Node Documentation Index Communication Motors Sensors Control Safety & I/O Interfaces Computer Vision ML & AI","category":"rust"},{"id":119,"title":"JoystickNode","description":"Game controller input for teleoperation","slug":"/rust/library/built-in-nodes/joystick","content":"JoystickNode Joystick/gamepad input node for robot teleoperation. Supports PlayStation, Xbox, Logitech, and generic USB game controllers for manual control of robots. Source Code - JoystickNode Implementation - Joystick Messages Features - USB game controller support - PlayStation 3/4/5 controllers - Xbox 360/One controllers - Logitech F310/F710 - Axis and button mapping - Deadzone configuration - Button press/release events - Trigger support - Rumble/vibration (if supported) - Simulation support Quick Start Requires: USB game controller and the gilrs feature. Enabling Features There are three ways to enable the required gilrs feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using JoystickNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Usage Teleoperation Example See Also - KeyboardInputNode - Keyboard control - DifferentialDriveNode - Drive commands","headings":"JoystickNode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: gilrs) Configuration Usage Teleoperation Example See Also","category":"rust"},{"id":120,"title":"KeyboardInputNode","description":"Keyboard input for manual robot control","slug":"/rust/library/built-in-nodes/keyboard-input","content":"KeyboardInputNode Keyboard input node for robot teleoperation and manual control. Captures keyboard events for WASD/arrow key control schemes. Source Code - KeyboardInputNode Implementation - Keyboard Messages Features - Key press/release detection - Arrow keys and WASD support - Modifier keys (Shift, Ctrl, Alt) - Configurable key bindings - Key repeat control - Non-blocking input - Simulation support Quick Start Requires: Terminal access and the crossterm feature. Enabling Features There are three ways to enable the required crossterm feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using KeyboardInputNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Usage Teleoperation Example See Also - JoystickNode - Game controller input - DifferentialDriveNode - Drive commands","headings":"KeyboardInputNode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: crossterm) Usage Teleoperation Example See Also","category":"rust"},{"id":121,"title":"LidarNode","description":"2D/3D LiDAR laser rangefinder for mapping and obstacle detection","slug":"/rust/library/built-in-nodes/lidar","content":"LidarNode LiDAR (Light Detection and Ranging) node for 2D and 3D laser rangefinding. Supports RPLidar, YDLIDAR, Hokuyo, SICK, and Velodyne sensors for SLAM, navigation, and obstacle detection. Source Code - LidarNode Implementation - Perception Messages Features - RPLidar A1/A2/A3, YDLIDAR X2/X4 - Hokuyo URG series, SICK TiM/LMS - Velodyne (3D LiDAR) - 360° scanning - Configurable scan rate (5-20 Hz) - Point cloud output - Obstacle detection - Hardware fallback to simulation Quick Start Publishes to: scan topic with 360-degree laser scan data. Requires: Serial port access and the rplidar feature for hardware LiDAR support. Enabling Features There are three ways to enable the required rplidar feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using LidarNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Supported LiDAR Models RPLidar Series Range Angular Resolution 0.15-12m 1 degree 0.15-18m 0.9 degrees 0.15-25m 0.225-0.45 degrees 0.15-40m 0.39 degrees YDLIDAR Series Range Angular Resolution 0.12-10m 1 degree 0.12-8m 1 degree 0.12-16m 0.48 degrees 0.05-30m 0.13 degrees Other Supported Models Range Notes 0.1-30m Industrial grade Hokuyo URG-04LX 10 Hz Various Industrial automation Parameter Default Description frameid \"laserframe\" Coordinate frame identifier for TF transforms scanfrequency 10.0 Target scan rate in scans per second minrange 0.1 Minimum valid range measurement maxrange 30.0 Maximum valid range measurement angleincrement π/180 Angular resolution (default: 1 degree) Topic Description scan Laser scan data with range measurements and metadata | Usage Patterns Basic Obstacle Detection Multi-LiDAR Setup (Front and Rear) Collision Detection Zones Message Types LaserScan Laser scan message containing distance measurements and scan metadata: LaserScan Helper Methods","headings":"LidarNode Source Code Features Quick Start Enabling Features Output: Auto-detected hardware nodes (features: rplidar) Supported LiDAR Models RPLidar Series YDLIDAR Series Other Supported Models Configuration Construction Configuration Methods Configuration Parameters Topics Publishers Usage Patterns Basic Obstacle Detection Multi-LiDAR Setup (Front and Rear) Collision Detection Zones Message Types LaserScan LaserScan Helper Methods Coordinate System Scan Parameters Explanation Angular Resolution (angleincrement) Range Limits Scan Frequency Integration with SLAM/Navigation GMapping SLAM Integration Costmap Generation Troubleshooting Issue: No scan data published Issue: Serial port permission denied Add user to dialout group (Linux) Set permissions on device Verify device exists Create udev rule Add rule for RPLidar Reload rules Issue: Inconsistent scan rate Issue: Noisy or invalid readings Issue: USB device disconnects Disable USB autosuspend (Linux) Performance Considerations CPU Usage Memory Usage Bandwidth Optimization Tips See Also","category":"rust"},{"id":122,"title":"LocalizationNode","description":"Sensor fusion for accurate position estimation","slug":"/rust/library/built-in-nodes/localization","content":"LocalizationNode Localization node fusing multiple sensors (odometry, IMU, GPS, LiDAR) for accurate position estimation. Implements Extended Kalman Filter (EKF) and particle filters for robust localization. Source Code - LocalizationNode Implementation - Navigation Messages Features - Extended Kalman Filter (EKF) - Particle Filter (Monte Carlo Localization) - Sensor fusion (odom + IMU + GPS + LiDAR) - Map-based localization - AMCL (Adaptive Monte Carlo Localization) - Covariance estimation - Simulation support Quick Start Usage See Also - OdometryNode - Wheel odometry - ImuNode - Inertial measurement - GpsNode - GPS positioning - LidarNode - Map matching","headings":"LocalizationNode Source Code Features Quick Start Usage See Also","category":"rust"},{"id":123,"title":"ModbusNode","description":"Modbus RTU/TCP communication for industrial devices","slug":"/rust/library/built-in-nodes/modbus","content":"ModbusNode Modbus protocol communication node for industrial automation, supporting both Modbus RTU (serial) and Modbus TCP (Ethernet) variants. Interfaces with PLCs, sensors, motor drives, power meters, and industrial control systems. Source Code - ModbusNode Implementation - Modbus Message Types Features - Modbus RTU (RS485/RS232) - Modbus TCP (Ethernet) - Master and Slave modes - All function codes (0x01-0x17) - Multiple slave addressing (1-247) - Configurable timeouts - CRC/checksum validation - Register mapping - Hardware fallback to simulation Quick Start Hardware Setup System Requirements Modbus RTU Wiring (RS485) Important: RS485 requires 120Ω termination resistors at both ends of the bus. Modbus TCP Setup Enabling Features There are three ways to enable the required serial-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using ModbusNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Modbus RTU Modbus TCP Operating Modes Function Codes Coils (Digital Outputs) Discrete Inputs (Digital Inputs) Input Registers (Analog Inputs) Holding Registers (Analog Outputs) Usage Patterns Reading Sensor Data Writing Control Values Polling Multiple Slaves Common Devices Power Meter (Eastron SDM120) Temperature Controller VFD (Variable Frequency Drive) PLC (Programmable Logic Controller) Message Format ModbusRequest ModbusResponse Exception Codes Complete Example: SCADA System Register Mapping Many devices use specific register layouts. Example: Best Practices 1. Use correct function code for register type: 2. Set appropriate timeouts: 3. Handle exceptions gracefully: 4. Respect bus timing (RTU): 5. Use proper termination (RS485): 6. Test with Modbus tools first: Troubleshooting Problem: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. RTU: Ch","headings":"ModbusNode Source Code Features Quick Start Hardware Setup System Requirements Install Modbus tools For RTU: Add user to dialout group For TCP: Ensure network connectivity Modbus RTU Wiring (RS485) Modbus TCP Setup No special wiring - uses standard Ethernet Default port: 502 Enabling Features Output: Auto-detected hardware nodes (features: serial-hardware) Configuration Modbus RTU Modbus TCP Operating Modes Function Codes Coils (Digital Outputs) Discrete Inputs (Digital Inputs) Input Registers (Analog Inputs) Holding Registers (Analog Outputs) Usage Patterns Reading Sensor Data Writing Control Values Polling Multiple Slaves Common Devices Power Meter (Eastron SDM120) Temperature Controller VFD (Variable Frequency Drive) PLC (Programmable Logic Controller) Message Format ModbusRequest ModbusResponse Exception Codes Complete Example: SCADA System Register Mapping Best Practices Troubleshooting Testing Modbus RTU testing Modbus TCP testing Modbus slave simulator See Also","category":"rust"},{"id":124,"title":"OdometryNode","description":"Dead reckoning position tracking from wheel encoders","slug":"/rust/library/built-in-nodes/odometry","content":"OdometryNode Odometry node for position tracking using wheel encoder data. Calculates robot pose (x, y, theta) through dead reckoning for navigation and localization. Source Code - OdometryNode Implementation - Navigation Messages Features - 2D pose estimation (x, y, theta) - Wheel encoder integration - Velocity estimation - Covariance tracking - Configurable wheel parameters - Reset/calibration - Simulation support Quick Start Usage See Also - EncoderNode - Encoder reading - DifferentialDriveNode - Drive control - LocalizationNode - Sensor fusion","headings":"OdometryNode Source Code Features Quick Start Usage See Also","category":"rust"},{"id":125,"title":"ONNXInferenceNode","description":"Generic ONNX model inference for custom ML models","slug":"/rust/library/built-in-nodes/onnx-inference","content":"ONNXInferenceNode Generic ONNX model inference node for running custom machine learning models. Supports image classification, object detection, segmentation, and any ONNX-compatible model. Source Code - ONNXInferenceNode Implementation - ML Messages Features - Generic ONNX model support - CPU and GPU execution providers - Batch inference support - Dynamic input/output tensor handling - Preprocessing pipeline (resize, normalize) - Performance metrics tracking - Model optimization levels Supported Model Types - Image classification (ResNet, MobileNet, EfficientNet) - Object detection (YOLO, SSD, Faster R-CNN) - Semantic segmentation (DeepLab, U-Net) - Pose estimation (OpenPose, MediaPipe) - Custom ONNX models Requirements Enable the onnx feature in your horus.yaml: Quick Start Configuration InferenceConfig Type Description usize Batch size for inference usegpu false u32 GPU device ID confidencethreshold 0.5 bool Enable image preprocessing inputsize None [f32; 3] Normalization mean (ImageNet) normstd [0.229, 0.224, 0.225] u8 Graph optimization (0-3) Level Use Case 0 Debugging 1 Default 2 Production 3 Maximum performance Topic Description {inputtopic} Input images {inputtopic}/tensor Raw tensor input Topic Description {outputtopic} Model predictions {outputtopic}/tensor Raw output tensor {outputtopic}/metrics Performance metrics | Usage Examples Image Classification Custom Model with Specific Preprocessing Batch Processing Raw Tensor I/O Model Conversion Convert models from other frameworks to ONNX: PyTorch TensorFlow Performance Tips 1. Enable GPU - Set usegpu: true for 5-10x speedup 2. Batch processing - Process multiple images together 3. Optimize graph - Use optimizationlevel: 2 or higher 4. Match input size - Use model's native input size when possible See Also - TFLiteInferenceNode - TensorFlow Lite inference - YOLOv8DetectorNode - Object detection - PoseEstimationNode - Pose estimation","headings":"ONNXInferenceNode Source Code Features Supported Model Types Requirements Quick Start Configuration InferenceConfig Optimization Levels Topics Subscribed Topics Published Topics Usage Examples Image Classification Custom Model with Specific Preprocessing Batch Processing Raw Tensor I/O Model Conversion PyTorch TensorFlow Performance Tips See Also","category":"rust"},{"id":126,"title":"PathPlannerNode","description":"Path planning algorithms for autonomous navigation","slug":"/rust/library/built-in-nodes/path-planner","content":"PathPlannerNode Path planning node implementing A, RRT, and other planning algorithms for autonomous navigation. Generates collision-free paths from start to goal positions. Source Code - PathPlannerNode Implementation - Navigation Messages Features - A (grid-based) - RRT/RRT (sampling-based) - Dijkstra's algorithm - Dynamic replanning - Obstacle avoidance - Configurable resolution - Simulation support Quick Start Usage See Also - OdometryNode - Position tracking - LidarNode - Obstacle detection - CollisionDetectorNode - Collision avoidance","headings":"PathPlannerNode Source Code Features Quick Start Usage See Also","category":"rust"},{"id":127,"title":"PidControllerNode","description":"PID control loop for precise position, velocity, and process control","slug":"/rust/library/built-in-nodes/pid-controller","content":"PidControllerNode Proportional-Integral-Derivative (PID) controller node for closed-loop control of position, velocity, temperature, and other process variables. Provides tunable PID gains, anti-windup, and deadband for precise control applications. Source Code - PidControllerNode Implementation - Control Messages Features - P, PI, PD, and PID control modes - Anti-windup protection - Output limiting - Error deadband - Multiple controllers - Motor ID management - Runtime gain adjustment - Simulation support Quick Start Subscribes to: pid.setpoint and pid.feedback Publishes to: motorcmd (PwmCommand with calculated control output) Architecture This node is a thin wrapper around the pure algorithm in horuslibrary/algorithms/: - algorithms::pid::PID - PID feedback control algorithm with anti-windup and deadband The node handles: - Topic subscription/publishing (Hub I/O) - Setpoint and feedback reception - Motor command publishing - Configuration updates The algorithm handles: - PID computation (P, I, D terms) - Anti-windup (integral limiting) - Output limiting - Deadband application Configuration Construction Configuration Methods Configuration Parameters Type Description f32 Proportional gain ki 0.1 f32 Derivative gain outputmin -100.0 f32 Maximum output value integralmin -50.0 f32 Maximum integral value (anti-windup) deadband 0.01 u8 Motor identifier for output commands Topic Description setpoint Target value for the controller feedback Current measurement from sensor pidconfig Runtime PID parameter updates Topic Description pidoutput Control output command Application Ki Notes Motor Position 0.1-1.0 Fast response needed Motor Velocity 0.1-0.5 Less integral gain Temperature 1.0-5.0 Slow system, more integral Pressure 0.5-2.0 Medium response | Anti-Windup The integral term can accumulate (\"wind up\") when the output is saturated, causing overshoot. This node implements anti-windup by clamping the integral value: Guidelines: - Set integral limits to about 50% of output li","headings":"PidControllerNode Source Code Features Quick Start Architecture Configuration Construction Configuration Methods Configuration Parameters Topics Subscribers Publishers Usage Patterns Basic Position Control Velocity Control Temperature Control Multiple PID Controllers Message Types PidConfig MotorCommand PID Tuning Guide Understanding PID Terms Tuning Process (Ziegler-Nichols Method) Common Applications and Typical Gains Anti-Windup Deadband Implementation Details Control Loop Calculation Deadband Application Output Limiting Troubleshooting Issue: Output oscillates Issue: Steady-state error Issue: Slow response Issue: Output saturates Performance Considerations Update Rate CPU Usage Memory Usage See Also","category":"rust"},{"id":128,"title":"PoseEstimationNode","description":"Human pose estimation and skeleton detection","slug":"/rust/library/built-in-nodes/pose-estimation","content":"PoseEstimationNode Human pose estimation node for detecting body keypoints and skeleton structure. Supports multiple pose models for robotics applications including human-robot interaction and gesture recognition. Source Code - PoseEstimationNode Implementation - ML Messages Features - Multiple pose model support (MoveNet, BlazePose, OpenPose) - 17-33 body keypoints detection - Skeleton visualization - Multi-person pose estimation - Real-time performance (30+ FPS) - GPU acceleration Requirements Enable the onnx feature in your horus.yaml: Quick Start Configuration PoseConfig Type Description PoseModelType Pose model to use confidencethreshold 0.3 usize Maximum people to detect usegpu false bool Output skeleton visualization Model Speed MoveNetLightning Fastest 17 Balanced accuracy BlazePose Medium 25 High accuracy Topic Description {inputtopic} Input camera images Topic Description {outputtopic} Detected poses with keypoints {outputtopic}/viz Skeleton visualization Model CPU (i7-12700) MoveNet Lightning 30+ FPS MoveNet Thunder 15-20 FPS BlazePose 8-12 FPS | See Also - YOLOv8DetectorNode - Object detection - SemanticSegmentationNode - Scene understanding - CameraNode - Image input","headings":"PoseEstimationNode Source Code Features Requirements Quick Start Configuration PoseConfig PoseModelType Topics Subscribed Topics Published Topics Keypoint Layout (17-point model) Usage Examples Gesture Recognition Human-Robot Interaction Safety Monitoring Performance See Also","category":"rust"},{"id":129,"title":"RoboclawMotorNode","description":"Roboclaw dual motor controller with encoder feedback","slug":"/rust/library/built-in-nodes/roboclaw-motor","content":"RoboclawMotorNode Roboclaw dual motor controller node supporting the full range of Roboclaw boards from BasicMicro. Provides DC motor control with quadrature encoder feedback, current sensing, and advanced motion profiling for mobile robots and drive systems. Source Code - RoboclawMotorNode Implementation - Motor Control Messages Features - Dual motor control per controller - Multiple Roboclaw controllers (chaining) - Quadrature encoder feedback - Position, velocity, and duty cycle control - PID tuning and motion profiling - Current limiting and monitoring - Battery voltage monitoring - Temperature monitoring - E-stop and failsafe - Serial TTL or USB communication - Simulation fallback Quick Start Hardware Setup System Requirements Wiring Example Encoder Connections Enabling Features There are three ways to enable the required serial-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using RoboclawMotorNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Roboclaw Models Voltage Ratings Configuration Communication Setup Encoder Configuration Motor Configuration PID Configuration Limits Control Modes Duty Cycle Control (Open Loop) Velocity Control (Closed Loop) Position Control (Closed Loop) Mixed Mode (Differential Drive) Usage Patterns Differential Drive Robot Position Tracking Reset Encoders Message Format RoboclawCommand Command Types RoboclawMixedCommand RoboclawStatus Error Flags PID Tuning Guide Velocity PID 1. Start with all gains at zero 2. Increase P until oscillation: 3. Add I to eliminate steady-state error: 4. Add D to reduce overshoot (usually not needed for velocity) Position PID 1. Set maxspeed appropriately 2. Tune P first 3. Add D to reduce overshoot 4. Add I if needed for position holding Best Practices 1. Always use encoder feedback: 2. Set cur","headings":"RoboclawMotorNode Source Code Features Quick Start Hardware Setup System Requirements Install USB-serial drivers Add user to dialout group Verify port Wiring Example Encoder Connections Enabling Features Output: Auto-detected hardware nodes (features: serial-hardware) Roboclaw Models Voltage Ratings Configuration Communication Setup Encoder Configuration Motor Configuration PID Configuration Limits Control Modes Duty Cycle Control (Open Loop) Velocity Control (Closed Loop) Position Control (Closed Loop) Mixed Mode (Differential Drive) Usage Patterns Differential Drive Robot Position Tracking Reset Encoders Message Format RoboclawCommand Command Types RoboclawMixedCommand RoboclawStatus Error Flags PID Tuning Guide Velocity PID Position PID Best Practices Motion Studio Troubleshooting Graceful Shutdown See Also","category":"rust"},{"id":130,"title":"SafetyMonitorNode","description":"System health monitoring and diagnostics","slug":"/rust/library/built-in-nodes/safety-monitor","content":"SafetyMonitorNode System health monitoring node tracking temperature, voltage, current, CPU usage, and other vital parameters. Provides warnings and automatic shutdown for safety-critical conditions. Source Code - SafetyMonitorNode Implementation - Diagnostics Messages Features - Temperature monitoring - Voltage monitoring - Current monitoring - CPU/memory usage - Disk space monitoring - Network connectivity - Sensor health checks - Configurable thresholds - Warning and critical alerts - Auto-shutdown triggers - Simulation support Quick Start Usage See Also - EmergencyStopNode - E-stop system - BatteryMonitorNode - Battery monitoring","headings":"SafetyMonitorNode Source Code Features Quick Start Usage See Also","category":"rust"},{"id":131,"title":"SemanticSegmentationNode","description":"Pixel-wise scene segmentation for environment understanding","slug":"/rust/library/built-in-nodes/semantic-segmentation","content":"SemanticSegmentationNode Semantic segmentation node for pixel-wise scene understanding. Classifies every pixel in an image into semantic categories for navigation, obstacle detection, and scene comprehension. Source Code - SemanticSegmentationNode Implementation - ML Messages Features - Pixel-wise semantic classification - Multiple model architectures (DeepLabV3, SegFormer) - Real-time performance - Configurable class labels - GPU acceleration - Colorized segmentation output Requirements Enable the onnx feature in your horus.yaml: Quick Start Configuration SegmentationConfig Type Description usize Number of semantic classes inputsize (512, 512) bool Enable GPU acceleration enablecolorizedoutput true Vec<String Class label names Topic Description {inputtopic} Input camera images Topic Description {outputtopic} Per-pixel class IDs {outputtopic}/colorized Colorized segmentation {outputtopic}/metrics Inference timing Model GPU (RTX 3080) DeepLabV3-MobileNet 45-60 FPS 512x512 3-5 FPS SegFormer-B0 40-50 FPS See Also - YOLOv8DetectorNode - Object detection - PoseEstimationNode - Human pose detection - DepthCameraNode - 3D depth perception - PathPlannerNode - Navigation planning","headings":"SemanticSegmentationNode Source Code Features Requirements Quick Start Configuration SegmentationConfig Topics Subscribed Topics Published Topics Common Class Sets Pascal VOC (21 classes) Cityscapes (19 classes) Usage Examples Navigable Area Detection Obstacle Avoidance Custom Indoor Classes Performance See Also","category":"rust"},{"id":132,"title":"SerialNode","description":"UART/RS232/RS485 serial communication for sensors and devices","slug":"/rust/library/built-in-nodes/serial","content":"SerialNode Universal Asynchronous Receiver-Transmitter (UART) serial communication node for interfacing with GPS modules, sensor arrays, motor controllers, telemetry radios, and any serial devices. Supports RS232, RS485, and TTL serial protocols. Source Code - SerialNode Implementation - Serial Message Types Features - Multiple serial ports (ttyUSB, ttyS, ttyAMA) - Configurable baud rates (9600 to 921600) - Data bits (5, 6, 7, 8), parity (None, Even, Odd), stop bits (1, 2) - Flow control (None, RTS/CTS, XON/XOFF) - Binary and ASCII modes - Line-based and binary framing - Timeout configuration - Hardware fallback to simulation Quick Start Hardware Setup System Requirements USB-to-Serial Adapters RS232 Wiring RS485 Wiring (Half-Duplex) Enabling Features There are three ways to enable the required serial-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using SerialNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Port and Baud Rate Data Format Flow Control Timeouts Framing Modes Usage Patterns Sending Data Receiving Data Line-Based Protocol Common Devices GPS Module (NMEA) Arduino (Firmata Protocol) Modbus RTU Device Telemetry Radio (3DR Radio) Message Format Complete Example: GPS Logger Port Discovery Best Practices 1. Always configure format correctly: 2. Set appropriate timeouts: 3. Use correct framing for your protocol: 4. Check permissions: 5. Flush buffers when switching modes: 6. Handle disconnections gracefully: Troubleshooting Problem: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. Check port exists: ls -l /dev/ttyUSB 2. Check permissions: groups (should include \"dialout\") 3. Add to dialout: sudo usermod -a -G dialout $USER (then logout/login) 4. Check if port is in use: lsof /dev/ttyUSB0 5. Test with minicom: minicom -D /d","headings":"SerialNode Source Code Features Quick Start Hardware Setup System Requirements Install serial tools Add user to dialout group Verify serial ports USB-to-Serial Adapters RS232 Wiring RS485 Wiring (Half-Duplex) Enabling Features Output: Auto-detected hardware nodes (features: serial-hardware) Configuration Port and Baud Rate Data Format Flow Control Timeouts Framing Modes Usage Patterns Sending Data Receiving Data Line-Based Protocol Common Devices GPS Module (NMEA) Arduino (Firmata Protocol) Modbus RTU Device Telemetry Radio (3DR Radio) Message Format Complete Example: GPS Logger Port Discovery Best Practices Troubleshooting Testing Send test data Receive data Monitor with screen Monitor with minicom See Also","category":"rust"},{"id":133,"title":"ServoControllerNode","description":"Standard PWM servo control for up to 16 servos","slug":"/rust/library/built-in-nodes/servo-controller","content":"ServoControllerNode Standard PWM servo controller node for hobby servos (analog and digital). Supports up to 16 servos using hardware PWM, software PWM, or external servo controllers like PCA9685. Ideal for robot arms, grippers, pan-tilt systems, and actuated mechanisms. Source Code - ServoControllerNode Implementation - Motor Control Messages Features - Up to 16 servos simultaneously - Hardware PWM (2 channels) or software PWM - PCA9685 16-channel I2C controller support - Configurable pulse width (500-2500 μs) - Position, speed, and acceleration control - Center calibration per servo - Min/max angle limits - Smooth motion profiles - Hardware fallback to simulation Quick Start Hardware Setup System Requirements GPIO PWM (Direct Connection) Hardware PWM pins on Raspberry Pi: - GPIO 12, 13 (PWM0) - GPIO 18, 19 (PWM0, PWM1) PCA9685 I2C Controller Advantages: - 16 servos from one I2C address - Chain multiple boards (up to 62) - Dedicated servo power supply - No CPU load for PWM generation Enabling Features There are three ways to enable the required features: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using ServoControllerNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Servo Setup (GPIO) PCA9685 Setup Pulse Width Configuration Angle Configuration Speed Control Limits Usage Patterns Position Control (Angle) Position Control (Pulse Width) Smooth Movement Disable/Enable Servo Calibration Complete Example: Pan-Tilt Camera Message Format ServoCommand Command Types ServoStatus Servo Types Analog Servos Digital Servos Continuous Rotation Servos PCA9685 Features Multiple Boards Output Enable Frequency Calibration Procedure Best Practices 1. Always set appropriate limits: 2. Use speed control for smoother motion: 3. Calibrate each servo: 4. Power servos separately f","headings":"ServoControllerNode Source Code Features Quick Start Hardware Setup System Requirements Install GPIO and I2C libraries Enable GPIO and I2C GPIO PWM (Direct Connection) PCA9685 I2C Controller Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Configuration Servo Setup (GPIO) PCA9685 Setup Pulse Width Configuration Angle Configuration Speed Control Limits Usage Patterns Position Control (Angle) Position Control (Pulse Width) Smooth Movement Disable/Enable Servo Calibration Complete Example: Pan-Tilt Camera Message Format ServoCommand Command Types ServoStatus Servo Types Analog Servos Digital Servos Continuous Rotation Servos PCA9685 Features Multiple Boards Output Enable Frequency Calibration Procedure Best Practices Troubleshooting Servo Specifications Common Specifications Torque Ratings Graceful Shutdown See Also","category":"rust"},{"id":134,"title":"SpiBusNode","description":"SPI bus communication for high-speed peripherals","slug":"/rust/library/built-in-nodes/spi-bus","content":"SpiBusNode Serial Peripheral Interface (SPI) bus communication node for high-speed data transfer with ADCs, DACs, SD cards, displays, and other SPI peripherals. Supports multiple chip selects and SPI modes. Source Code - SpiBusNode Implementation - SPI Message Types Features - Multiple SPI bus support (SPI-0, SPI-1, etc.) - Up to 8 chip select (CS) lines per bus - Four SPI modes (0-3) for clock polarity/phase - Configurable clock speed (up to 32 MHz) - Full-duplex communication - Per-device configuration - Hardware fallback to simulation Quick Start Hardware Setup System Requirements Wiring Example Enabling Features There are three ways to enable the required spi-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using SpiBusNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Bus and Speed SPI Modes Per-Device Configuration Usage Patterns Basic Transfer Read from Device Write to Device Common Devices MCP3008 ADC (8-channel, 10-bit) SD Card (SPI Mode) OLED Display (SSD1306) Message Format SPI Modes Explained CPOL Clock Polarity 0 Idle low 0 Idle low 1 Idle high 1 Idle high Best Practices 1. Use correct SPI mode for your device: 2. Start with lower speeds: 3. Keep wires short: 4. Check hardware device paths: Troubleshooting Problem: \"Hardware unavailable - using SIMULATION mode\" Solutions: 1. Check SPI device: ls /dev/spidev 2. Enable SPI: sudo raspi-config -Interface Options -SPI 3. Check permissions: ls -l /dev/spidev0.0 4. Add to spi group: sudo usermod -a -G spi $USER 5. Reboot: sudo reboot Problem: Reading all zeros or 0xFF Solutions: 1. Check wiring (MOSI ↔ MISO often swapped) 2. Verify SPI mode matches device 3. Check clock speed (too fast can cause errors) 4. Ensure device is powered See Also - I2cBusNode - I2C communication - CanBusNode - C","headings":"SpiBusNode Source Code Features Quick Start Hardware Setup System Requirements Install SPI tools Enable SPI interface Add user to spi group Wiring Example Enabling Features Output: Auto-detected hardware nodes (features: spi-hardware) Configuration Bus and Speed SPI Modes Per-Device Configuration Usage Patterns Basic Transfer Read from Device Write to Device Common Devices MCP3008 ADC (8-channel, 10-bit) SD Card (SPI Mode) OLED Display (SSD1306) Message Format SPI Modes Explained Best Practices Troubleshooting See Also","category":"rust"},{"id":135,"title":"StepperMotorNode","description":"Stepper motor control with motion profiling and multi-motor support","slug":"/rust/library/built-in-nodes/stepper-motor","content":"StepperMotorNode High-performance stepper motor controller with support for up to 8 motors, microstepping, motion profiling, gear ratios, and homing. Ideal for CNC machines, 3D printers, robot arms, and precision positioning systems. Source Code - StepperMotorNode Implementation - Stepper Control Messages Features - Up to 8 stepper motors simultaneously - Microstepping support (1, 2, 4, 8, 16, 32, etc.) - Motion profiling (trapezoidal acceleration) - Gear ratio support - Position, velocity, and homing commands - Per-motor configuration (steps/rev, max speed, acceleration) - Current limiting - Hardware GPIO control or simulation - Position feedback Quick Start Hardware Setup System Requirements Wiring Example (A4988 Driver) Enabling Features There are three ways to enable the required gpio-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using StepperMotorNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Motor Setup Microstepping Gear Ratios Motion Parameters GPIO Pins Timeouts and Feedback Usage Patterns Position Control Velocity Control Relative Movement Homing Stop/Emergency Motion Profiling Trapezoidal Profile The node automatically generates trapezoidal velocity profiles: Parameters: - Acceleration phase: Ramps up to target velocity - Cruise phase: Constant velocity (if distance allows) - Deceleration phase: Ramps down to target position Example Complete Example: CNC System Message Format StepperCommand Command Types Best Practices 1. Always enable feedback for critical applications: 2. Use appropriate microstepping: - Full/half step: High torque, more vibration - 1/16 step: Smooth, quiet, less torque - Balance based on your needs 3. Set realistic velocities: 4. Enable current limiting: 5. Implement homing on startup: Troubleshooting Probl","headings":"StepperMotorNode Source Code Features Quick Start Hardware Setup System Requirements Install GPIO library Enable GPIO interface Wiring Example (A4988 Driver) Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Configuration Motor Setup Microstepping Gear Ratios Motion Parameters GPIO Pins Timeouts and Feedback Usage Patterns Position Control Velocity Control Relative Movement Homing Stop/Emergency Motion Profiling Trapezoidal Profile Example Complete Example: CNC System Message Format StepperCommand Command Types Best Practices Troubleshooting Graceful Shutdown See Also","category":"rust"},{"id":136,"title":"TensorRTInferenceNode","description":"High-performance inference using NVIDIA TensorRT","slug":"/rust/library/built-in-nodes/tensorrt-inference","content":"TensorRTInferenceNode High-performance inference using NVIDIA TensorRT for 2-5x speedup over standard ONNX Runtime on NVIDIA GPUs. Supports FP32, FP16, and INT8 precision modes with automatic engine caching. Source Code - TensorRTInferenceNode Implementation - ML Messages Performance Comparison YOLOv8n @ 640x640 100ms 15ms 5ms 3ms Features - FP32, FP16, and INT8 precision modes - Automatic engine caching for fast subsequent loads - Zero-copy GPU memory when possible - Dynamic batch size support - DLA support for Jetson devices - CUDA graph capture for reduced kernel overhead Requirements System Dependencies Hardware Requirements - NVIDIA GPU with CUDA compute capability = 7.0 - Turing architecture or newer recommended (RTX 20-series, Jetson Xavier/Orin) - CUDA toolkit 11.x or 12.x - cuDNN 8.x - TensorRT 8.x or later (8.6+ recommended) Feature Flag Enable in your horus.yaml: Quick Start Configuration TensorRTConfig Options Type Description usize Batch size for inference maxbatchsize 8 TensorRTPrecision Precision mode deviceid 0 f32 Prediction threshold enablepreprocessing true Option<[u32; 2] Target input [H, W] normmean ImageNet [f32; 3] Normalization std workspacesizemb 1024 Option<PathBuf Engine cache directory forcerebuild false bool Use DLA (Jetson only) dlacore 0 bool CUDA graph capture Mode Speed FP32 1x Half precision Very good INT8 3-5x Topics Subscribed Topics (Image Input) Type Image Subscribed Topics (Tensor Input) Type Tensor Published Topics Type Predictions Tensor InferenceMetrics Usage Examples Image Classification Object Detection (YOLOv8) INT8 Quantization Jetson DLA Acceleration Raw Tensor Input Batch Processing Engine Caching TensorRT builds optimized engines from ONNX models. This process is slow but only happens once: Recommendation: Always set enginecachedir for production deployments. Performance Tips 1. Use FP16 for Best Balance 2. Match Input Size to Model 3. Enable Engine Caching 4. Use Appropriate Workspace 5. Consider Batch Processing Tro","headings":"TensorRTInferenceNode Source Code Performance Comparison Features Requirements System Dependencies Ubuntu 22.04 Verify installation Hardware Requirements Feature Flag Quick Start Configuration TensorRTConfig Options Precision Modes Topics Subscribed Topics (Image Input) Subscribed Topics (Tensor Input) Published Topics Usage Examples Image Classification Object Detection (YOLOv8) INT8 Quantization Jetson DLA Acceleration Raw Tensor Input Batch Processing Engine Caching Performance Tips 1. Use FP16 for Best Balance 2. Match Input Size to Model 3. Enable Engine Caching 4. Use Appropriate Workspace 5. Consider Batch Processing Troubleshooting Engine Build Fails Slow First Run INT8 Accuracy Issues DLA Not Available Comparison with ONNXInferenceNode See Also","category":"rust"},{"id":137,"title":"TFLiteInferenceNode","description":"TensorFlow Lite inference for edge devices","slug":"/rust/library/built-in-nodes/tflite-inference","content":"TFLiteInferenceNode TensorFlow Lite inference node optimized for edge devices and embedded systems. Run ML models on Raspberry Pi, Jetson, and other resource-constrained platforms. Source Code - TFLiteInferenceNode Implementation - ML Messages Features - Optimized for edge devices (Raspberry Pi, Jetson) - CPU, GPU delegate, and Coral TPU support - Quantized model support (INT8) - Low memory footprint - Real-time inference on embedded systems Requirements Enable the tflite-inference feature in your horus.yaml: Quick Start Configuration TFLiteConfig Type Description usize Number of CPU threads usegpudelegate false bool Enable Coral Edge TPU inputsize None bool Enable image preprocessing Topic Description {inputtopic} Input images Topic Description {outputtopic} Model predictions {outputtopic}/metrics Performance metrics Model FPS MobileNetV2 25-30 MobileNetV2 8-12 EfficientNet-Lite0 15-20 Model MobileNetV2 EdgeTPU 40-50 | Model Quantization Convert a TensorFlow model to quantized TFLite: See Also - ONNXInferenceNode - ONNX model inference - CameraNode - Image input - YOLOv8DetectorNode - Object detection","headings":"TFLiteInferenceNode Source Code Features Requirements Quick Start Configuration TFLiteConfig Delegates CPU (Default) GPU Delegate (Jetson, Android) Coral Edge TPU Topics Subscribed Topics Published Topics Usage Examples Image Classification on Raspberry Pi Object Detection with Coral TPU Reading Predictions Model Sources TensorFlow Hub Download pre-trained TFLite models Coral Model Zoo Edge TPU optimized models Performance Raspberry Pi 4 (4GB) With Coral USB Accelerator Model Quantization Representative dataset for calibration See Also","category":"rust"},{"id":138,"title":"UltrasonicNode","description":"HC-SR04 ultrasonic distance sensor with multi-sensor support","slug":"/rust/library/built-in-nodes/ultrasonic","content":"UltrasonicNode HC-SR04 ultrasonic distance sensor node for obstacle detection, proximity sensing, and rangefinding. Supports multiple sensors simultaneously for 360° coverage or sensor arrays. Source Code - UltrasonicNode Implementation - Range Message Type Features - HC-SR04 and compatible sensors - Multi-sensor support (up to 8 sensors) - Range: 2cm to 4m - Configurable measurement rate - Median filtering for noise reduction - Temperature compensation - Simulation fallback - Hardware GPIO control Quick Start Hardware Setup HC-SR04 Wiring IMPORTANT: HC-SR04 Echo pin outputs 5V but Raspberry Pi GPIOs are 3.3V tolerant! Voltage Divider for Echo Pin This creates: 3.3V = 5V × (2kΩ / (1kΩ + 2kΩ)) Multiple Sensors System Requirements Enabling Features There are three ways to enable the required gpio-hardware feature: Option 1: Automatic detection (recommended) When you use horus run, HORUS automatically detects that you're using UltrasonicNode and enables the feature: Option 2: Explicit in horus.yaml Add the feature to your horus.yaml dependencies: Option 3: Manual Cargo.toml (for cargo projects) If using cargo directly: Configuration Adding Sensors Measurement Rate Filtering Range Limits Temperature Compensation Usage Patterns Reading Distance Obstacle Detection Multi-Sensor Array Complete Example: Obstacle Avoidance Message Format Range Published on topic: ultrasonic.range Constants: - Range::ULTRASONIC = 0 - Range::INFRARED = 1 Timing and Accuracy Measurement Process 1. Trigger: 10μs pulse on trigger pin 2. Echo wait: Up to 38ms for maximum range 3. Echo measurement: Time echo pin is HIGH 4. Distance calculation: distance = (time × speedofsound) / 2 Timing Constraints Accuracy - Resolution: 3mm (based on timing resolution) - Accuracy: ±3cm typical - Affected by: - Temperature (speed of sound changes) - Surface angle (best at 90°) - Surface material (soft materials absorb sound) - Air currents Limitations - Minimum range: 2cm (echo too close to trigger) - Maximum range","headings":"UltrasonicNode Source Code Features Quick Start Hardware Setup HC-SR04 Wiring Voltage Divider for Echo Pin Multiple Sensors System Requirements Install GPIO library Enable GPIO Enabling Features Output: Auto-detected hardware nodes (features: gpio-hardware) Configuration Adding Sensors Measurement Rate Filtering Range Limits Temperature Compensation Usage Patterns Reading Distance Obstacle Detection Multi-Sensor Array Complete Example: Obstacle Avoidance Message Format Range Timing and Accuracy Measurement Process Timing Constraints Accuracy Limitations Best Practices Troubleshooting Simulation Mode See Also","category":"rust"},{"id":139,"title":"Visual Odometry","description":"Camera-based motion estimation using feature tracking","slug":"/rust/library/built-in-nodes/visual-odometry","content":"Visual Odometry Node The VisualOdometryNode provides visual odometry estimation from camera images using feature-based methods. It extracts features, tracks them across frames, and estimates camera motion for localization. Features - Monocular visual odometry - Single camera with scale ambiguity - Stereo visual odometry - Full scale recovery with stereo baseline - RGB-D visual odometry - Depth from sensor for metric scale - Multiple feature detectors - ORB, SIFT, FAST, Good Features to Track - Loop closure detection - Appearance-based place recognition - Hybrid node pattern - Injectable processing via closures or processors Basic Usage Configuration Camera Modes Description Single camera Stereo camera pair RGB-D camera Feature Detectors Speed Best For Fast General purpose SIFT Yes Very fast Real-time GoodFeatures No VOConfig Options Type Description CameraMode Camera configuration featuredetector ORB MatchingMethod Feature matching approach maxfeatures 500 f64 Minimum feature quality (0-1) mindistance 7.0 [f64; 4] [fx, fy, cx, cy] stereobaseline 0.12 f64 Min inliers for valid pose enableloopclosure false f64 Keyframe translation threshold (m) keyframethresholdrot 0.1 Topics Subscribed Type Image Image Image Published Type Odometry Stereo Visual Odometry RGB-D Visual Odometry Hybrid Processing The node supports the hybrid pattern for custom processing: Integration with Localization Combine visual odometry with other sensors for robust localization: Scale Estimation For monocular VO, scale must be estimated from external sources: Performance Considerations CPU Usage Latency Low 5ms 500 features, ORB Good High 50ms | Tips: - Start with ORB + OpticalFlow for balanced performance - Use stereo or RGB-D when metric scale is required - Enable loop closure only if revisiting locations - Reduce maxfeatures for real-time on embedded systems Limitations - Pure Rust implementation - For full Visual SLAM with mapping, consider ROS2 bridge integration with ORB-SLAM3 or similar - S","headings":"Visual Odometry Node Features Basic Usage Configuration Camera Modes Feature Detectors VOConfig Options Topics Subscribed Published Stereo Visual Odometry RGB-D Visual Odometry Hybrid Processing Integration with Localization Scale Estimation Performance Considerations Limitations See Also","category":"rust"},{"id":140,"title":"YOLOv8DetectorNode","description":"Real-time object detection using YOLOv8 models","slug":"/rust/library/built-in-nodes/yolo-detector","content":"YOLOv8DetectorNode Real-time object detection node using YOLOv8 models (n/s/m/l/x variants). Supports COCO dataset (80 classes) and custom trained models for robotics applications. Source Code - YOLOv8DetectorNode Implementation - ML Messages Features - YOLOv8n/s/m/l/x model support - Real-time inference (30-60 FPS on GPU) - Non-Maximum Suppression (NMS) - Confidence filtering - Bounding box visualization (optional) - GPU acceleration support - COCO and custom model support Requirements Enable the onnx feature in your horus.yaml: Quick Start Configuration YOLOConfig Type Description f32 Confidence threshold (0.0-1.0) iouthreshold 0.45 usize Maximum detections to return usegpu false u32 GPU device ID inputsize 640 Vec<String Class labels enablevisualization false Topics Subscribed Topics Type Image Published Topics Type DetectionArray Image InferenceMetrics Usage Examples Basic Object Detection Person Detection for Robot Navigation Multi-Class Detection Model Download Download pre-trained YOLOv8 ONNX models: Performance GPU (RTX 3080) Accuracy (mAP) 60+ FPS 37.3 YOLOv8s 8-12 FPS 30-45 FPS 50.2 YOLOv8l 2-3 FPS See Also - PoseEstimationNode - Human pose detection - SemanticSegmentationNode - Pixel-wise segmentation - CameraNode - Image input - ONNXInferenceNode - Generic ONNX inference","headings":"YOLOv8DetectorNode Source Code Features Requirements Quick Start Configuration YOLOConfig Topics Subscribed Topics Published Topics Usage Examples Basic Object Detection Person Detection for Robot Navigation Multi-Class Detection Model Download Nano (fastest, least accurate) Small (balanced) Medium Large (slowest, most accurate) Performance See Also","category":"rust"},{"id":141,"title":"Rust Library","description":"Built-in nodes and algorithms for HORUS","slug":"/rust/library","content":"Rust Library Pre-built components ready to use in your HORUS applications. Built-in Nodes Hardware abstraction nodes for common robotics components: - Sensors (IMU, GPS, Camera, LiDAR) - Actuators (DC Motor, Servo, Stepper) - Communication (CAN Bus, I2C, Serial) - And more... Algorithms Robotics algorithms implemented and optimized: - PID Controller - Kalman Filter - A Pathfinding - Pure Pursuit - And more...","headings":"Rust Library [Built-in Nodes](/rust/library/built-in-nodes) [Algorithms](/rust/library/algorithms)","category":"rust"},{"id":142,"title":"Simulators","description":"HORUS simulation environments for 2D and 3D robotics","slug":"/simulators","content":"Simulators HORUS includes built-in simulation environments for testing and development. Available Simulators Sim2D Lightweight 2D robot simulation for rapid prototyping and algorithm testing. - Fast iteration - Simple physics - Perfect for path planning, control algorithms Sim3D Full 3D physics simulation powered by Bevy game engine. - Realistic physics - Sensor simulation - Reinforcement learning support - ROS2-compatible sensor outputs","headings":"Simulators Available Simulators [Sim2D](/simulators/sim2d) [Sim3D](/simulators/sim3d)","category":"simulators"},{"id":143,"title":"Articulated Robots in Sim2D","description":"Multi-joint robot simulation with preset configurations","slug":"/simulators/sim2d/articulated","content":"Articulated Robots Sim2D supports multi-joint articulated robots for simulating robot arms, humanoids, and other kinematic chains in 2D. Quick Start Available Presets arm2dof Simple 2-joint planar arm: - 2 revolute joints - Shoulder + elbow configuration - Good for learning kinematics arm6dof Industrial-style 6-DOF arm: - 6 revolute joints - Full planar reachability - Suitable for manipulation tasks humanoid Bipedal humanoid (side view): - Torso, legs, arms - Requires --gravity flag - Side-view simulation Configuration File Basic Structure Link Properties Type string float float float [r,g,b] float Joint Properties Type string string string string [x,y] [min,max] float float Control Interface Topics Type JointCommand JointState JointCommand Message JointState Message Control Example Inverse Kinematics For end-effector control, compute joint angles: Gravity Mode For side-view simulation with gravity: In gravity mode: - Y-axis points up - Gravity pulls downward - Useful for legged robots, pendulums Visual Markers Joint positions are marked with circles in the UI: - Red: Active/moving - Gray: Stationary - Green: At target position Enable/disable with J key. Limitations - 2D only (planar kinematics) - No closed kinematic chains - Limited collision detection between links - No self-collision by default For 3D articulated robots with full dynamics, use Sim3D. See Also - Sim2D Configuration - YAML reference - Sim3D - 3D simulation - Differential Drive - Mobile robot kinematics","headings":"Articulated Robots Quick Start Use a preset robot arm 6-DOF arm Humanoid (side view with gravity) Custom articulated robot Available Presets arm2dof arm6dof humanoid Configuration File Basic Structure articulatedrobot.yaml Link Properties Joint Properties Control Interface Topics JointCommand Message JointState Message Control Example Inverse Kinematics Gravity Mode Visual Markers Limitations See Also","category":"simulators"},{"id":144,"title":"Sim2D Configuration","description":"Robot and world YAML configuration reference","slug":"/simulators/sim2d/configuration","content":"Sim2D Configuration Sim2D uses YAML files to configure robots and worlds. This page covers all configuration options. Command Line Arguments Robot Configuration Basic Configuration Kinematics Model Description Two-wheel drive (tank steering) ackermann Omnidirectional (holonomic) Resolution 0.01 5 cm per pixel (typical) 0.1 Creating Maps 1. Use image editor to draw floor plan 2. Save as PGM, PNG, or JPG 3. Load with appropriate resolution Multi-Robot Configuration For multiple robots, create separate config files with different topic prefixes: Launch with multiple robots: Environment Variables Description Logging level (debug, info, warn, error) SIM2DSEED See Also - Getting Started - First steps - Sensors - Sensor configuration details - Articulated Robots - Multi-joint robots","headings":"Sim2D Configuration Command Line Arguments Robot Configuration Basic Configuration robot.yaml Physical dimensions Appearance Kinematics Model LIDAR Configuration Camera Configuration GPS Configuration Ultrasonic Sensors Contact Sensors Visual Components Complete Robot Example tankrobot.yaml World Configuration Basic World world.yaml Obstacles Rectangle Obstacles Circle Obstacles Dynamic Obstacles Complete World Example warehouse.yaml World from Image PGM format (common in ROS) PNG with custom threshold Image Format Resolution Creating Maps Example: 1000x1000 pixel map at 5cm resolution = 50m x 50m world Multi-Robot Configuration robot1.yaml robot2.yaml Currently requires library API See Python API documentation for multi-robot support Environment Variables See Also","category":"simulators"},{"id":145,"title":"Getting Started with Sim2D","description":"Launch your first 2D simulation and connect a controller","slug":"/simulators/sim2d/getting-started","content":"Getting Started with Sim2D This guide walks you through launching Sim2D, understanding the interface, and connecting your first robot controller. Prerequisites - HORUS installed (./install.sh) - Basic familiarity with HORUS nodes Launch the Simulator You'll see a window with: - A green robot rectangle - Gray boundary walls - Grid background - UI panels for configuration Understanding the Interface Main View The main view shows a top-down view of the simulation: UI Panels Description Position, velocity, configuration World LIDAR, IMU, GPS settings Performance Place/remove obstacles Key W/A/S/D Zoom in/out R Pause/Resume simulation E Toggle grid visibility L Your First Controller Create a simple keyboard teleop controller: Step 1: Create Project Step 2: Write the Controller Replace main.rs: Step 3: Run Both Watch the robot move forward in the simulator! Working with LIDAR Read LIDAR data to implement reactive behaviors: Using the World Editor Press E to enter editor mode: 1. Add Rectangle: Click \"Rectangle\" then click in world 2. Add Circle: Click \"Circle\" then click in world 3. Delete: Click obstacle, press Delete 4. Move: Drag obstacles 5. Resize: Drag corners 6. Save: Click \"Save World\" to export YAML Loading Custom Configurations Custom Robot Custom World From Image (Occupancy Grid) Headless Mode For RL training or CI/CD: Troubleshooting Robot doesn't move 1. Check topic names match: robot.cmdvel 2. Verify messages are being published 3. Check maxspeed in robot config LIDAR rays not visible Press L to toggle LIDAR visualization Simulation too slow 1. Close UI panels you don't need 2. Reduce LIDAR ray count 3. Use --headless for training Can't connect to topics Ensure both processes use the same topic name: Next Steps - Configuration - Detailed YAML reference - Sensors - All sensor types - Articulated Robots - Multi-joint robots - Python API - For RL integration","headings":"Getting Started with Sim2D Prerequisites Launch the Simulator Default configuration With custom topic prefix Build from source (development) Understanding the Interface Main View UI Panels Keyboard Controls Your First Controller Step 1: Create Project Step 2: Write the Controller Step 3: Run Both Terminal 1: Start simulator Terminal 2: Run controller Working with LIDAR Using the World Editor Loading Custom Configurations Custom Robot myrobot.yaml Custom World myworld.yaml From Image (Occupancy Grid) Load PGM/PNG as world map Dark pixels = obstacles Headless Mode No window, just physics With specific configuration Troubleshooting Robot doesn't move LIDAR rays not visible Simulation too slow Can't connect to topics Next Steps","category":"simulators"},{"id":146,"title":"Sim2D Overview","description":"Simple 2D robotics simulator with physics, sensors, and HORUS integration","slug":"/simulators/sim2d","content":"Sim2D - 2D Robotics Simulator A lightweight 2D robotics simulator built with Bevy and Rapier2D physics. One command gives you physics simulation, sensor models, and visualization - perfect for algorithm development, testing, and learning. Features - Rapier2D Physics - Realistic rigid body dynamics and collision detection - Multiple Sensors - LIDAR, camera, GPS, ultrasonic, IMU, contact sensors - HORUS Integration - Publish/subscribe to standard HORUS topics - Articulated Robots - Multi-joint robot arms with 2DOF, 6DOF presets - World Editor - Interactive obstacle placement and world design - Recording/Playback - Capture and replay simulation sessions - Headless Mode - Run without GUI for RL training and CI/CD Quick Start Architecture Default Topics Type Description CmdVel Velocity commands robot.odom Output Imu IMU data robot.scan Output NavSatFix GPS position Key WASD Zoom in/out R Pause/Resume E Toggle grid L Documentation - Getting Started - First steps with Sim2D - Configuration - Robot and world YAML files - Sensors - LIDAR, camera, GPS, ultrasonic, IMU - Articulated Robots - Multi-joint robots - Python API - Python bindings for RL Example: Simple Controller Control the simulated robot from your HORUS node: Run in two terminals: Comparison: Sim2D vs Sim3D Sim2D 2D (Rapier2D) Top-down view No No Very fast Algorithms, navigation See Also - Sim3D - Full 3D simulator - CLI Reference - horus sim2d options - Built-in Nodes - Sensor and control nodes","headings":"Sim2D - 2D Robotics Simulator Features Quick Start Launch with default robot and world Custom robot configuration Load world from image (occupancy grid) Headless mode for training Architecture Default Topics Simulator Controls Documentation Example: Simple Controller Terminal 1: Start simulator Terminal 2: Run your controller Comparison: Sim2D vs Sim3D See Also","category":"simulators"},{"id":147,"title":"Sim2D Python API","description":"Python bindings for Sim2D simulation and RL training","slug":"/simulators/sim2d/python-api","content":"Sim2D Python API Sim2D provides Python bindings for reinforcement learning, rapid prototyping, and integration with ML frameworks. Installation Quick Start API Reference Sim2D Class Methods Description Advance simulation by dt seconds reset() Set robot velocity command getpose() Get LIDAR scan data getimu() Shutdown simulation | RobotConfig WorldConfig Obstacle Observation Space The step() method returns a dictionary: Gym Environment Wrap Sim2D as a Gymnasium environment: Training with Stable-Baselines3 Multi-Robot Simulation Performance Tips Headless Mode Always use headless=True for training: Batch Stepping Step multiple times between observations: Reduce LIDAR Rays Fewer rays = faster simulation: HORUS Integration The Python API uses HORUS shared memory internally: See Also - Sim2D Overview - Full simulator documentation - Python Bindings - HORUS Python API","headings":"Sim2D Python API Installation Install with Python support Or build from source with Python feature Quick Start Create simulation Step simulation API Reference Sim2D Class Methods RobotConfig WorldConfig Obstacle Observation Space Pose Velocity LIDAR (if enabled) IMU (if enabled) Collision Gym Environment Training with Stable-Baselines3 Create vectorized environment Train agent Save model Test Multi-Robot Simulation Create robots with different prefixes Step all robots Performance Tips Headless Mode Batch Stepping Reduce LIDAR Rays HORUS Integration Your Python RL agent Can communicate with Rust nodes on same topics! Rust node can subscribe to robot.cmdvel Python can publish to robot.cmdvel See Also","category":"simulators"},{"id":148,"title":"Sim2D Sensors","description":"LIDAR, camera, GPS, IMU, ultrasonic, and contact sensor simulation","slug":"/simulators/sim2d/sensors","content":"Sim2D Sensors Sim2D provides realistic sensor models with configurable noise for testing perception and navigation algorithms. Available Sensors Topic Description {prefix}.scan 2D laser scanner IMU Imu {prefix}.odom Wheel odometry Camera Image {prefix}.gps Global position Ultrasonic Range {prefix}.contact Collision detection Robot Type numrays Indoor robot 360 30.0 0.5° resolution Low-cost 180 50.0 0.2° resolution Quality Description RTK Centimeter accuracy Good Clear sky Urban Buildings, multipath Indoor Very poor signal Sensor Type fov HC-SR04 15° 6.5 0.15 Short-range 30° Message Format Contact Sensors Bump sensors that detect physical contact with obstacles. Configuration Message Format Usage Example Noise Models All sensors support Gaussian noise models: Applying Noise Realistic Noise Values Parameter Range Position Gyro Accel Range Drift Sensor Fusion Example Combine multiple sensors for robust localization: See Also - Configuration - Full YAML reference - Sensor Fusion Algorithm - Combining sensors - EKF Algorithm - State estimation - Built-in Sensor Nodes - Hardware sensor drivers","headings":"Sim2D Sensors Available Sensors LIDAR Configuration Common Configurations Message Format Usage Example IMU Configuration In robot config, IMU noise is applied automatically based on physics simulation Message Format Usage Example Odometry Message Format Usage Example GPS Configuration Accuracy Levels Message Format Coordinate System Ultrasonic Sensors Configuration Typical Configurations Message Format Contact Sensors Configuration Message Format Usage Example Noise Models Applying Noise Realistic Noise Values Sensor Fusion Example See Also","category":"simulators"},{"id":149,"title":"Installation","description":"Installing and setting up Sim3D","slug":"/simulators/sim3d/getting-started/installation","content":"Installing Sim3D Sim3D is included with the HORUS framework. This guide covers installation and initial setup. Prerequisites - HORUS framework installed (cargo install horus) - Rust 1.70+ (for building from source) - OpenGL 3.3+ or Vulkan (for rendering) Optional Dependencies - CUDA Toolkit 11+: For GPU-accelerated physics - Python 3.9+: For RL training with Python - FFmpeg: For video recording/export Installation Methods Via HORUS CLI (Recommended) Sim3D is bundled with the HORUS CLI: From Source Python Package (for RL) Verify Installation Directory Structure After installation, sim3d uses these directories: GPU Setup CUDA (NVIDIA) Vulkan Vulkan is used for rendering. Install drivers for your GPU: Troubleshooting \"Failed to create window\" Install graphics drivers and Vulkan support: \"CUDA not found\" Ensure CUDA toolkit is installed and CUDAHOME is set: Headless Server (No Display) Use virtual framebuffer for headless rendering: Or use pure headless mode (no rendering): Next Steps - Quick Start Tutorial - Create your first simulation - Loading Robots - Import URDF/MJCF models - Sensors Overview - Configure sensor suite","headings":"Installing Sim3D Prerequisites Optional Dependencies Installation Methods Via HORUS CLI (Recommended) Install HORUS (includes sim3d) Verify installation From Source Clone HORUS repository Build sim3d with default features Build with all features Python Package (for RL) Install Python bindings Or build from source with maturin Verify Installation Check version Run with a test scene Test headless mode Directory Structure GPU Setup CUDA (NVIDIA) Check CUDA availability Build with CUDA support Vulkan Ubuntu/Debian Verify Troubleshooting \"Failed to create window\" NVIDIA AMD Intel \"CUDA not found\" Headless Server (No Display) Install Xvfb Run sim3d with virtual display Next Steps","category":"simulators"},{"id":150,"title":"Quick Start","description":"Create your first Sim3D simulation","slug":"/simulators/sim3d/getting-started/quick-start","content":"Quick Start This guide walks you through creating your first Sim3D simulation with a mobile robot. Basic Simulation 1. Create a World Configuration Create myworld.yaml: 2. Run the Simulation 3. Controls Action Move camera Mouse Zoom in/out Space Reset simulation F1 Exit | Adding a Robot 1. Use a Robot Model 2. Create a Robot Configuration Create myrobot.yaml: 3. Run with Your Robot Controlling the Robot From Command Line From Rust Code From Python Reading Sensor Data Subscribe to Topics Headless Mode For training or batch simulations: Deterministic Simulation Faster-than-Realtime When running headless, use the --speed flag with the sim3d binary directly: Complete Example Here's a complete node that controls the robot: Next Steps - Sensors Overview - Configure cameras, LiDAR, IMU - Physics Configuration - Tune physics parameters - RL Training - Set up reinforcement learning","headings":"Quick Start Basic Simulation 1. Create a World Configuration World configuration Ground plane Obstacles Lighting 2. Run the Simulation Via HORUS CLI (recommended) Or run sim3d binary directly 3. Controls Adding a Robot 1. Use a Robot Model Specify a URDF file 2. Create a Robot Configuration Physical properties Sensors 3. Run with Your Robot Controlling the Robot From Command Line In another terminal, publish velocity commands From Rust Code From Python Connect to robot Send command Reading Sensor Data Subscribe to Topics Headless Mode Run without rendering Deterministic Simulation Use a fixed seed for reproducible results Faster-than-Realtime Run at 10x speed (via sim3d binary) Complete Example Next Steps","category":"simulators"},{"id":151,"title":"Loading Robots","description":"Loading URDF robots into Sim3D","slug":"/simulators/sim3d/getting-started/robots","content":"Loading Robots in Sim3D Sim3D supports loading robots from URDF (Unified Robot Description Format) files, the standard format used in robotics. Quick Start URDF Support Sim3D supports standard URDF features: Support STL, OBJ, DAE Collision meshes revolute, prismatic, fixed, continuous Materials Full inertia tensors Limits Example URDF Built-in Robot Presets Loading from Code Rust API Python API Spawn Position Control where the robot appears: In YAML: Multi-Robot Setup Load multiple robots: Mesh Files Place mesh files relative to the URDF: Reference in URDF: Troubleshooting Robot doesn't appear - Check URDF path is correct - Verify mesh files exist - Check console for parsing errors Robot falls through ground - Add a collision geometry to base link - Ensure ground plane exists in world Joints don't move - Check joint type is revolute or prismatic (not fixed) - Verify joint limits allow movement - Check topic names for joint commands See Also - Installation - Setup guide - Quick Start - First simulation - Sensors Overview - Adding sensors to robots","headings":"Loading Robots in Sim3D Quick Start Load a robot from URDF Load with custom world URDF Support Example URDF Built-in Robot Presets TurtleBot3 Burger TurtleBot3 Waffle Simple differential drive 6-DOF arm Quadruped Loading from Code Rust API Python API Spawn Position Spawn at specific position Spawn with rotation (yaw in radians) world.yaml Multi-Robot Setup multirobot.yaml Mesh Files Troubleshooting Robot doesn't appear Robot falls through ground Joints don't move See Also","category":"simulators"},{"id":152,"title":"Sim3D - 3D Robotics Simulator","description":"High-fidelity 3D physics simulation for robotics development, testing, and reinforcement learning","slug":"/simulators/sim3d","content":"Sim3D - 3D Robotics Simulator Sim3D is HORUS's high-fidelity 3D robotics simulator built on Bevy and Rapier3D physics. It provides realistic physics simulation, sensor emulation, and reinforcement learning environments for developing and testing robotic systems. Key Features - Physics Engine: Rapier3D rigid and soft body dynamics - GPU Acceleration: Optional GPU-accelerated physics and rendering - Sensor Suite: 16+ sensor types (cameras, LiDAR, IMU, force/torque, etc.) - Robot Formats: URDF, MJCF, SDF, USD support - RL Integration: 6 built-in tasks with curriculum learning - Recording: Trajectory and video recording/export - Editor: Full scene editor with undo/redo Quick Start Architecture HORUS Integration Sim3D automatically creates HORUS topics for robot control and sensor data: Type Description Twist Velocity commands {robot}.odom Publish LaserScan LiDAR scan {robot}.hf Publish PointCloud2 3D point cloud {robot}.jointstates Publish Documentation Sections - Getting Started - Installation and first simulation - Sensors - Camera, LiDAR, IMU, and more - Physics - Rigid body, soft body, and GPU physics - Reinforcement Learning - RL tasks and training System Requirements Minimum 4 cores 8 GB OpenGL 3.3 2 GB Feature Flags Enable optional features in your Cargo.toml: Description Full 3D rendering (default) headless Scene editor UI python All features combined |","headings":"Sim3D - 3D Robotics Simulator Key Features Quick Start Run sim3d with a URDF robot Headless mode for training Architecture HORUS Integration Documentation Sections System Requirements Feature Flags","category":"simulators"},{"id":153,"title":"Sim3D Physics","description":"Physics simulation in the HORUS 3D simulator","slug":"/simulators/sim3d/physics/overview","content":"Sim3D Physics Sim3D uses Rapier3D for high-fidelity physics simulation, supporting rigid bodies, soft bodies, joints, and GPU-accelerated physics. Physics Engine Sim3D is built on Rapier3D, a fast and accurate physics engine written in Rust: - Rigid body dynamics - Accurate collision and contact simulation - Soft body physics - Deformable objects and cloth - Articulated bodies - Robots with joints and constraints - GPU acceleration - Optional CUDA/Vulkan compute Configuration Configure physics in your scene or via CLI: Rigid Bodies Body Types YAML Configuration Colliders Primitive Shapes Complex Shapes Materials Configure surface properties: Joints Revolute Joint (Hinge) Prismatic Joint (Slider) Fixed Joint Ball Joint (Spherical) Generic 6-DOF Joint Controllers Built-in joint controllers: Position Controller Velocity Controller Torque Controller Differential Drive Built-in differential drive physics: Soft Bodies Deformable objects using FEM: Collision Groups Control what collides with what: Contact Events Subscribe to collision events: GPU Physics Enable GPU-accelerated physics (requires CUDA): Performance Tuning Timestep vs Accuracy Accuracy Use Case Highest High-precision manipulation 0.001s Good Medium Real-time training 0.016s Fastest Solver Iterations Substeps See Also - Sim3D Sensors - Simulated sensors - Sim3D RL - Reinforcement learning - URDF Loading - Robot models","headings":"Sim3D Physics Physics Engine Configuration scene.yaml CLI options Rigid Bodies Body Types YAML Configuration Colliders Primitive Shapes Complex Shapes Materials Joints Revolute Joint (Hinge) Prismatic Joint (Slider) Fixed Joint Ball Joint (Spherical) Generic 6-DOF Joint Controllers Position Controller Velocity Controller Torque Controller Differential Drive Soft Bodies Collision Groups Contact Events GPU Physics Performance Tuning Timestep vs Accuracy Solver Iterations Substeps See Also","category":"simulators"},{"id":154,"title":"Sim3D Reinforcement Learning","description":"RL training environments in the HORUS 3D simulator","slug":"/simulators/sim3d/rl/overview","content":"Sim3D Reinforcement Learning Sim3D provides reinforcement learning environments with curriculum learning, domain randomization, and reward shaping for training robot policies. Features - 6 built-in tasks - Navigation, manipulation, locomotion, etc. - Curriculum learning - Automatic difficulty progression - Domain randomization - Visual, physics, and environment randomization - Reward shaping - Composable reward functions - Python bindings - Gymnasium-compatible API - Parallel environments - Train on multiple envs simultaneously Quick Start Python (Gymnasium API) Rust API Built-in Tasks Reaching Reach a target position with end-effector. Observation: Joint positions, velocities, end-effector position, target position Action: Joint position or velocity commands Reward: -distancetotarget + bonusonsuccess Push Push an object to a target location. Observation: Robot state, object pose, target pose Action: End-effector delta position Reward: -objectdistancetotarget Manipulation Pick and place objects. Observation: Robot state, gripper state, object poses Action: End-effector + gripper commands Reward: Multi-stage (approach, grasp, lift, place) Navigation Navigate a mobile robot to goals while avoiding obstacles. Observation: LiDAR scan, odometry, goal position Action: Linear/angular velocity (cmdvel) Reward: -distancetogoal - collisionpenalty Locomotion Legged robot locomotion (walking, running). Observation: Joint states, body orientation, velocity Action: Joint torques or positions Reward: velocitytracking - energy - stabilitypenalty Balancing Balance an inverted pendulum or unstable system. Observation: Cart position/velocity, pole angle/velocity Action: Cart force Reward: +1 per timestep balanced Curriculum Learning Automatically adjust task difficulty based on performance: YAML Configuration Domain Randomization Randomize environment for sim-to-real transfer: Visual Randomization Physics Randomization Environment Randomization Reward Shaping Compose rewards from mult","headings":"Sim3D Reinforcement Learning Features Quick Start Python (Gymnasium API) Create environment Standard Gym loop Rust API Built-in Tasks Reaching Push Manipulation Navigation Locomotion Balancing Curriculum Learning YAML Configuration Domain Randomization Visual Randomization Physics Randomization Environment Randomization Reward Shaping Built-in Reward Functions Parallel Environments Vector environment (CPU) GPU-accelerated (requires CUDA) Step all envs Headless Training CLI Python Integration with RL Libraries Stable-Baselines3 Ray RLlib CleanRL Use CleanRL's PPO implementation Custom Tasks Performance See Also","category":"simulators"},{"id":155,"title":"Sim3D Sensors","description":"Simulated sensors in the HORUS 3D simulator","slug":"/simulators/sim3d/sensors/overview","content":"Sim3D Sensors Sim3D provides high-fidelity simulated sensors that mirror real hardware behavior. Each sensor publishes to HORUS topics using identical interfaces as physical hardware, enabling code to run unchanged in simulation and on real robots. Available Sensors Description RGB camera with lens distortion Depth sensing (stereo/structured light) Combined RGB + Depth 3D laser scanner Accelerometer + Gyroscope Global positioning Wheel/joint encoders 6-axis force sensing Touch/pressure sensing Dynamic Vision Sensor (DVS) Radio detection and ranging Ultrasonic ranging Infrared thermal imaging Semantic/instance segmentation Sensor Configuration Sensors are configured in your robot URDF or scene YAML: Camera RGB camera with realistic lens distortion and noise models. Published Topics: - {topic} - Image (RGB) - {topic}.info - CameraInfo (intrinsics) Depth Camera Simulates stereo or structured-light depth cameras (RealSense, Kinect, etc.). Published Topics: - {topic} - DepthImage (16-bit depth in mm) RGB-D Combined RGB and depth camera (e.g., RealSense D435). Published Topics: - {topic}.color - Image (RGB) - {topic}.depth - DepthImage - {topic}.points - PointCloud2 (optional) LiDAR 3D 3D laser scanner with configurable beam pattern. Published Topics: - {topic} - PointCloud2 (XYZ + intensity) - {topic}.scan - LaserScan (2D slice, optional) IMU Inertial Measurement Unit with accelerometer and gyroscope. Published Topics: - {topic} - Imu (orientation, angular velocity, linear acceleration) GPS Global Positioning System simulation. Published Topics: - {topic} - NavSatFix - {topic}.velocity - TwistStamped Encoder Wheel or joint encoders. Published Topics: - {topic} - JointState (position, velocity) Force/Torque 6-axis force/torque sensor. Published Topics: - {topic} - Wrench (force XYZ, torque XYZ) Tactile Tactile/pressure sensor array. Published Topics: - {topic} - TactileArray (pressure grid) Event Camera Dynamic Vision Sensor (DVS) - outputs events on brightness change. Pu","headings":"Sim3D Sensors Available Sensors Sensor Configuration scene.yaml Camera Depth Camera RGB-D LiDAR 3D IMU GPS Encoder Force/Torque Tactile Event Camera Radar Sonar Thermal Segmentation Noise Models Distortion Models See Also","category":"simulators"},{"id":156,"title":"Troubleshooting Runtime Errors","description":"Common HORUS runtime errors and how to fix them","slug":"/troubleshooting-runtime","content":"Troubleshooting Runtime Errors This guide helps you diagnose and fix common errors that occur when running HORUS applications. For installation issues, see Installation Troubleshooting. Quick Diagnostic Steps When your HORUS application isn't working: 1. Check the Monitor: Run horus monitor to see active nodes, topics, and message flow 2. Examine Logs: Look for error messages in your terminal output 3. Verify Topics: Ensure publisher and subscriber use exact same topic names 4. Check Shared Memory: Look in /dev/shm/ for stale HORUS memory regions 5. Test Individually: Run nodes one at a time to isolate the problem Hub Creation Errors Error: \"Hub creation failed\" or \"Failed to create Hub<T\" Symptom: Application crashes on startup with: Common Causes: 1. Stale Shared Memory from Previous Run - HORUS uses /dev/shm/horus for communication - If your app crashes, these files persist Fix: Clean shared memory: 2. Permission Issues - You may not have write access to /dev/shm/ Fix: Check permissions: 3. Conflicting Topic Names - Two Hubs with same name but different types Fix: Use unique topic names: Error: \"No such file or directory\" when creating Hub Symptom: Application crashes with: Cause: You're using slashes (/) in your topic name instead of dots (.). HORUS topic names become file names in /dev/shm. When you use a slash, it's interpreted as a directory path that doesn't exist: Fix: Replace all slashes with dots in topic names: Coming from ROS? ROS uses slashes (/sensor/lidar) because it uses network-based naming. HORUS uses dots because topic names map directly to shared memory file names. See Topic Naming for details. Message Communication Issues Problem: \"No messages received\" - recv() always returns None Symptom: Subscriber node never receives messages even though publisher is sending. Common Causes: 1. Topic Name Mismatch - Publisher and subscriber use different topic names - Typos are the 1 cause Fix: Verify exact topic names: Debug with Monitor: Check the \"Topics\"","headings":"Troubleshooting Runtime Errors Quick Diagnostic Steps Hub Creation Errors Error: \"Hub creation failed\" or \"Failed to create Hub<T>\" Error: \"No such file or directory\" when creating Hub Message Communication Issues Problem: \"No messages received\" - recv() always returns None Deadlock and Hanging Issues Problem: Application hangs, no output, no progress Message Size Issues Error: \"Message too large\" or allocation failure Build and Compilation Issues Error: \"unresolved import\" or \"cannot find type in this scope\" Error: \"trait bound ... is not satisfied\" Using the Monitor for Debugging Start the Monitor In a separate terminal Monitor Features Example Debugging Session Reading Log Output Log Levels Interpreting Timestamps Common Patterns and Anti-Patterns [OK] DO: Check recv() for None [FAIL] DON'T: Unwrap recv() [OK] DO: Use Result for errors [FAIL] DON'T: panic!() in nodes [OK] DO: Keep tick() fast [FAIL] DON'T: Block in tick() Still Stuck? Next Steps","category":"general"},{"id":157,"title":"Troubleshooting & Maintenance","description":"Fix installation issues, update HORUS, and verify installation health","slug":"/troubleshooting","content":"Troubleshooting & Maintenance HORUS includes utility scripts to help you update, recover from broken installations, and verify your setup. Quick Reference Use When Install or update Check installation health Remove HORUS Updating HORUS To update to the latest version: To preview changes before updating: If you have uncommitted changes: verify.sh - Installation Health Check Use when: Diagnosing issues, checking if installation is correct Quick Usage What It Checks 1. System Requirements - Rust version (&gt;= 1.70) - Cargo installation - Build tools - pkg-config - System libraries (OpenSSL, udev) 2. HORUS Installation - Binary location and version - PATH configuration - Core libraries - Optional components (Python bindings) 3. Functionality Tests - Commands work (--version, --help) - All subcommands accessible (new, run, monitor, pkg, env, auth, version) - Build verification (when run in HORUS repo): - cargo check passes without errors - Zero warnings in codebase - Debug binary is functional 4. Disk Usage - Cache sizes - Installation footprint Example Output Exit Codes Useful for CI/CD: - 0 = Perfect, no issues - 1 = Warnings (minor issues) - 2 = Errors (installation broken) Common Warnings Binary not in PATH: Old Rust version: Missing optional libraries: Manual Recovery Use when: Build errors, corrupted cache, installation broken Quick Steps When to Use Recovery Symptoms requiring recovery: 1. Build fails: 2. Corrupted cache: 3. Binary doesn't work: 4. Version mismatches: 5. Broken after system updates: - Rust updated - System libraries changed - GCC/Clang updated What Gets Removed By cargo clean: - target/ directory (build artifacts) By rm -rf /.horus/cache: - Installed libraries - Cached dependencies Never removed (safe): - /.horus/config (user settings) - /.horus/credentials (registry auth) - Project-local .horus/ directories - Your source code Full Reset (Nuclear Option) If the quick steps don't work, do a complete reset: Common Issues & Solutions Installation Is","headings":"Troubleshooting & Maintenance Quick Reference Updating HORUS verify.sh - Installation Health Check Quick Usage What It Checks Example Output Exit Codes Common Warnings Manual Recovery Quick Steps Navigate to HORUS source directory 1. Clean build artifacts 2. Remove cached libraries 3. Fresh install 4. Verify installation When to Use Recovery What Gets Removed Full Reset (Nuclear Option) Remove everything HORUS-related Fresh install Verify Common Issues & Solutions Installation Issues Install Rust Then try again Ubuntu/Debian/Raspberry Pi OS - Install ALL required packages Fedora/RHEL Install ALL missing system libraries (most common cause) Ubuntu/Debian/Raspberry Pi OS Or run manual recovery (see Manual Recovery section) Update Issues Try manual recovery Force rebuild Runtime Issues Add to PATH (add to ~/.bashrc or ~/.zshrc) Then reload shell Verify Full recovery Clean cached build artifacts and dependencies This removes .horus/target/ and forces a fresh build with the new version Remove the entire .horus directory Next run will rebuild from scratch Only needed if --clean doesn't work This reinstalls HORUS libraries globally Clean all projects in your workspace Option 1: Set HORUSSOURCE (recommended for non-standard installations) Option 2: Install HORUS to a standard location The CLI checks these paths automatically: - ~/horus/HORUS - /horus - /opt/horus - /usr/local/horus Verify HORUS source is found Performance Issues Use release mode (optimized) Or configure in horus.yaml Check usage Clean old cargo cache Remove unused dependencies Clean build artifacts in current project Or use horus clean flag (next build will be slower) Regular cleanup (if working on multiple projects) Add to .gitignore (already included in horus new templates) Best Practices Regular Maintenance If Rust/GCC updated, run manual recovery CI/CD Integration In CI pipeline Exit codes Debugging Workflow Getting Help Runtime Errors Hub Creation Failed Check /dev/shm permissions Check available space Clean old HORUS shared memory Fix permissions (if needed) Topic Not Found / No Messages Received Terminal 1: Run your app Terminal 2: Open monitor Application Hangs / Deadlock Message Size Errors Using Monitor to Debug Terminal 1: Run your application Terminal 2: Start monitor Problem: Subscriber not receiving messages Monitor shows: Nodes: SensorNode (Running), DisplayNode (Running) Topics: \"sensordata\" (1 pub, 0 sub)  <-- AHA! Issue: No subscribers! Fix: Check DisplayNode - likely wrong topic name Next Steps","category":"general"}]}